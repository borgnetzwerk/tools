{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage II\n",
    "\n",
    "## Task 3: Search\n",
    "|Step|Result|Requirement|\n",
    ":----|:----|:----|\n",
    "|Find resources|preliminary document list|16. use reliable sources<br>17. find relevant documents<br>18. find similar documents|\n",
    "|Remove duplicates|preliminary document set|19. identify duplicate documents|\n",
    "|Find missing documents|curated document set|20. find unindexed documents<br>21. identify document set gaps|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"images/Task 3.jpg\" width=\"990\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Find resources\n",
    "Requirements:\n",
    "* use reliable sources\n",
    "* find relevant documents\n",
    "* find similar documents\n",
    "\n",
    "1. **Reference manager**: First, a digital library setup is required. While this setup uses [Zotero](https://www.zotero.org/), others like [Citavi](https://www.citavi.com/) are equally valid, though some steps may need to be modified to fit their specific functionality. The following steps are recommended:\n",
    "    1. Install the Zotero application and browser plugin.\n",
    "    2. Sign in to your Zotero account for both.\n",
    "    3. **Zotero library**: Setup a library (/group) for this literature SWIM.\n",
    "    4. **Query collections**: For each search query, set up a collection (/folder) within this library.\n",
    "2. **Search engine**: While each literature SWIM only uses one *Reference manager*, it can and should use multiple search engines, Google Scholar, Semantic Scholar, OKMaps etc. Proceed as follows:\n",
    "    1. For each search engine:\n",
    "        1. For each query:\n",
    "            1. Create a collection (/folder) within the respective *query collection*. Select this collection with a left-click.\n",
    "            2. Open the search engine and use the query there.\n",
    "            3. Store each resulting page using the zotero plugin. While the results should be between 100 and 500, it is recommended to stop after cataloguing the first ~200 results.\n",
    "                * *Hint*: While you can open multiple tabs and increase the amount of search results per page, neither are recommended. Many search engines use temporary timeouts to sanction highly frequent access.\n",
    "            4. Then export the *query collection* as a BibTeX, for later reference.\n",
    "\n",
    "The reliability of sources is generally given for most dedicated scholarly search engines, with only minor curation required later on. While this step collects the majority of relevant documents will be collected during this step, there are various means through which the document set can be expanded later on. Examples include:\n",
    "* A highly relevant document is found and is used to query **Connected Papers**. This results in a recommendation of additional relevant papers, which can be downloaded as BibTeX and added via Zotero's \"Import from BibTeX\" functionality.\n",
    "* A (large) research project relevant to a research question is found and has it's publications catalogued. These results can be either added through BibTeX (see above), or looked up individually and added manually.\n",
    "\n",
    "Within the *Zotero library*, a new collection should be created called \"others\". Within that, each of these examples (e.g. Connected Papers dump / research project publications / ...) is stored as it's own collection. Like the *query collection*, the BibTeX representation of these collections should be exported and stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Remove duplicates\n",
    "**Requirements:**\n",
    "* identify duplicate documents\n",
    "\n",
    "*Hint*: Before any duplicates are removed, it is important to make sure all collections have their BibTeX stored. If not, it is impossible to reliably trace back the origin of a document once duplicates are removed.\n",
    "\n",
    "Most duplicates can be removed by using Zotero's \"Duplicate items\" section next to the collections. Each item there can be merged with the click of a button, removing the duplicates.\n",
    "\n",
    "Other duplicates may only be found later on, for example when calculating document similarity. This step is primarily to reduce future overhead processing the same file twice, while it presumably can't fully prevent this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Find missing documents\n",
    "Requirements:\n",
    "* find unindexed documents\n",
    "* identify document set gaps\n",
    "\n",
    "Once all queries are processed and all apparent duplicates removed, the last step of task 3 includes three phases:\n",
    "1. **Find documents**: First, using Zotero's \"Find Available PDFs\" feature, all PDFs of the library are downloaded. Select the library, all references therin and find this feature by right-clicking any of them. After this is processed, presumably not all PDFs are found. By filtering the library by attatchments, each reference without PDF can be inspected. The research can attempt to find missing PDFs of promising references through other means, e.g. from their (departments) own library, by buying the work, contacting the authors or consulting a librarian.\n",
    "2. **Identify gaps**: If works knwon to the research that are deemed relevant to the research question are not in the Zotero library, they can be added as a dedicated collection within the \"others\" collection. Each document added here should be thuroughly inspected for the following reasons:\n",
    "    * Works of a second (non-english) language are usually not picked up by research engines. This can be circumnvented by translating each query to said other language, which provides extended scope in exchange for significant overhead in data management. While not recommended, this process is not adviced against, and can be conducted if the benefit is deemed worth the investment.\n",
    "    * Potentially, the search queries have a blind spot, either being to exclusive in their keyword combination, or not including an important keyword. This indicates a) an oversight in \"Step 2.4 Refine with related literature\", as well as b) a potential to soft-reset the survey back to Step 2.5. Generally, the collected references are not invalid and can be kept, leaving only the modified and added queries to be re-run.\n",
    "        * *Hint*: Instead of adding this kind of missing keyword ```B``` as ```A OR B```, a new query should be added without the ```A```. While in hindsight the ```A OR B``` variation would have been prefered, re-running the ```A OR B``` query will return already recorded results.\n",
    "    \n",
    "    Similarly, gaps can be identified without the right documents to fill them. If such a gap is identified *via known missing keywords*, proceed with a soft reset as described above. If not, this blind spot might be a finding of the SWIM survey itself, noting not a gap in the search, but in the literature itself.\n",
    "3. **Export library**: Concluding task 3, the Zotero library should be exported as BibTeX, this time with \"Export Files\" checked.\n",
    "\n",
    "*Note*: Take note that this survey methodology can only process documents that have a PDF available. If the PDF is behind a paywall or otherwise unaccessible, the work will not be regarded beyond this point. This, amongst others, further supports the relevance of Open Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Select\n",
    "|Step|Result|Requirement|\n",
    ":----|:----|:----|\n",
    "|Extract structured data from documents|metadata|22. extract publication date<br>23. extract author(s)<br>24. extract publication venue<br>25. extract specified keywords|\n",
    "| |content|26. extract document text<br>27. differentiate chapters|\n",
    "| |bag of words|28. remove special character<br>29. identify multi-word expressions<br>30. expand acronyms<br>31. lemmatise words<br>32. normalise words<br>33. remove stopwords|\n",
    "| |contribution statements|34. identify statements|\n",
    "|Calculate relational meassurements within the document set|document representation|35. calculate \"term frequency\" (tf) and \"term frequency - inverse document frequency\" (tf-idf)<br>36. calculate wordembedding and document embedding<br>37. represent document machine-readable|\n",
    "| |similarity of documents within the document set|38. consider synonyms<br>39. consider polysems<br>40. calculate document similarity|\n",
    "|Identify documents relevant for the research questions|relevance of documents for research question|41. represent research question machine-readable<br>42. calculate document relevancy for research question|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"images/Task 4.jpg\" width=\"990\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 Extract structures data form documents.\n",
    "**Requirements:**\n",
    "* metadata\n",
    "    * extract publication date\n",
    "    * extract author(s)\n",
    "    * extract publication venue\n",
    "    * extract specified keywords\n",
    "* content\n",
    "    * extract document text\n",
    "    * differentiate chapters\n",
    "* bag of words\n",
    "    * remove special character\n",
    "    * identify multi-wprds\n",
    "    * expand acronyms\n",
    "    * lemmatise words\n",
    "    * normalise words\n",
    "    * remove stopwords\n",
    "* contribution statements\n",
    "    * identify statements\n",
    "\n",
    "This step is broken down into extracting various structured data from documents. With this step, we begin to utilize Python, requiring setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "import bnw_tools\n",
    "\n",
    "\n",
    "\n",
    "from bnw_tools.publish.Obsidian import nlped_whispered_folder\n",
    "from bnw_tools.publish import util_wordcloud\n",
    "from bnw_tools.extract.nlp import util_nlp\n",
    "\n",
    "folder_path = \"D:/workspace/Zotero/SE2A-B4-2\"\n",
    "language = \"en\"\n",
    "\n",
    "nlptools = util_nlp.NLPTools()\n",
    "\n",
    "# NLP (Flair and SpaCy)\n",
    "folder = util_nlp.Folder(\n",
    "    folder_path, nlptools=nlptools, language=language)\n",
    "\n",
    "# Wordcloud\n",
    "if folder.media_resources:\n",
    "    util_wordcloud.generate_wordcloud(\n",
    "        folder.bag_of_words.get(), os.path.join(folder_path, \"00_bag_of_words\"))\n",
    "    util_wordcloud.generate_wordcloud(\n",
    "        folder.named_entities.get_frequencies(), os.path.join(folder_path, \"00_named_entities\"))\n",
    "    mask_path = folder.get_image()\n",
    "    if mask_path:\n",
    "        mask = util_wordcloud.generate_mask(mask_path)\n",
    "        util_wordcloud.generate_wordcloud_mask(\n",
    "            folder.bag_of_words.get(), mask, os.path.join(folder_path, \"00_bag_of_words_mask\"))\n",
    "        util_wordcloud.generate_wordcloud_mask(folder.named_entities.get_frequencies(\n",
    "        ), mask, os.path.join(folder_path, \"00_named_entities_mask\"))\n",
    "\n",
    "    # Obsidian\n",
    "    nlped_whispered_folder.folder(folder, force=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "Given the BibTeX export, most of the matadata is already structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content\n",
    "Working on a purely textual basis, this pipeline extracts all text from the PDF. This has a multitude of shortcomings, including among others:\n",
    "* PDFs that either not allow, actively hinder or somehow are incompatible with automatic mining are excluded from this approach.\n",
    "* Previously formated text looses context, such as tables, image captions, page numbers, headers and footers, etc.\n",
    "* Overlapping text, either visible oder invisible, may grain the mined text.\n",
    "\n",
    "Despite these errors, this method continues to work with this text-extraction-basis, due the nature of prior publications being of PDF-only nature at best and (scanned) print versions at worst.Then differentiate chapters. If more tools like [ORKG](https://orkg.org/) and [SciKGTeX](https://github.com/Christof93/SciKGTeX) are used in scientific practice, this and other step would benefit greatly.\n",
    "\n",
    "In the meantime, we proceed as follows:\n",
    "1. For each PDF\n",
    "    1. **Extract text**: If no available PDF reader can extract text from a given PDF, this step is skipped for said document. It will not be further analyzed computationally and awaits manual evaluation later on.\n",
    "    2. **Clean text**: Due to the nature of PDF, a multitude of errors can be *attempted* to clean up post extraction. These attempts are differentiated between ```always correct [++]```, ```potentially wrong [+-]``` and  ```highly situational [--]```. They include:\n",
    "        * [++] Removing line-breaks inside words: ```know-\\n ledge``` -> ```know-ledge```\n",
    "        * [+-] Removing hyphenation inside words: ```know-ledge``` -> ```knowledge```\n",
    "        * [+-] Remove PDF authors, institutions, etc.\n",
    "        * [+-] Remove headers and footers\n",
    "        * [+-] Re-position captions\n",
    "        * [--] Remove / re-position footnotes\n",
    "        * [--] Remove / re-position table content\n",
    "    3. **Structure text**: Attempt to differentiate between:\n",
    "        * Abstract\n",
    "        * Chapters / sections\n",
    "        * References\n",
    "\n",
    "Each extracted and potentially structured text is stored for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words\n",
    "Before the plain text can be converted to a bag of words (BoW), some sub-steps are required: \n",
    "* **remove special character**: For the purpose of the BoW, special characters such as ```!\"ยง$%&/()=?``` are not required and are removed.\n",
    "* **identify multi-word expressions**: Words that semantically form a single unit, such as ```New York```, should be treated as such. \n",
    "* **expand acronyms**: Acronyms such as ```BoW``` and ```Bag of Words``` should not both be stored, hence each acroynme is expanded to its long form.\n",
    "* **lemmatise words**: Instance like ```New Yorks``` and ```instances``` is reduced to it's non-flexed lemma ```New York``` and ```instance```. \n",
    "* **normalise words**: \n",
    "* **remove stopwords**: Grammatical words that carry no distinct meaning are removed, such as ```such```, ```as``` and ```and```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contribution statements\n",
    "The representation of a document as statements is among the potentially most significant forms of knowledge representations. Due tu the complexity, **SWIM currently includes no statement extraction module**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Evaluate\n",
    "|Step|Result|Requirement|\n",
    ":----|:----|:----|\n",
    "|Remove out-of-scope document subset|in-scope document set|43. define in-/exclusion criteria<br>44. exclude documents|\n",
    "|Evaluate relevancy measurement|selection approval|45. evaluate similarity of documents<br>46. evaluate relevance of documents|\n",
    "|Classify document subsets|literature subsets|47. define thresholds<br>48. divide document set into subsets|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove out-of-scope document subset\n",
    "**Requirements:**\n",
    "* define in-/exclusion criteria\n",
    "* exclude documents\n",
    "\n",
    "While formally each exclusion criteria could be rephrased as an inclusion criteria, their nature is different:\n",
    "* **Inclusion criteria** are defined *a priori* and designate which documents *can* be significant to answer the research question. They are derived from the research question scope. They aim to increase feasability.\n",
    "    * e.g. publicated between YYYY and XXXX\n",
    "* **Exclusion criteria** are defined *a posteriori* and designate which documents *will not* be evaluated to anser the research question. They narrow down the research question's scope. They aim to increase quality.\n",
    "    * e.g. without a scientific evaluation\n",
    "\n",
    "The exclusion can be semi-automated, while certain criteria will most likely take effect during the later manual review of remaining papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate relevancy measurement\n",
    "**Requirements:**\n",
    "* evaluate similarity of documents\n",
    "* evaluate relevance of documents\n",
    "\n",
    "Works can be pre-evaluated according to their allignment with the research question via the keywords. This means that the researcher can begin with works that are statistically more likely to be relevant to the research questions, and can gradually work down until all research questions are satisfied. Due to each RQ having their own set of keywords, the calculation of significance can be adjusted throughout the survey process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RQ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify document subsets\n",
    "**Requirements:**\n",
    "* define thresholds\n",
    "* divide document set into subsets\n",
    "\n",
    "With the metrics established in this stage, a final classification of the document set is possible. Similar to the in-/exclusion criteria, this classification functions as a soft criteria, specifying the conditions to evaluate a given document. By using certain **thresholds** over the document relevancy, the document set is divided into subsets that *must (M)*, *should (S)*, *could (C)* and *won't (W)* be considered. Unlike hard criteria, these are guidelines and aim as a decision support to which works to prioritise.\n",
    "\n",
    "Giving an example:\n",
    "* Documents *must* be evaluated if their relevancy score is above 75 % (M=.75), they have been published within the last year or in a Q1/A venue.\n",
    "* Documents *should* be evaluated if their relevancy score is above 50 % (S=.50) or they have been published within the last 3 years.\n",
    "* Documents *could* be evaluated if their relevancy score is above 25 % (C=.25) or below 5 % (W=.05).\n",
    "* Documents *won't* be evaluated if their relevancy score is above 5 % (W=.05).\n",
    "\n",
    "*Note*:\n",
    "* These are *soft* criteria and to be percievved as guidelines.\n",
    "* Relevancy scores of 0 and below the *W* threshold are percieved as errors and move up to *C*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
