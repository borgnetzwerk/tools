{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List\n",
    "import csv\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, title: str = None, total_time: float = None, members: List[str] = None):\n",
    "        self.total_time = total_time\n",
    "        self.title = title\n",
    "        self.members = members if members is not None else []\n",
    "    \n",
    "    def __str__(self):\n",
    "        members_str = \", \".join(self.members)\n",
    "        res = f\"Group time: \"\n",
    "        if self.title:\n",
    "            res += f\"{self.title}: \"\n",
    "        res += f\"{self.total_time}\\n\"\n",
    "        if sum([int(member) for member in self.members if member != '']) > 0:\n",
    "            res += f\"Members: {members_str}\\n\"\n",
    "        return res\n",
    "\n",
    "class Time:\n",
    "    def __init__(self, total_time: float = None, groups: List[Group] = None):\n",
    "        self.total_time = total_time\n",
    "        self.groups = groups if groups is not None else []\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Total time: {self.total_time}\\nGroups:\\n{''.join([str(group) for group in self.groups])}\"\n",
    "    \n",
    "    def get_publishable_results(self):\n",
    "        return f\"#### Time:\\nTotal time: {self.total_time}\\nGroups:\\n{''.join([str(group) for group in self.groups])}\"\n",
    "\n",
    "\n",
    "class Reply:\n",
    "    def __init__(self, row, survey:Survey = None):\n",
    "        index = 0\n",
    "        index_dict_iterator = iter(survey.index_dict)\n",
    "\n",
    "        # # print newline separated entire row\n",
    "        # for i in range(len(row)):\n",
    "        #     print(f\"{i}: {row[i]} ({survey.labels[i]})\")\n",
    "        \n",
    "        section = next(index_dict_iterator)     # section = 'metadata'\n",
    "        members = survey.index_dict[section]    # members = ['Response ID', ...]\n",
    "        member_iterator = iter(members)         # member_iterator = iter(['Response ID', ...])\n",
    "        end = index + len(members)\n",
    "        while index < end:\n",
    "            key = next(member_iterator)       # value = 'Response ID'\n",
    "            value = row[index]\n",
    "            if key in survey.answer_code_dict:\n",
    "                if value in survey.answer_code_dict[key]:\n",
    "                    value = survey.answer_code_dict[key][value]\n",
    "            if key == \"Response ID\":\n",
    "                self.response_id = value\n",
    "            elif key == \"Date submitted\":\n",
    "                self.date_submitted = value\n",
    "            elif key == \"Last page\":\n",
    "                self.last_page = value\n",
    "            elif key == \"Start language\":\n",
    "                self.start_language = value\n",
    "            elif key == \"Seed\":\n",
    "                self.seed = value\n",
    "            elif key == \"Date started\":\n",
    "                self.date_started = value\n",
    "            elif key == \"Date last action\":\n",
    "                self.date_last_action = value\n",
    "            elif key == \"Referrer URL\":\n",
    "                self.referrer_url = value\n",
    "            elif key == \"tool\" or key == \"tool_other\":\n",
    "                # check if self.tool exists. If not, create it as row[index]\n",
    "                if not hasattr(self, \"tool\"):\n",
    "                    self.tool = value\n",
    "                elif self.tool == \"-oth-\":\n",
    "                    self.tool = value\n",
    "            index += 1\n",
    "\n",
    "        self.scores = []\n",
    "\n",
    "        section = next(index_dict_iterator)     # section = 'requirements'\n",
    "        members = survey.index_dict[section]    # members = [1, 2, ...]\n",
    "        end = index + len(members)\n",
    "        while index < end:\n",
    "            self.scores.append(row[index])\n",
    "            index += 1\n",
    "\n",
    "        section = next(index_dict_iterator)     # section = 'requirements'\n",
    "        members = survey.index_dict[section]    # members = ['age', 'education', ...]\n",
    "        member_iterator = iter(members)         # member_iterator = iter(['Response ID', ...])\n",
    "        end = index + len(members)\n",
    "        while index < end:\n",
    "            key = str(next(member_iterator))  # value = 'Response ID'\n",
    "            value = row[index]\n",
    "            if key in survey.answer_code_dict:\n",
    "                if value in survey.answer_code_dict[key]:\n",
    "                    value = survey.answer_code_dict[key][value]\n",
    "            if key == \"age\":\n",
    "                self.age = value\n",
    "            elif key == \"education\" or key == \"education_other\":\n",
    "                # check if self.tool exists. If not, create it as row[index]\n",
    "                if not hasattr(self, \"education\"):\n",
    "                    self.education = value\n",
    "                elif  self.education == \"-oth-\":\n",
    "                    self.education = value\n",
    "            elif key == \"survey_count\":\n",
    "                self.survey_count = value\n",
    "            elif key == \"experience\":\n",
    "                self.experience = value\n",
    "            elif key == \"comments\":\n",
    "                self.comments = value\n",
    "            index += 1\n",
    "\n",
    "        # the time is an object and holds nested values for the 10 groups\n",
    "        self.time = Time()\n",
    "        self.time.total_time = row[index]\n",
    "        index += 1\n",
    "\n",
    "        # iterate over groups\n",
    "        while index < len(row)-1:\n",
    "            if survey.labels[index].startswith(\"Group time:\"):\n",
    "                title = survey.labels[index].replace(\"Group time: \", \"\")\n",
    "                self.time.groups.append(Group(title))\n",
    "                self.time.groups[-1].total_time = row[index]\n",
    "            else:\n",
    "                self.time.groups[-1].members.append(row[index])\n",
    "            index += 1\n",
    "\n",
    "        # check for reported errors\n",
    "        self.check_reported_errors()\n",
    "        \n",
    "    def __str__(self):\n",
    "        res = f\"Reply: {self.response_id}\\nDate submitted: {self.date_submitted}\\nLast page: {self.last_page}\\nStart language: {self.start_language}\\nSeed: {self.seed}\\nDate started: {self.date_started}\\nDate last action: {self.date_last_action}\\nRefer0rer URL: {self.referrer_url}\\n\"\n",
    "        if hasattr(self, \"tool\"):\n",
    "            res += f\"Tool: {self.tool}\\n\"\n",
    "        res += f\"Scores: {self.scores}\\nAge: {self.age}\\nEducation: {self.education}\\nSurvey count: {self.survey_count}\\nExperience: {self.experience}\\nComments: {self.comments}\\n\"\n",
    "        res += f\"{self.time}\\n\"\n",
    "        return res\n",
    "    \n",
    "    def check_reported_errors(self):\n",
    "        if hasattr(self, \"tool\"):\n",
    "            if self.tool == \"-oth-\" or self.tool == \"\":\n",
    "                print(f\"Error: {self.response_id} reported tool as other, but did not specify the tool.\")\n",
    "        if hasattr(self, \"education\"):\n",
    "            if self.education == \"-oth-\" or self.education == \"\":\n",
    "                print(f\"Error: {self.response_id} reported education as other, but did not specify the education.\")\n",
    "        # A respondent reported to have accidentally selected the wrong tool when actually evaluating the \"SWARM-SLR 2024-01\".\n",
    "        # They reported on 2024-01-15 to have submitted late friday morning on the 2024-01-12.\n",
    "        # A response fitting their described time, time taken, tool selection etc. was found and and the exact submission time was reported to them: 2024-01-12 10:27:21.\n",
    "        # They confirmed that this was their response.\n",
    "        # This specific response is hence updated to reflect the correct tool.\n",
    "        if self.date_submitted == \"2024-01-12 10:27:21\":\n",
    "            self.tool = \"SWARM-SLR 2024-01\"\n",
    "\n",
    "        # Once this issue was known, the channels used to communicated the survey were informed to check if they had made the same error.\n",
    "        # Indicators are a total time exceeding 20 minutes and especially comments referencing the \"approach\"/\"method\" or \"SWARM-SLR\"\n",
    "            \n",
    "        # One other response reported the same issue.\n",
    "        # They reported their time, tool selection and demographic data, which mapped to the response with the submission time 2024-01-12 12:25:56.\n",
    "        # This specific response is hence updated to reflect the correct tool.\n",
    "        if self.date_submitted == \"2024-01-12 12:25:56\":\n",
    "            self.tool = \"SWARM-SLR 2024-01\"\n",
    "\n",
    "        \n",
    "        # In the meantime, a hint is presented, identifying unconfirmed surveys taking more than 20 minutes, without referring to \"SWARM-SLR\"\n",
    "        # IDs confirmed are excluded\n",
    "        confiremd_ids = [\n",
    "            21,             # Submitted 2023, before the SWARM-SLR toolset was proposed\n",
    "            31,             # Submitted 2023, before the SWARM-SLR toolset was proposed\n",
    "            # 42,           # Hint: 42 took 21 minutes and might have selected the wrong tool (Zotero).\n",
    "            # 58,           # Hint: 58 took 72 minutes and might have selected the wrong tool (Zotero).\n",
    "        ]\n",
    "        if float(self.time.total_time) > 1200:\n",
    "            if int(self.response_id) not in confiremd_ids:\n",
    "                if hasattr(self, \"tool\") and not \"SWARM-SLR\" in self.tool:\n",
    "                    print(f\"Hint: {self.response_id} took {round(float(self.time.total_time)/60)} minutes and might have selected the wrong tool ({self.tool}).\")\n",
    "    \n",
    "    def get_publishable_results(self):\n",
    "        res = f\"### Response ID: {self.response_id}\\n\"\n",
    "        if hasattr(self, \"tool\"):\n",
    "            res += f\"#### Tool: {self.tool}\\n\"\n",
    "        res += f\"#### Scores:\\n{self.scores}\\n\"\n",
    "        res += f\"{self.time.get_publishable_results()}\\n\"\n",
    "        return res\n",
    "\n",
    "def remove_rogue_linebreaks(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    current_line = \"\"\n",
    "    for line in lines:\n",
    "        current_line += line.strip()\n",
    "        if current_line.count('\"') % 2 == 0:  # if count of \" is even\n",
    "            new_lines.append(current_line)\n",
    "            current_line = \"\"\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write('\\n'.join(new_lines))\n",
    "\n",
    "class Survey:\n",
    "    # different types of survey, with different selection_last_index and deletions\n",
    "    types = {\n",
    "        \"default\": {\n",
    "            \"index_dict\": {\n",
    "                \"metadata\": [\n",
    "                    \"Response ID\",\n",
    "                    \"Date submitted\",\n",
    "                    \"Last page\",\n",
    "                    \"Start language\",\n",
    "                    \"Seed\",\n",
    "                    \"Date started\",\n",
    "                    \"Date last action\",\n",
    "                    \"Referrer URL\",\n",
    "                ],\n",
    "                \"requirements\" : [i for i in range(65)],\n",
    "                \"demographics\": [\n",
    "                    \"age\",\n",
    "                    \"education\",\n",
    "                    \"education_other\",\n",
    "                    \"survey_count\",\n",
    "                    \"experience\",\n",
    "                    \"comments\",\n",
    "                ],\n",
    "                \"time\" : -1,\n",
    "            },\n",
    "            \"deletions\": [],\n",
    "            \"expected_last_page\": \"10\",\n",
    "        },\n",
    "        \"555283\": {\n",
    "            \"index_dict\": {\n",
    "                \"metadata\": [\n",
    "                    \"Response ID\",\n",
    "                    \"Date submitted\",\n",
    "                    \"Last page\",\n",
    "                    \"Start language\",\n",
    "                    \"Seed\",\n",
    "                    \"Date started\",\n",
    "                    \"Date last action\",\n",
    "                    \"Referrer URL\",\n",
    "                ],\n",
    "                \"requirements\" : [i for i in range(65)],\n",
    "                \"demographics\": [\n",
    "                    \"age\",\n",
    "                    \"education\",\n",
    "                    \"education_other\",\n",
    "                    \"survey_count\",\n",
    "                    \"experience\",\n",
    "                    \"comments\",\n",
    "                ],\n",
    "                \"time\" : -1,\n",
    "            },\n",
    "            \"answer_code_dict\": {\n",
    "                \"tool\": {\n",
    "                    \"A1\": \"CADIMA\",\n",
    "                    \"A2\": \"Large Language Models (LLM) like ChatGPT, Bing\",\n",
    "                    \"A3\": \"Open Research Knowledge Graph (ORKG)\",\n",
    "                    \"A4\": \"Google Scholar\",\n",
    "                    \"A5\": \"Semantic Scholar\",\n",
    "                    \"A6\": \"Open Knowledge Maps (OKMaps)\",\n",
    "                    \"A7\": \"ConnectedPapers\",\n",
    "                    \"A8\": \"Python\",\n",
    "                    \"A9\": \"Natural Language Processing (NLP) libraries like NLTK, spaCy, FLAIR\",\n",
    "                    \"A10\": \"PDF miners like pdfminer, pypdf2\",\n",
    "                    \"A11\": \"Zotero\",\n",
    "                    \"A12\": \"LaTeX\",\n",
    "                    \"A13\": \"SciKGTeX\",\n",
    "                    \"A14\": \"Colandr\",\n",
    "                    \"A15\": \"Cochrane RevMan\",\n",
    "                    \"A16\": \"covidence\",\n",
    "                    \"A17\": \"rayyan\",\n",
    "                    \"A18\": \"Health Assessment Workspace Collaborative (HAWC) Project\",\n",
    "                    \"A19\": \"metagear\",\n",
    "                    \"A20\": \"Parsifal\",\n",
    "                    \"A21\": \"Systematic Review Data Repository Plus (SRDR+)\",\n",
    "                    \"A22\": \"Sciome\",\n",
    "                    \"A23\": \"Systematic Review Facility (SyRF)\",\n",
    "                    \"A24\": \"interactive Summary of Findings (iSoF)\",\n",
    "                    \"A25\": \"ReLiS\",\n",
    "                    \"A26\": \"SESRA\",\n",
    "                    \"A27\": \"Right Review\",\n",
    "                    \"A28\": \"JBI SUMARI\",\n",
    "                    \"A29\": \"Research Rabbit\",\n",
    "                },\n",
    "                \"education\": {\n",
    "                    \"A1\": \"not yet graduated high school\",\n",
    "                    \"A2\": \"High school\",\n",
    "                    \"A3\": \"Trade school\",\n",
    "                    \"A4\": \"Bachelor’s degree\",\n",
    "                    \"A5\": \"Master’s degree\",\n",
    "                    \"A6\": \"Ph.D. or higher\",\n",
    "                    \"A7\": \"Prefer not to say\",\n",
    "                },\n",
    "                \"survey_count\": {\n",
    "                    \"A1\": \"None\",\n",
    "                    \"A2\": \"1\",\n",
    "                    \"A3\": \"2-3\",\n",
    "                    \"A4\": \"4-5\",\n",
    "                    \"A5\": \"More than 5\",\n",
    "                },\n",
    "                \"experience\": {\n",
    "                    \"A1\": \"Poor\",\n",
    "                    \"A2\": \"Fair\",\n",
    "                    \"A3\": \"Good\",\n",
    "                    \"A4\": \"Very good\",\n",
    "                    \"A5\": \"Excellent\",\n",
    "                },\n",
    "            },\n",
    "            \"deletions\": [51, 56],\n",
    "            \"expected_last_page\": \"10\",\n",
    "        },\n",
    "        \"628237\": {\n",
    "            \"index_dict\": {\n",
    "                \"metadata\": [\n",
    "                    \"Response ID\",\n",
    "                    \"Date submitted\",\n",
    "                    \"Last page\",\n",
    "                    \"Start language\",\n",
    "                    \"Seed\",\n",
    "                    \"Date started\",\n",
    "                    \"Date last action\",\n",
    "                    \"Referrer URL\",\n",
    "                    \"tool\",\n",
    "                    \"tool_other\"\n",
    "                ],\n",
    "                \"requirements\" : [i for i in range(65)],\n",
    "                \"demographics\": [\n",
    "                    \"age\",\n",
    "                    \"education\",\n",
    "                    \"education_other\",\n",
    "                    \"survey_count\",\n",
    "                    \"experience\",\n",
    "                    \"comments\",\n",
    "                ],\n",
    "                \"time\" : -1,\n",
    "            },\n",
    "            \"answer_code_dict\": {\n",
    "                \"tool\": {\n",
    "                    \"A1\": \"CADIMA\",\n",
    "                    \"A2\": \"Large Language Models (LLM) like ChatGPT, Bing\",\n",
    "                    \"A3\": \"Open Research Knowledge Graph (ORKG)\",\n",
    "                    \"A4\": \"Google Scholar\",\n",
    "                    \"A5\": \"Semantic Scholar\",\n",
    "                    \"A6\": \"Open Knowledge Maps (OKMaps)\",\n",
    "                    \"A7\": \"ConnectedPapers\",\n",
    "                    \"A8\": \"Python\",\n",
    "                    \"A9\": \"Natural Language Processing (NLP) libraries like NLTK, spaCy, FLAIR\",\n",
    "                    \"A10\": \"PDF miners like pdfminer, pypdf2\",\n",
    "                    \"A11\": \"Zotero\",\n",
    "                    \"A12\": \"LaTeX\",\n",
    "                    \"A13\": \"SciKGTeX\",\n",
    "                    \"A14\": \"Colandr\",\n",
    "                    \"A15\": \"Cochrane RevMan\",\n",
    "                    \"A16\": \"covidence\",\n",
    "                    \"A17\": \"rayyan\",\n",
    "                    \"A18\": \"Health Assessment Workspace Collaborative (HAWC) Project\",\n",
    "                    \"A19\": \"metagear\",\n",
    "                    \"A20\": \"Parsifal\",\n",
    "                    \"A21\": \"Systematic Review Data Repository Plus (SRDR+)\",\n",
    "                    \"A22\": \"Sciome\",\n",
    "                    \"A23\": \"Systematic Review Facility (SyRF)\",\n",
    "                    \"A24\": \"interactive Summary of Findings (iSoF)\",\n",
    "                    \"A25\": \"ReLiS\",\n",
    "                    \"A26\": \"SESRA\",\n",
    "                    \"A27\": \"Right Review\",\n",
    "                    \"A28\": \"JBI SUMARI\",\n",
    "                    \"A29\": \"Research Rabbit\",\n",
    "                },\n",
    "                \"education\": {\n",
    "                    \"A1\": \"not yet graduated high school\",\n",
    "                    \"A2\": \"High school\",\n",
    "                    \"A3\": \"Trade school\",\n",
    "                    \"A4\": \"Bachelor’s degree\",\n",
    "                    \"A5\": \"Master’s degree\",\n",
    "                    \"A6\": \"Ph.D. or higher\",\n",
    "                    \"A7\": \"Prefer not to say\",\n",
    "                },\n",
    "                \"survey_count\": {\n",
    "                    \"A1\": \"None\",\n",
    "                    \"A2\": \"1\",\n",
    "                    \"A3\": \"2-3\",\n",
    "                    \"A4\": \"4-5\",\n",
    "                    \"A5\": \"More than 5\",\n",
    "                },\n",
    "                \"experience\": {\n",
    "                    \"A1\": \"Poor\",\n",
    "                    \"A2\": \"Fair\",\n",
    "                    \"A3\": \"Good\",\n",
    "                    \"A4\": \"Very good\",\n",
    "                    \"A5\": \"Excellent\",\n",
    "                },\n",
    "            },\n",
    "            \"deletions\": [53, 58],\n",
    "            \"expected_last_page\": \"11\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # initialize survey\n",
    "    def __init__(self, labels: List[str] = None, replies: List[Reply] = None, type: str = \"default\", csv_file: str = None):\n",
    "        self.labels = labels if labels is not None else []\n",
    "        self.replies = replies if replies is not None else []\n",
    "        # dict of indexes of each section\n",
    "        self.index_dict = {}\n",
    "        self.deletions = []\n",
    "        self.expected_last_page = None\n",
    "\n",
    "        if csv_file is not None:\n",
    "            self.init_from_csv(csv_file, type)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Type: {self.type}\\nLabels: {self.labels}\\nReplies: {''.join([str(reply) for reply in self.replies])}\"\n",
    "    \n",
    "    def get_publishable_results(self):\n",
    "        res = f\"# survey-{self.type}\\n\"\n",
    "        # labels_str = '\\n'.join(self.labels) + \"\\n\"\n",
    "        # res += f\"## Labels:\\n{labels_str}\\n\"\n",
    "        res += f\"## Replies:\\n{''.join([reply.get_publishable_results() for reply in self.replies])}\"\n",
    "        return res\n",
    "    \n",
    "    def get(self, key: str = \"self\"):\n",
    "        if key == \"self\":\n",
    "            return self\n",
    "        elif key == \"labels\":\n",
    "            return self.labels\n",
    "        elif key == \"replies\":\n",
    "            return self.replies\n",
    "        elif key == \"index_dict\":\n",
    "            return self.index_dict\n",
    "        elif key == \"deletions\":\n",
    "            return self.deletions\n",
    "        elif key == \"expected_last_page\":\n",
    "            return self.expected_last_page\n",
    "        elif key == \"answer_code_dict\":\n",
    "            return self.answer_code_dict\n",
    "        elif key == \"viewed_counter\":\n",
    "            return self.viewed_counter\n",
    "        elif key == \"started_counter\":\n",
    "            return self.started_counter\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # init from csv file\n",
    "    def init_from_csv(self, csv_file: str, type: str = \"default\"):\n",
    "        remove_rogue_linebreaks(csv_file)\n",
    "\n",
    "        self.type = type\n",
    "        self.index_dict = self.types[type][\"index_dict\"]\n",
    "        self.deletions = sorted(self.types[type][\"deletions\"], reverse=True)\n",
    "        expected_last_page = self.types[type][\"expected_last_page\"]\n",
    "        self.answer_code_dict = self.types[type][\"answer_code_dict\"]\n",
    "        self.viewed_counter = 0\n",
    "        self.started_counter = 0\n",
    "\n",
    "        with open(csv_file, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "\n",
    "            self.labels = next(csv_reader)\n",
    "            for i in self.deletions:\n",
    "                del self.labels[i]\n",
    "                \n",
    "            rows = []\n",
    "\n",
    "            for row in csv_reader:\n",
    "                # delete all columns that are not needed\n",
    "                if row:\n",
    "                    for i in self.deletions:\n",
    "                        del row[i]\n",
    "                    rows.append(row)\n",
    "            \n",
    "            last_page_index = self.labels.index(\"Last page\")\n",
    "            self.viewed_counter = len(rows)\n",
    "\n",
    "            for i, row in enumerate(rows):\n",
    "                # Skip rows that did not complete the survey\n",
    "                if not row or row[last_page_index] != expected_last_page:\n",
    "                    if row[last_page_index]:\n",
    "                        # participants that started, but not finished the survey\n",
    "                        self.started_counter += 1\n",
    "                    continue\n",
    "                # participant has started and finished the survey\n",
    "                self.started_counter += 1\n",
    "                # Create a reply object\n",
    "                reply = Reply(row, self)\n",
    "\n",
    "                # Append the reply to the list of replies\n",
    "                self.replies.append(reply)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# Specify the folder where your CSV files are located\n",
    "bnw_data_path = os.path.join(\"c:\\\\\", \"workspace\", \"borgnetzwerk\", \"tools\", \"scripts\", \"SWARM-SLR\", \"data\")\n",
    "folder_path = os.path.join(\"c:\\\\\", \"workspace\", \"surveys\")\n",
    "\n",
    "# Create a pattern to match files starting with \"results-survey\" and ending with \".csv\"\n",
    "file_pattern = os.path.join(folder_path, 'results-survey*.csv')\n",
    "\n",
    "# Get a list of file paths matching the pattern\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "surveys:List[Survey] = []\n",
    "\n",
    "# Iterate through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # print(f\"Reading data from file: {csv_file}\")\n",
    "    filename = os.path.basename(csv_file)\n",
    "    type = filename.split(\"results-survey\")[1].split(\".csv\")[0]\n",
    "    surveys.append(Survey(csv_file=csv_file, type=type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code cemetary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to create a 2D line with markers plot\n",
    "def plot_2d(replies):\n",
    "    font = {'size'   : 4}\n",
    "    # plt.minorticks_on()\n",
    "\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "    c = [\"#FF7F0E\",\"#FFBB78\",\"#FFBB78\",\"white\",\"#AEC7E8\",\"#AEC7E8\",\"#1F77B4\"]\n",
    "    v = [0,.175,.4,.5,0.6,.825,1.]\n",
    "    l = list(zip(v,c))\n",
    "\n",
    "    cmap=LinearSegmentedColormap.from_list('rg',l, N=256)\n",
    "\n",
    "    agreement = [\"strongly agree\", \"agree\", \"neither agree\\nnor disagree\", \"disagree\", \"strongly disagree\"]\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=300, figsize=(30, 1))\n",
    "    plotlim = plt.xlim(0,len(replies[0].scores)+1) + plt.ylim(10,0)  \n",
    "\n",
    "    ax.imshow([[0.5,0.5],[0,0]], cmap=cmap, interpolation='bicubic', extent=plotlim)  \n",
    "    \n",
    "    ax.set_ylabel('agreement with requirement')\n",
    "    # set the x ticks from 1 to 9\n",
    "    # ax.set_yticks(range(1,10))\n",
    "    ax.set_yticks([1, 3, 5, 7, 9])\n",
    "    ax.set_yticklabels(agreement)\n",
    "\n",
    "    ax.set_xlabel('SLR-tool requirement')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "\n",
    "\n",
    "    labels = labels_for_box_plot(replies[0].scores)\n",
    "   \n",
    "    for reply in replies:\n",
    "        ax.plot([i+1 for i in range(len(reply.scores))], reply.scores, label=reply.tool)\n",
    "    ax.set_title(f\"Tool Assisted Literature Surveys - A Tool Review\")\n",
    "    ax.set_xlabel(\"Requirement\")\n",
    "    ax.set_ylabel(\"Fulfillment of Requirement\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_grouped_bar(replies):\n",
    "    labels = labels_for_box_plot(replies[0].scores)\n",
    "    num_requirements = len(replies[0].scores)\n",
    "    num_replies = len(replies)\n",
    "    x = np.arange(num_requirements)  # the label locations\n",
    "    width = 0.8 / num_replies  # the width of the bars\n",
    "\n",
    "    plt.figure()\n",
    "    for i, reply in enumerate(replies):\n",
    "        plt.bar(x - width/2 + i*width, reply.scores, width, label=reply.tool)\n",
    "\n",
    "    plt.title(f\"Tool Assisted Literature Surveys - A Tool Review\")\n",
    "    plt.xlabel(\"Requirement\")\n",
    "    plt.ylabel(\"Fulfillment of Requirement\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey in surveys:\n",
    "    filename = os.path.join(folder_path, \"analysis\" + survey.type + \".txt\")\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(str(survey))\n",
    "    publish_filename = os.path.join(bnw_data_path, \"analysis\" + survey.type + \".md\")\n",
    "    with open(publish_filename, 'w') as file:\n",
    "        file.write(survey.get_publishable_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_box_plot(replies:List[Reply], vert=True, title=\"\"):\n",
    "    title = title if title else \"Boxplot\"\n",
    "    if title == \"tool\":\n",
    "        title = replies[0].tool\n",
    "    elif title == \"tools\":\n",
    "        title = 'Tool Assisted Literature Surveys - A Tool Review'\n",
    "    elif title == \"requirements\":\n",
    "        title = 'Tool Assisted Literature Surveys - A Requirements Review'\n",
    "\n",
    "    data = []\n",
    "    for reply in replies:\n",
    "        data_for_box_plot(data, reply)\n",
    "    labels = labels_for_box_plot(data=data)\n",
    "    font = {'size'   : 4}\n",
    "    # plt.minorticks_on()\n",
    "\n",
    "\n",
    "    plt.rc('font', **font)\n",
    "    c = [\"#FF7F0E\",\"#FFBB78\",\"#FFBB78\",\"white\",\"#AEC7E8\",\"#AEC7E8\",\"#1F77B4\"]\n",
    "    v = [0,.175,.4,.5,0.6,.825,1.]\n",
    "    l = list(zip(v,c))\n",
    "\n",
    "    cmap=LinearSegmentedColormap.from_list('rg',l, N=256)\n",
    "\n",
    "    # agreement = [\"strongly agree\", \"\", \"agree\", \"\", \"neither agree\\nnor disagree\", \"\", \"disagree\", \"\", \"strongly disagree\"]\n",
    "    agreement = [\"strongly agree\", \"agree\", \"neither agree\\nnor disagree\", \"disagree\", \"strongly disagree\"]\n",
    "\n",
    "    if vert:\n",
    "        fig, ax = plt.subplots(dpi=300, figsize=(30, 1))\n",
    "        plotlim = plt.xlim(0,len(data)+1) + plt.ylim(10,0)  \n",
    "\n",
    "        ax.imshow([[0.5,0.5],[0,0]], cmap=cmap, interpolation='bicubic', extent=plotlim)  \n",
    "        \n",
    "        ax.set_ylabel('agreement with requirement')\n",
    "        # set the x ticks from 1 to 9\n",
    "        # ax.set_yticks(range(1,10))\n",
    "        ax.set_yticks([1, 3, 5, 7, 9])\n",
    "        ax.set_yticklabels(agreement)\n",
    "\n",
    "        ax.set_xlabel('SLR-tool requirement')\n",
    "        plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "\n",
    "    else:\n",
    "        fig, ax = plt.subplots(dpi=300, figsize=(1, 30))\n",
    "        plotlim = plt.xlim(1,9) + plt.ylim(len(data),0)  \n",
    "\n",
    "        ax.imshow([[1,0],[1,0]], cmap=cmap, interpolation='bicubic', extent=plotlim)  \n",
    "      \n",
    "        ax.set_xlabel('Values')\n",
    "\n",
    "        ax.set_ylabel('Requirement')\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    flierprops = dict(marker='o', markerfacecolor='none', markersize=2,\n",
    "                  linestyle='none', markeredgecolor='black', markeredgewidth=0.5)\n",
    "\n",
    "    ax.boxplot(data, vert=vert, labels=labels, flierprops=flierprops)\n",
    "\n",
    "\n",
    "    # ax.legend(labels, title='Categories', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.show()\n",
    "    path = os.path.join(bnw_data_path, \"visualization\", title + '.png')\n",
    "    fig.savefig(path, bbox_inches='tight')\n",
    "    path = os.path.join(bnw_data_path, \"visualization\", title + '.svg')\n",
    "    fig.savefig(path, bbox_inches='tight')\n",
    "\n",
    "def data_for_box_plot(data, reply:Reply = None):\n",
    "    for i, score in enumerate(reply.scores):\n",
    "        res = None\n",
    "        if score:\n",
    "            res = int(score[1:])\n",
    "            # max score is 9. If score is 10, it means the user did not answer the question\n",
    "            if res == 10:\n",
    "                res = None\n",
    "        if i >= len(data):\n",
    "            data.append([])\n",
    "        if res:\n",
    "            data[i].append(res)\n",
    "    return data\n",
    "\n",
    "def labels_for_box_plot(data:List = None, labels:List[str] = None, reply:Reply = None):\n",
    "    labels = [] if labels is None else labels\n",
    "    if not labels:\n",
    "        for i in range(len(data)):\n",
    "            labels.append(f\"R{i+1}\")\n",
    "    return labels\n",
    "\n",
    "# def is_invalid(reply:Reply):\n",
    "def is_invalid(reply:Reply):\n",
    "    # it is unrealistic to expect a minor to have experience on SLR\n",
    "    if reply.age and int(reply.age) < 18:\n",
    "        print(f\"Reply {reply.response_id} is invalid because age is {reply.age}\")\n",
    "        return True\n",
    "    # it is unrealistic to finish the survey in less than 60 seconds\n",
    "    if float(reply.time.total_time) < 60:\n",
    "        print(f\"Reply {reply.response_id} is invalid because total time is {reply.time.total_time}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for survey in surveys:\n",
    "    # labels = survey.labels\n",
    "    if survey.type == \"555283\":\n",
    "        # Requirements survey. all we need is one big graphic.\n",
    "        valid = []\n",
    "        for reply in survey.replies:\n",
    "            if is_invalid(reply):\n",
    "                continue\n",
    "            valid.append(reply)\n",
    "            \n",
    "        print(f\"Survey {survey.type} was viewed by {survey.viewed_counter} people.\")\n",
    "        print(f\"Survey {survey.type} has been started by {survey.started_counter} people.\")\n",
    "        print(f\"Survey {survey.type} has been completed by {len(survey.replies)} respondents.\")\n",
    "        print(f\"Survey {survey.type} has {len(valid)} valid and {len(survey.replies) - len(valid)} invalid replies.\")\n",
    "        create_box_plot(valid, title=\"requirements\")\n",
    "        continue\n",
    "    elif survey.type == \"628237\":\n",
    "        data = []\n",
    "        valid = []\n",
    "        tool_dict = {}\n",
    "        for reply in survey.replies:\n",
    "            if is_invalid(reply):\n",
    "                continue\n",
    "            if reply.tool not in tool_dict:\n",
    "                tool_dict[reply.tool] = []\n",
    "            tool_dict[reply.tool].append(reply)\n",
    "            valid.append(reply)\n",
    "\n",
    "        multiple_replies = []\n",
    "        multiple_replies_count = 0\n",
    "        swarm_slr_replies = []\n",
    "        for tool, replies in tool_dict.items():\n",
    "            if len(replies) > 1:\n",
    "                multiple_replies += replies\n",
    "                multiple_replies_count += 1\n",
    "            if \"SWARM-SLR\" in tool:\n",
    "                swarm_slr_replies += replies\n",
    "                \n",
    "        # calculate the average time for SWARM-SLR\n",
    "        time_taken = [float(reply.time.total_time) for reply in swarm_slr_replies]\n",
    "        total_time = sum(time_taken)\n",
    "        average_time = total_time / len(time_taken)\n",
    "        total_time_minutes = round(total_time / 60)\n",
    "        average_time_minutes = round(average_time / 60)\n",
    "\n",
    "        print(f\"Survey {survey.type} was viewed by {survey.viewed_counter} people.\")\n",
    "        print(f\"Survey {survey.type} has been started by {survey.started_counter} people.\")\n",
    "        print(f\"Survey {survey.type} has been completed by {len(survey.replies)} respondents.\")\n",
    "        print(f\"Survey {survey.type} has {len(valid)} valid and {len(survey.replies) - len(valid)} invalid replies.\")\n",
    "        print(f\"{len(tool_dict)} tools have been evaluated, {multiple_replies_count} of them by multiple replies.\")\n",
    "        print()\n",
    "        print(f\"SWARM-SLR has been evaluated by {len(swarm_slr_replies)} replies.\")\n",
    "        print(f\"SWARM-SLR has been evaluated for {average_time_minutes} minutes on average ({', '.join([str(round(t/60)) for t in time_taken])}).\")\n",
    "\n",
    "        for tool, replies in tool_dict.items():\n",
    "            create_box_plot(replies, title=\"tool\")\n",
    "        create_box_plot(valid, title=\"tools\")\n",
    "\n",
    "        create_box_plot(multiple_replies, title=\"Tools with multiple replies\")\n",
    "        # plot_2d(valid)\n",
    "        # plot_grouped_bar(valid)\n",
    "    else:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
