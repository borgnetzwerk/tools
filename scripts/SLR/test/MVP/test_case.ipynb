{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, for_git=True):\n",
    "        self.gap_too_large_threshold = 1000\n",
    "        self.savetime_on_fulltext = False   # If True, operations on fulltext will be kept to a minimum\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_function(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        appendix = \"\"\n",
    "        # if instances in args:\n",
    "        if \"instances\" in kwargs:\n",
    "            # append len of instances\n",
    "            appendix = f\"({len(kwargs['instances'])} instances\"\n",
    "        if \"papers\" in kwargs:\n",
    "            if appendix:\n",
    "                appendix += \", \"\n",
    "            appendix += f\"{len(kwargs['papers'])} papers\"\n",
    "        if appendix:\n",
    "            appendix += \")\"\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} executed in {end_time - start_time} seconds\" + appendix)\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string, delimiters = [\" \", \"-\", \"_\"]):\n",
    "    for delimiter in delimiters:\n",
    "        input_string = \" \".join(input_string.split(delimiter))\n",
    "    return input_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: find occurrences of instances in full text of papers\n",
    "import sys\n",
    "from bisect import bisect_left\n",
    "from sortedcontainers import SortedSet\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from collections import deque\n",
    "\n",
    "class PosInPaper:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.min_distances = {}\n",
    "        \"\"\"\n",
    "        Initialize the PosInPaper class with empty dictionaries for storing data and minimum distances.\n",
    "        \"\"\"\n",
    "\n",
    "    def save_to_file(self, path=None):\n",
    "        if path is None:\n",
    "            path = \"pos_in_paper\"\n",
    "        data_to_save = {paper: {literal: list(positions) for literal, positions in literals.items()}\n",
    "                        for paper, literals in self.data.items()}\n",
    "        with open(path + \".json\", 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(data_to_save, f, ensure_ascii=False)\n",
    "        data_to_save = {outer_key: {str(inner_key): value for inner_key, value in inner_dict.items()}\n",
    "                        for outer_key, inner_dict in self.min_distances.items()}\n",
    "\n",
    "        with open(path + \"_min_distances.json\", 'w', encoding=\"utf-8\") as f:\n",
    "            json.dump(data_to_save, f, ensure_ascii=False)\n",
    "\n",
    "    def load_from_file(self, path=None):\n",
    "        if path is None:\n",
    "            path = \"pos_in_paper\"\n",
    "        with open(path + \".json\", 'r', encoding=\"utf-8\") as f:\n",
    "            self.data = json.load(f)\n",
    "        with open(path + \"_min_distances.json\", 'r', encoding=\"utf-8\") as f:\n",
    "            min_distances_str_keys = json.load(f)\n",
    "            # Convert string keys back to frozensets\n",
    "            self.min_distances = {outer_key: {frozenset(eval(inner_key)): value for inner_key, value in inner_dict.items()}\n",
    "                                for outer_key, inner_dict in min_distances_str_keys.items()}\n",
    "        self.optimize_data()\n",
    "        \n",
    "    def add_occurrence(self, paper, literal, pos):\n",
    "        \"\"\"\n",
    "        Add an occurrence of a literal in a paper.\n",
    "\n",
    "        Parameters:\n",
    "        - paper (str): The identifier for the paper.\n",
    "        - literal (hashable): A literal that occurs in the paper. string or frozenset\n",
    "        - pos (int): The position of the literal's occurrence in the paper.\n",
    "        \"\"\"\n",
    "        if paper not in self.data:\n",
    "            self.data[paper] = {}\n",
    "        if literal not in self.data[paper]:\n",
    "            self.data[paper][literal] = []\n",
    "        self.data[paper][literal].append(pos)\n",
    "\n",
    "    def optimize_data(self):\n",
    "        \"\"\"\n",
    "        Optimize the data structure for memory efficiency.\n",
    "        \"\"\"\n",
    "        for paper in self.data:\n",
    "            for literal, positions in self.data[paper].items():\n",
    "                # self.data[paper][literal] = np.array(self.data[paper][literal], dtype=int)\n",
    "                self.data[paper][literal] = SortedSet(positions)\n",
    "\n",
    "    @time_function\n",
    "    def find(self, config:Config, papers, paper_full_text, instances, paper_instance_occurrence_matrix):\n",
    "        \"\"\"\n",
    "        Find all occurrences of instances in the full text of papers.\n",
    "\n",
    "        Parameters:\n",
    "        - config (Config): Configuration object with settings.\n",
    "        - papers (list): A list of paper identifiers.\n",
    "        - paper_full_text (dict): A mapping from paper identifiers to their full text file paths.\n",
    "        - instances (list): A list of instances to find in the papers.\n",
    "        - paper_instance_occurrence_matrix (list of lists): A matrix indicating whether an instance is in a paper.\n",
    "        \"\"\"\n",
    "        # find all occurrences of instances in text files\n",
    "        for paperID, paper in enumerate(papers):\n",
    "            if paperID % 100 == 0:\n",
    "                # print(f\"Processing paper {paperID} of {len(papers)}\")\n",
    "                pass\n",
    "            if paper in paper_full_text:\n",
    "                # Full text of paper is available\n",
    "                with open(paper_full_text[paper], 'r', encoding=\"utf8\") as f:\n",
    "                    text = f.read().lower()\n",
    "                    for i, instance in enumerate(instances):\n",
    "                        # if this instance is not in this document, move on.\n",
    "                        if config.savetime_on_fulltext:\n",
    "                            if not paper_instance_occurrence_matrix[paperID][i]:\n",
    "                                # assume instance is not in this paper\n",
    "                                continue\n",
    "                            \n",
    "                        pieces = split_string(instance) \n",
    "                        for piece in pieces:\n",
    "                            piece = piece.lower()\n",
    "                            pos = text.find(piece)\n",
    "                            while pos != -1:\n",
    "                                self.add_occurrence(paper, piece, pos)\n",
    "                                pos = text.find(piece, pos + 1)\n",
    "                                # Idea: store the sentence in which the instance was found\n",
    "                if not self.data.get(paper):\n",
    "                    print(f\"Paper {paper} has no instances in full text.\")\n",
    "            else:\n",
    "                print(f\"Paper {paper} has no full text available.\")\n",
    "   \n",
    "    def set_min_distance(self, paper, literals, distance):\n",
    "        \"\"\"\n",
    "        Set the minimum distance between occurrences of literals in a paper.\n",
    "\n",
    "        Parameters:\n",
    "        - paper (str): The identifier for the paper.\n",
    "        - literals (list): A list of literals for which the distance is calculated.\n",
    "        - distance (int): The calculated minimum distance.\n",
    "        \"\"\"\n",
    "        key = frozenset(literals)\n",
    "        if paper not in self.min_distances:\n",
    "            self.min_distances[paper] = {}\n",
    "        self.min_distances[paper][key] = distance\n",
    "\n",
    "    def get_min_distance(self, paper, literals, allow_call = True):\n",
    "        \"\"\"\n",
    "        Get the minimum distance between occurrences of literals in a paper, if previously calculated.\n",
    "\n",
    "        Parameters:\n",
    "        - paper (str): The identifier for the paper.\n",
    "        - literals (list): A list of literals to find the minimum distance between.\n",
    "        - allow_call (bool): Flag to allow recursive call to find_min_distance.\n",
    "\n",
    "        Returns:\n",
    "        - int or None: The minimum distance if found, otherwise None.\n",
    "        \"\"\"\n",
    "        key = frozenset(literals)\n",
    "        if paper in self.min_distances and key in self.min_distances[paper]:\n",
    "            return self.min_distances[paper][key]\n",
    "        if allow_call:\n",
    "            return self.find_min_distance(paper, literals, allow_call = False)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_min_distance(self, paper, literals, allow_call = True):\n",
    "        if allow_call:\n",
    "            min_distance = self.get_min_distance(paper, literals, allow_call = False)\n",
    "            if min_distance:\n",
    "                return min_distance\n",
    "        literals = sorted(literals, key=len, reverse=True)\n",
    "        added = []\n",
    "        for literal in literals:\n",
    "            if literal in added:\n",
    "                continue\n",
    "            added.append(literal)\n",
    "            if literal not in self.data[paper]:\n",
    "                return -1  # Literal not found in paper\n",
    "        lit_len = [len(literal) for literal in added]\n",
    "            \n",
    "        inputs = [[(x, i) for x in self.data[paper][literal]] for i, literal in enumerate(added)]\n",
    "\n",
    "        indices = [lst[0][0] for lst in inputs]\n",
    "        best = float('inf')\n",
    "\n",
    "        for item in sorted(sum(inputs, [])):\n",
    "            indices[item[1]] = item[0]\n",
    "            arr_min = min(indices)\n",
    "            best = min(max(indices) - arr_min - lit_len[indices.index(arr_min)], best)\n",
    "\n",
    "        return best\n",
    "\n",
    "    # Begin testing here. find_min_distance needs to be improved. the new method needs to have the same results, but be faster.\n",
    "\n",
    "    def find_min_distance_test(self, paper, literals):\n",
    "        raise NotImplementedError(\"You can implement and test a new function here.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@time_function\n",
    "def calculate_proximity_matrix_test(config:Config, pos_in_paper:PosInPaper, instances, mode = \"sqrt\", try_to_save_time = False, check_against:PosInPaper = None, test = False, stop_at=None, start_at=0):\n",
    "    instance_instance_proximity_matrix = np.zeros((len(instances), len(instances)), dtype=float)\n",
    "    if check_against:\n",
    "        test = True\n",
    "    for paperID, paper in enumerate(pos_in_paper.data):\n",
    "        if paperID < start_at:\n",
    "            continue\n",
    "        if stop_at:\n",
    "            if paperID >= stop_at:\n",
    "                break\n",
    "        for id1, instance1 in enumerate(instances):\n",
    "            for id2, instance2 in enumerate(instances):\n",
    "                if id1 < id2:\n",
    "                    continue\n",
    "                if instance1 != instance2:\n",
    "                    literals = []\n",
    "                    for instance in [instance1, instance2]:\n",
    "                        pieces = split_string(instance)\n",
    "                        literals += pieces\n",
    "                    if test:\n",
    "                        distance = pos_in_paper.find_min_distance_test(paper, literals)\n",
    "                        if check_against:\n",
    "                            distance_old = check_against.find_min_distance(paper, literals)\n",
    "                            if distance_old != distance:\n",
    "                                print(f\"Error: new: {distance} != old: {distance_old}\")\n",
    "                                print(f\"Paper: {paper}, Instances: {instance1}, {instance2}\")\n",
    "                                print(f\"Literals: {literals}\")\n",
    "                                raise ValueError(\"Error in distance calculation\")\n",
    "                    else:\n",
    "                        distance = pos_in_paper.get_min_distance(paper, literals)\n",
    "                    if distance < 0:\n",
    "                        # print(f\"Error: {instance1} and {instance2} not found in {paper}\")\n",
    "                        continue\n",
    "                    result = 0.0\n",
    "                    if distance == 0:\n",
    "                        result = 1\n",
    "                    elif distance == 1:\n",
    "                        result = 1\n",
    "                    elif mode == \"sqrt\":\n",
    "                        result = 1 / np.sqrt(distance)\n",
    "                    elif mode == \"linear\":\n",
    "                        result = 1 / distance\n",
    "                    elif mode == \"binary\":\n",
    "                        result = 1 if distance < config.gap_too_large_threshold else 0\n",
    "                    elif mode == \"log\":\n",
    "                        result = 1 / np.log(distance)\n",
    "                    else:\n",
    "                        print(\"Error: unknown mode\")\n",
    "                        break\n",
    "                    if result > 0.0:\n",
    "                        instance_instance_proximity_matrix[id1][id2] += result\n",
    "                        instance_instance_proximity_matrix[id2][id1] += result\n",
    "\n",
    "    \n",
    "    return instance_instance_proximity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_in_paper = PosInPaper()\n",
    "pos_in_paper.load_from_file(\"pos_in_paper\")\n",
    "# there are some bugs in old min_distances\n",
    "pos_in_paper.min_distances = {}\n",
    "\n",
    "instances = []\n",
    "with open(\"instances.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    instances = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_proximity_matrix_test executed in 0.21204781532287598 seconds\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "stop_at=5\n",
    "\n",
    "known_pos_in_paper = PosInPaper()\n",
    "known_pos_in_paper.data = {\n",
    "    \"paper1\": {\n",
    "        \"instance1\": [1, 550, 1031],\n",
    "        \"ins2\": [50, 85, 1512]\n",
    "    }\n",
    "}\n",
    "known_pos_in_paper.optimize_data()\n",
    "check_against = copy.deepcopy(known_pos_in_paper)\n",
    "known_literals = [\"instance1\", \"ins2\"]\n",
    "\n",
    "\n",
    "instance_instance_proximity_matrix = calculate_proximity_matrix_test(config, known_pos_in_paper, instances, check_against=check_against, test = True, stop_at=stop_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now testing new vs. old\n",
      "calculate_proximity_matrix_test executed in 47.845316886901855 seconds\n",
      "Now testing only old\n",
      "calculate_proximity_matrix_test executed in 13.13222050666809 seconds\n",
      "Now testing the new version\n",
      "calculate_proximity_matrix_test executed in 33.89843773841858 seconds\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "start_at=0\n",
    "stop_at=10\n",
    "\n",
    "# instances = [\n",
    "#     'knowledge based engineering',\n",
    "#     'engine analysis'\n",
    "# ]\n",
    "\n",
    "print(\"Now testing new vs. old\")\n",
    "test_pos_in_paper = copy.deepcopy(pos_in_paper)\n",
    "check_against = copy.deepcopy(pos_in_paper)\n",
    "instance_instance_proximity_matrix = calculate_proximity_matrix_test(config, test_pos_in_paper, instances, check_against=check_against, test = True, stop_at=stop_at, start_at=start_at)\n",
    "\n",
    "print(\"Now testing only old\")\n",
    "test_pos_in_paper = copy.deepcopy(pos_in_paper)\n",
    "instance_instance_proximity_matrix = calculate_proximity_matrix_test(config, test_pos_in_paper, instances, stop_at=stop_at)\n",
    "\n",
    "print(\"Now testing the new version\")\n",
    "test_pos_in_paper = copy.deepcopy(pos_in_paper)\n",
    "instance_instance_proximity_matrix = calculate_proximity_matrix_test(config, test_pos_in_paper, instances, test = True, stop_at=stop_at)\n",
    "\n",
    "# Debug barrier\n",
    "raise Exception(\"This is the end of the script. The following code is not executed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code graveyard\n",
    "raise Exception(\"This is the end of the script. The following code is not executed.\")\n",
    "\n",
    "\n",
    "\n",
    "# further down = older\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### All functions below have some issues. They are not used in the current implementation.\n",
    "\n",
    "\n",
    "def find_min_distance_v3(self, paper, literals, allow_call = True):\n",
    "    # Step 1: Merge and tag all occurrences\n",
    "    merged_occurrences = []\n",
    "    added = []\n",
    "    for literal in literals:\n",
    "        if literal in added:\n",
    "            continue\n",
    "        added.append(literal)\n",
    "        for pos in self.data[paper].get(literal, []):\n",
    "            merged_occurrences.append((pos, literal))\n",
    "    # merged_occurrences.sort(key=lambda x: (x[0], len(x[1])))\n",
    "    merged_occurrences.sort(key=lambda x: (x[0], -len(x[1])))\n",
    "    # merged_occurrences.sort()\n",
    "\n",
    "    # Step 2: Initialize sliding window\n",
    "    window = deque()\n",
    "    seen_literals = set()\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    for pos, literal in merged_occurrences:\n",
    "        window.append((pos, literal))\n",
    "        seen_literals.add(literal)\n",
    "\n",
    "        # Remove elements from the left of the window if they are no longer needed\n",
    "        while window and len(seen_literals) == len(added):\n",
    "            if literal in seen_literals:  # Check if current literal is still in the window\n",
    "                current_distance = window[-1][0] - window[0][0] - len(window[0][1])\n",
    "                min_distance = min(min_distance, current_distance)\n",
    "                _, left_literal = window.popleft()\n",
    "                if not any(lit == left_literal for _, lit in window):\n",
    "                    seen_literals.remove(left_literal)\n",
    "\n",
    "    return min_distance if min_distance != float('inf') else -1\n",
    "    raise NotImplementedError(\"You can implement and test a new function here.\")\n",
    "\n",
    "\n",
    "## -------- broken functions. Reference functions for future improvements --------\n",
    "def find_min_distance_v2(self, paper, literals, allow_call = True):\n",
    "    #TODO: currently, this does not consider stemmed words\n",
    "    if allow_call:\n",
    "        min_distance = self.get_min_distance(paper, literals, allow_call = False)\n",
    "        if min_distance:\n",
    "            return min_distance\n",
    "        \n",
    "    # Step 1: Ensure all literals are present\n",
    "\n",
    "    for literal in literals:\n",
    "        if literal not in self.data[paper]:\n",
    "            return -1  # Literal not found in paper\n",
    "\n",
    "    # Step 2: Aggregate positions with tags\n",
    "    literals = sorted(literals, key=len, reverse=True)\n",
    "    aggregated_positions = []\n",
    "    added = []\n",
    "    for literal in literals:\n",
    "        if literal in added:\n",
    "            continue\n",
    "        added.append(literal)\n",
    "        for position in self.data[paper][literal]:\n",
    "            if position not in aggregated_positions:\n",
    "                aggregated_positions.append((position, literal))\n",
    "    \n",
    "    # Step 3: Sort the aggregated list by positions\n",
    "    aggregated_positions.sort()\n",
    "\n",
    "    # Step 4: Find the minimum range using a sliding window approach\n",
    "    from collections import Counter\n",
    "    count = Counter()\n",
    "    min_range = float('inf')\n",
    "    left = 0  # Window start\n",
    "    for right, (position, literal) in enumerate(aggregated_positions):\n",
    "        count[literal] += 1\n",
    "        # Try to contract the window from the left if it still contains all literals\n",
    "        while all(count[lit] > 0 for lit in literals):\n",
    "            _, left_literal = aggregated_positions[left]\n",
    "            current_range = aggregated_positions[right][0] - aggregated_positions[left][0] - len(left_literal)\n",
    "            # current_range = aggregated_positions[right][0] - aggregated_positions[left][0]\n",
    "            min_range = min(min_range, current_range)\n",
    "            # Move the window leftwards\n",
    "            count[left_literal] -= 1\n",
    "            left += 1\n",
    "\n",
    "    return min_range if min_range != float('inf') else -1\n",
    "\n",
    "\n",
    "def find_min_distance_v1(self, paper, literals = [], allow_call = True, ignore_errors = False):\n",
    "    \"\"\"\n",
    "    Find the minimum distance between occurrences of literals in a paper.\n",
    "\n",
    "    Parameters:\n",
    "    - paper (str): The identifier for the paper.\n",
    "    - literals (list, optional): A list of literals to find the minimum distance between. Defaults to an empty list.\n",
    "    - allow_call (bool): Flag to allow recursive call to get_min_distance.\n",
    "\n",
    "    Returns:\n",
    "    - int: The minimum distance between the occurrences of the literals, or -1 if not all literals are found.\n",
    "    \"\"\"\n",
    "    if not ignore_errors:\n",
    "        raise NotImplementedError(\"This function is not used in the current implementation. It does not reliably subtract the leftmost literal from the distance.\")\n",
    "    \n",
    "\n",
    "    #TODO: currently, this does not consider stemmed words\n",
    "    if allow_call:\n",
    "        min_distance = self.get_min_distance(paper, literals, allow_call = False)\n",
    "        if min_distance:\n",
    "            return min_distance\n",
    "    keys = [key for key in set(literals)]\n",
    "    lit_len = [len(key) for key in keys]\n",
    "    \n",
    "    # Initialize pointers for each of the lists\n",
    "    pointers = [0] * len(keys)\n",
    "    min_distance = sys.maxsize\n",
    "    for key in keys:\n",
    "        if key not in self.data[paper]:\n",
    "            self.set_min_distance(paper, literals, -1)\n",
    "            return -1\n",
    "        if not self.data[paper][key]:\n",
    "            self.set_min_distance(paper, literals, -1)\n",
    "            return -1\n",
    "    while True:\n",
    "        # Get the current elements from the lists\n",
    "        # self.data[paper][keys[i]][pointers[i]] =\n",
    "        # self.data (dict of papers)\n",
    "        # [paper] (current paper)\n",
    "        # [keys[i]] (current instance)\n",
    "        # [pointers[i]] (current position in the list of positions for the instance)\n",
    "        # current_elements = list of some positions of all instances from literals\n",
    "        current_elements = [self.data[paper][keys[i]][pointers[i]] for i in range(len(keys))]\n",
    "        \n",
    "        # Calculate the current distance\n",
    "        current_min = min(current_elements)\n",
    "        current_max = max(current_elements)\n",
    "\n",
    "        # FIXME: This is not 100% reliable, as current_min could be shared by multiple instances\n",
    "        # completely discarding this function now.\n",
    "        min_index = current_elements.index(current_min)\n",
    "        # reduce the distance by the length of the first word\n",
    "        current_distance = current_max - (current_min + lit_len[min_index] + 1)\n",
    "        \n",
    "        # Update the minimum distance\n",
    "        if current_distance < min_distance:\n",
    "            min_distance = current_distance\n",
    "            if min_distance <= 0:\n",
    "                min_distance = 0\n",
    "                break\n",
    "            \n",
    "        # Check if we can move forward in the list containing the minimum element\n",
    "        # If the pointer exceeds its list length, exit the loop\n",
    "        for i in range(len(keys)):\n",
    "            if pointers[i] < len(self.data[paper][keys[i]]):\n",
    "                break\n",
    "        if pointers[min_index] + 1 >= len(self.data[paper][keys[min_index]]):\n",
    "            break\n",
    "        \n",
    "        # Otherwise, increment the pointer\n",
    "        pointers[min_index] += 1\n",
    "    \n",
    "    self.set_min_distance(paper, literals, min_distance)\n",
    "    return min_distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: find the gap between the pieces of an instance\n",
    "import sys\n",
    "\n",
    "def find_min_distance(lists, literals = []):\n",
    "    \"\"\"\n",
    "    Old version of the function, kept for reference.\n",
    "    \"\"\"\n",
    "    #TODO: currently, this does not consider stemmed words\n",
    "    # implemented: consider the length of the words for measuring the distance.\n",
    "    ## e.g. \"four\" will always have a distance of at least 5 (4 characters + 1 space) to any consecutive word\n",
    "    ## We must subtract the length of the words from the distance later.\n",
    "\n",
    "    # Initialize pointers for each of the lists\n",
    "    pointers = [0] * len(lists)\n",
    "    min_distance = sys.maxsize\n",
    "    for list in lists:\n",
    "        if not list:\n",
    "            # There are cases where e.g. \"system integration\" is not found in full text\n",
    "            # This happens when NLP converts e.g. \"integrated\" to \"integration\"\n",
    "            # example:\n",
    "            # \"Liu und Hu - 2013 - A reuse oriented representation model for capturin\"\n",
    "            # \"system integration\" -> \"integration\" is not found in the full text\n",
    "            return -1\n",
    "    while True:\n",
    "        # Get the current elements from the lists\n",
    "        current_elements = [lists[i][pointers[i]] for i in range(len(lists))]\n",
    "        \n",
    "        # Calculate the current distance\n",
    "        current_min = min(current_elements)\n",
    "        current_max = max(current_elements)\n",
    "        current_distance = current_max - current_min\n",
    "        \n",
    "        # reduce the distance by the length of the first word\n",
    "        if literals:\n",
    "            min_element_index = current_elements.index(current_min)\n",
    "            current_distance -= len(literals[min_element_index]) + 1 # +1 for the space\n",
    "        \n",
    "        # Update the minimum distance\n",
    "        if current_distance < min_distance:\n",
    "            min_distance = current_distance\n",
    "            if min_distance <= 0:\n",
    "                min_distance = 0\n",
    "                break\n",
    "            \n",
    "        # Check if we can move forward in the list containing the minimum element\n",
    "        min_index = current_elements.index(current_min)\n",
    "        \n",
    "        # If the pointer exceeds its list length, exit the loop\n",
    "        for i in range(len(lists)):\n",
    "            if pointers[i] < len(lists[i]) - 1:\n",
    "                break\n",
    "        if pointers[min_index] + 1 >= len(lists[min_index]):\n",
    "            break\n",
    "        \n",
    "        # Otherwise, increment the pointer\n",
    "        pointers[min_index] += 1\n",
    "    \n",
    "    return min_distance\n",
    "\n",
    "\n",
    "def find_min_distance_keep(lists, literals = [], keep_close_matches = False):\n",
    "\n",
    "    #TODO: currently, this does not consider stemmed words\n",
    "    # implemented: consider the length of the words for measuring the distance.\n",
    "    ## e.g. \"four\" will always have a distance of at least 5 (4 characters + 1 space) to any consecutive word\n",
    "    ## We must subtract the length of the words from the distance later.\n",
    "    positions = []\n",
    "\n",
    "    # Initialize pointers for each of the lists\n",
    "    pointers = [0] * len(lists)\n",
    "    min_distance = sys.maxsize\n",
    "    \n",
    "    pointer_map = [i for i in range(len(lists))]\n",
    "    has_lists = []\n",
    "    for i, item in enumerate(lists):\n",
    "        if not item:\n",
    "            # There are cases where e.g. \"system integration\" is not found in full text\n",
    "            # This happens when NLP converts e.g. \"integrated\" to \"integration\"\n",
    "            # example:\n",
    "            # \"Liu und Hu - 2013 - A reuse oriented representation model for capturin\"\n",
    "            # \"system integration\" -> \"integration\" is not found in the full text\n",
    "            return -1\n",
    "        \n",
    "        if isinstance(item[0], list):\n",
    "            has_lists.append(i)\n",
    "            pointer_map = pointer_map[:i] + [pointer_map[i]] * len(item[0]) + pointer_map[i+1:]\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
