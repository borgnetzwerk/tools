{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, for_git=True):\n",
    "        self.for_git = for_git\n",
    "        self.visualize = not for_git\n",
    "        # self.visualize = True\n",
    "        self.csv_separator = ',' if for_git else ';'\n",
    "        self.csv_decimal = '.' if for_git else ','\n",
    "        self.only_included_papers = True\n",
    "        self.properties = ['source']\n",
    "        self.proximity_mode = \"sqrt\"  # \"log\" mode is untested/unsafe, prefer \"sqrt\"\n",
    "        self.base_path = 'data/'  # Default base path\n",
    "        self.subset_path = 'data_subset/'\n",
    "        self.visualization_path = 'visualization/'\n",
    "        self.ontology_path = 'ontology/'\n",
    "        self.papers_path = 'G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR/02_nlp'\n",
    "        self.review_path = 'G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR/03_notes'\n",
    "        self.csv_file = 'C:/workspace/borgnetzwerk/tools/scripts/SLR/data.csv'\n",
    "        self.gap_too_large_threshold = 1000\n",
    "        self.savetime_on_fulltext = False   # If True, operations on fulltext will be kept to a minimum\n",
    "        self.try_to_save_time = False\n",
    "        self.recalculate_pos_in_paper = False # while the calculation is inefficient, just load from file\n",
    "        self.debug = True\n",
    "\n",
    "        self.wikidata_query_limit = 20\n",
    "\n",
    "        self.proximity_seed = 17\n",
    "        self.proximity_k_spring = 18\n",
    "        self.proximity_min_value = 0.1\n",
    "\n",
    "\n",
    "    def get_output_path(self, path=\"\", visualization=False):\n",
    "        \"\"\"\n",
    "        Determine the output path based on the configuration and parameters.\n",
    "        \"\"\"\n",
    "        if not path:\n",
    "            path = self.subset_path if self.only_included_papers else self.base_path\n",
    "        if visualization and not path.endswith(self.visualization_path):\n",
    "            path = os.path.join(path, self.visualization_path)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        return path\n",
    "\n",
    "# Usage\n",
    "config = Config(for_git=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug test\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def run_debug_test(config: Config, instances:list[str] = None, papers:list[str] = None, paper_instance_occurrence_matrix:np.ndarray = None):\n",
    "    if \"ikewiki\" in instances:\n",
    "        ike_index = instances.index(\"ikewiki\")\n",
    "        sum_ikewiki = np.sum(paper_instance_occurrence_matrix[:,ike_index])\n",
    "        if sum_ikewiki > 1:\n",
    "            raise Exception(f\"Only one paper should contain 'ikewiki', but {sum_ikewiki} do.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_function(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        appendix = \"\"\n",
    "        # if instances in args:\n",
    "        if \"instances\" in kwargs:\n",
    "            # append len of instances\n",
    "            appendix = f\"({len(kwargs['instances'])} instances\"\n",
    "        if \"papers\" in kwargs:\n",
    "            if appendix:\n",
    "                appendix += \", \"\n",
    "            appendix += f\"{len(kwargs['papers'])} papers\"\n",
    "        if appendix:\n",
    "            appendix += \")\"\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"{func.__name__} executed in {end_time - start_time} seconds\" + appendix)\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful functions\n",
    "def index_all(input_list, item):\n",
    "    return [i for i, x in enumerate(input_list) if x == item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Paper Metadata\n",
    "from bnw_tools.extract import util_zotero\n",
    "\n",
    "def get_paper_nlp_paths(papers_path):\n",
    "    paper_nlp_paths = {}\n",
    "    for file in os.listdir(papers_path):\n",
    "        if file.endswith(\".json\"):\n",
    "            paper_nlp_paths[file[:-5]] = os.path.join(papers_path, file)\n",
    "    return paper_nlp_paths\n",
    "\n",
    "def reduce_to_reviewed_papers(papers, review_path):\n",
    "    # todo: sort by review score + average rank\n",
    "    included_papers = []\n",
    "    excluded_papers = []\n",
    "    included_identifier = [\"review_score:: 3\", \"review_score:: 4\", \"review_score:: 5\"]\n",
    "    excluded_identifier = [\"review_score:: 2\", \"review_score:: 1\", \"review_score:: 0\"]\n",
    "    for file in os.listdir(review_path):\n",
    "        if file.endswith(\".md\"):\n",
    "            paper_name = file[:-3]\n",
    "            if paper_name in papers:\n",
    "                # check if file contains \"reviewed\"ArithmeticError\n",
    "                with open(os.path.join(review_path, file), 'r', encoding=\"utf8\") as f:\n",
    "                    content = f.read()\n",
    "                    for id in included_identifier:\n",
    "                        if id in content:\n",
    "                            included_papers.append(paper_name)\n",
    "                            break\n",
    "                    for id in excluded_identifier:\n",
    "                        if id in content:\n",
    "                            excluded_papers.append(paper_name)\n",
    "                            break\n",
    "    return included_papers, excluded_papers\n",
    "\n",
    "@time_function\n",
    "def get_paper_metadata(papers, path):\n",
    "    papers_metadata = {}\n",
    "\n",
    "    bib_resources = util_zotero.BibResources(path)\n",
    "\n",
    "    for paper in papers:\n",
    "        for entry in bib_resources.entries:\n",
    "            if hasattr(bib_resources.entries[entry], 'file') and paper in bib_resources.entries[entry].file:\n",
    "                papers_metadata[paper] = bib_resources.entries[entry].get_dict()\n",
    "                del bib_resources.entries[entry]\n",
    "                break\n",
    "\n",
    "\n",
    "    print(f\"{len(papers_metadata)} out of {len(papers)} papers have metadata.\")\n",
    "\n",
    "    return papers_metadata\n",
    "\n",
    "paper_nlp_paths = get_paper_nlp_paths(config.papers_path)\n",
    "\n",
    "papers = list(paper_nlp_paths.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only included papers are considered. Excluded or not reviewed papers are removed.\n"
     ]
    }
   ],
   "source": [
    "def exclude_papers(paper_nlp_paths, papers, included_papers, only_included_papers):\n",
    "    if only_included_papers:\n",
    "        deletions = [False] * len(papers)\n",
    "        for p_ID, paper in enumerate(paper_nlp_paths):\n",
    "            if paper not in included_papers:\n",
    "                deletions[p_ID] = True\n",
    "        for p_ID, deletion in enumerate(deletions):\n",
    "            if deletion:\n",
    "                paper_nlp_paths.pop(papers[p_ID])\n",
    "        papers = included_papers\n",
    "        print(\"Only included papers are considered. Excluded or not reviewed papers are removed.\")\n",
    "    return paper_nlp_paths, papers\n",
    "\n",
    "included_papers, excluded_papers = reduce_to_reviewed_papers(papers, config.review_path)\n",
    "\n",
    "paper_nlp_paths, papers = exclude_papers(paper_nlp_paths, papers, included_papers, only_included_papers = config.only_included_papers)\n",
    "\n",
    "# Free memory\n",
    "del included_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found no new Zotero export at G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR:\n",
      "There should be a folder called 'files'\n",
      "We now have 1035 PDFs stored at G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR\\00_PDFs\n",
      "164 out of 164 papers have metadata.\n",
      "get_paper_metadata executed in 15.95762848854065 seconds\n"
     ]
    }
   ],
   "source": [
    "# extract the matadata from bibtex\n",
    "papers_metadata = get_paper_metadata(papers, 'G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort papers by year\n",
    "papers = sorted(papers, key=lambda x: papers_metadata[x]['year'] if x in papers_metadata and 'year' in papers_metadata[x] else \"9999\")\n",
    "# sort paper_nlp_paths and papers_metadata accordingly\n",
    "paper_nlp_paths = {k: paper_nlp_paths[k] for k in papers}\n",
    "papers_metadata = {k: papers_metadata[k] for k in papers if k in papers_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file improved, found 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: find occurrences of instances in bag of words of papers\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_string(input_string, delimiters = [\" \", \"-\", \"_\"]):\n",
    "    for delimiter in delimiters:\n",
    "        input_string = \" \".join(input_string.split(delimiter))\n",
    "    return input_string.split()\n",
    "\n",
    "def preprocess_csv(csv_file, config: Config, writeback = True):\n",
    "    with open(csv_file, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    expected_columns = len(lines[0].split(config.csv_separator))\n",
    "    processed_lines = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if line.count('\"') % 2 == 1:\n",
    "            # if the number of quotes is odd, the line is not complete\n",
    "            error = True\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                line = line + \" \" + lines[j].strip()\n",
    "                if line.count('\"') % 2 == 0:\n",
    "                    error = False\n",
    "                    print(f\"Merged rows {i} to {j}\")\n",
    "                    i = j + 1\n",
    "                    break\n",
    "            if error:\n",
    "                raise Exception(f\"Error: Lines {i} to {j-1} could not be processed. Odd number of quotes.\")\n",
    "        else:\n",
    "            i += 1\n",
    "        if '\"\"' in line:\n",
    "            # remove quotes from line\n",
    "            line = line.replace('\"\"', '')\n",
    "        if line.count('\"') % 2 == 0:\n",
    "            pos1 = line.find('\"')\n",
    "            while pos1 != -1:\n",
    "                pos2 = line.find('\"', pos1 + 1)\n",
    "                if not config.csv_separator in line[pos1:pos2]:\n",
    "                    line = line[pos1:pos2] + line[pos2 + 1:]\n",
    "                pos1 = line.find('\"', pos2 + 1)\n",
    "        processed_lines.append(line)\n",
    "    if writeback and len(processed_lines) != len(lines) or lines != processed_lines:\n",
    "        print(f\"CSV file improved, found {len(lines) - len(processed_lines)} errors.\")\n",
    "        with open(csv_file, 'w', encoding=\"utf8\") as f:\n",
    "            f.write(\"\\n\".join(processed_lines))\n",
    "\n",
    "    return processed_lines\n",
    "\n",
    "\n",
    "def csv_to_dict_of_sets(csv_file, config: Config, prune_nan = True):\n",
    "    dict_of_sets = {}\n",
    "    # try:\n",
    "    #     df = pd.read_csv(csv_file)\n",
    "    # except pd.errors.ParserError:\n",
    "    #     print(\"Error parsing CSV file. Trying again with 'error_bad_lines=False'\")\n",
    "    # TODO: Specify modular separator and decimal here as well\n",
    "\n",
    "    preprocess_csv(csv_file, config)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, on_bad_lines='warn', delimiter=config.csv_separator,  encoding=\"utf-8\")\n",
    "    except:\n",
    "        print(\"Error parsing CSV file. Trying again with 'encoding=ISO-8859-1'\")\n",
    "        df = pd.read_csv(csv_file, on_bad_lines='warn', delimiter=config.csv_separator, encoding='ISO-8859-1')\n",
    "    for column in df.columns:\n",
    "        dict_of_sets[column] = set(df[column].str.lower())\n",
    "        if prune_nan and np.nan in dict_of_sets[column]:\n",
    "            dict_of_sets[column].remove(np.nan)\n",
    "    # saved_column = df['process'] #you can also use df['column_name']\n",
    "    # delete all that exists in two or more columns\n",
    "    for key in dict_of_sets:\n",
    "        for other_key in dict_of_sets:\n",
    "            if key != other_key:\n",
    "                dict_of_sets[key] = dict_of_sets[key].difference(dict_of_sets[other_key])\n",
    "    return dict_of_sets\n",
    "\n",
    "def prune_properties(instance_types_dicts, properties_to_prune = [], prune_empty = True, prune_x = True):\n",
    "    properties = {}\n",
    "    \n",
    "    # merge \"interchange format\" into \"data format specification\"\n",
    "    if 'interchange format' in instance_types_dicts:\n",
    "        pruned = []\n",
    "        for key in instance_types_dicts['interchange format']:\n",
    "            if len(key) > 1:\n",
    "                instance_types_dicts['data format specification'].add(key)\n",
    "                pruned.append(key)\n",
    "        for key in pruned:\n",
    "            instance_types_dicts['interchange format'].remove(key)\n",
    "\n",
    "    for instance_type in instance_types_dicts:\n",
    "        prune = False\n",
    "        if instance_type in properties_to_prune:\n",
    "            prune = True\n",
    "        elif prune_empty and len(instance_types_dicts[instance_type]) == 0:\n",
    "            # prune empty sets\n",
    "            prune = True\n",
    "        elif prune_x and len(max(instance_types_dicts[instance_type], key=len)) < 2:\n",
    "            # prune sets with only one character entries\n",
    "            prune = True\n",
    "        \n",
    "        if prune:\n",
    "            properties[instance_type] = instance_types_dicts[instance_type]\n",
    "\n",
    "    for instance_type in properties:\n",
    "        instance_types_dicts.pop(instance_type)           \n",
    "\n",
    "    return instance_types_dicts, properties\n",
    "\n",
    "def count_occurrences(papers, instances):\n",
    "    occurrences = np.zeros((len(papers), len(instances)), dtype=int)\n",
    "\n",
    "    for p, paperpath in enumerate(papers.values()):\n",
    "        with open(paperpath, 'r', encoding=\"utf8\") as f:\n",
    "            paper = json.load(f)\n",
    "            for i, instance in enumerate(instances):\n",
    "                present = True\n",
    "                pieces = split_string(instance)\n",
    "                for piece in pieces:\n",
    "                    if piece.lower() not in paper['bag_of_words']:\n",
    "                        present = False\n",
    "                        break\n",
    "                    \n",
    "                # if instance == \"system integration\":\n",
    "                #     if \"Liu und Hu - 2013 - A reuse oriented representation model for capturin\" in paperpath:\n",
    "                #         print(present)\n",
    "                if present:\n",
    "                    occurrences[p][i] = 1\n",
    "    return occurrences\n",
    "\n",
    "# ---------------------- Variables ----------------------\n",
    "\n",
    "## instances: A list of all instances, regardless of their type\n",
    "# first all type 1, then all type 2, etc.\n",
    "# if possible, instance sare ordered by their occurrence\n",
    "\n",
    "## instances_dicts: A dictionary of all different types (columns) of instances\n",
    "#\n",
    "# types:\n",
    "#  - process\n",
    "#  - software\n",
    "#  - data item\n",
    "#  - data model\n",
    "#  - data format specification\n",
    "#  - interchange format\n",
    "#  - source\n",
    "#\n",
    "# instances_dicts['process']: A set of all instances of the type 'process'\n",
    "#\n",
    "instance_types_dicts = {}\n",
    "\n",
    "## paper_nlp_dict: A dictionary of all papers and their NLP data (as dict)\n",
    "\n",
    "## occurrences: A matrix of binary occurrences of instances in papers\n",
    "#\n",
    "# rows: papers\n",
    "# columns: instances\n",
    "# cells: 1 if instance is present in paper, 0 otherwise\n",
    "#\n",
    "paper_instance_occurrence_matrix = np.zeros((), dtype=int)\n",
    "\n",
    "\n",
    "# ---------------------- Main ----------------------\n",
    "\n",
    "# Usage example\n",
    "\n",
    "#TODO: Delete first 2 lines and see why this throws error then\n",
    "instance_types_dicts = csv_to_dict_of_sets(config.csv_file, config)\n",
    "\n",
    "# Extract instance types that are actually property types\n",
    "instance_types_dicts, property_types_dicts = prune_properties(instance_types_dicts, properties_to_prune=config.properties)\n",
    "\n",
    "def get_instances_list(instance_types_dicts):\n",
    "    instances = []\n",
    "    # merge all sets into one set\n",
    "    for instance_type in instance_types_dicts:\n",
    "        instances += (instance_types_dicts[instance_type])\n",
    "    return instances\n",
    "\n",
    "instances = get_instances_list(instance_types_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Whitelist\n",
    "\n",
    "# Class,URI,Label,Laymans Term,Status\n",
    "## e.g. process,software,data item,data model,data format specification,\n",
    "class InstanceType: # Class\n",
    "    def __init__(self, label:str = None, laymans_term:str = None, uri:str = None, properties = {}):\n",
    "        self.label = label\n",
    "        self.uri = uri\n",
    "        self.laymans_term = laymans_term\n",
    "        self.set_properties(properties)\n",
    "\n",
    "    def set_properties(self, properties = {}, overwrite = False):\n",
    "        for property, value in properties.items():\n",
    "            if not overwrite and hasattr(self, property) and getattr(self, property) != None:\n",
    "                continue\n",
    "            else:\n",
    "                setattr(self, property, value)\n",
    "\n",
    "class Instance:\n",
    "    properties = {\n",
    "        'default' : ['name', \n",
    "                     'instance_type',\n",
    "                     'uri',\n",
    "                     'also_known_as',\n",
    "                     ],\n",
    "        'software' : [\n",
    "                    'data visualization',\n",
    "                    'data validation',\n",
    "                    'data reasoning',\n",
    "                    ],\n",
    "        'format' : ['neutral']\n",
    "        }\n",
    "    \n",
    "    def __init__(self, name, instance_type, properties = {}):\n",
    "        self.name = name\n",
    "        self.instance_type = instance_type # class\n",
    "        self.uri = None\n",
    "        self.also_known_as = []\n",
    "        self.properties = self.set_properties(properties)\n",
    "\n",
    "    def set_properties(self, properties = {}, overwrite = False):\n",
    "        candidates = Instance.properties['default'] + Instance.properties.get(self.instance_type, [])\n",
    "        for candidate in candidates:\n",
    "            if candidate not in properties:\n",
    "                properties[candidate] = None\n",
    "\n",
    "        for property, value in properties.items():\n",
    "            if not overwrite and hasattr(self, property) and getattr(self, property) != None:\n",
    "                continue\n",
    "            else:\n",
    "                setattr(self, property, value)\n",
    "\n",
    "class InstanceDict:\n",
    "    def __init__(self, instance_types_dicts = {}):\n",
    "        self.instances:dict[str,Instance] = {}\n",
    "\n",
    "        if instance_types_dicts:\n",
    "            self.add_instance_types(instance_types_dicts)\n",
    "\n",
    "    def add_instance_types(self, instance_types_dicts):\n",
    "        for instance_type, instances in instance_types_dicts.items():\n",
    "            for instance in instances:\n",
    "                if instance not in self.instances:\n",
    "                    self.instances[instance] = Instance(instance, instance_type)\n",
    "    \n",
    "    def sort(self):\n",
    "        # sort according to the following order:\n",
    "        # first: all instances that have isinstance(self.uri, string)\n",
    "        # second: all instances that have isinstance(self.uri, list), sorted by length of self.uri (shortest first)\n",
    "        # third: all instances that have isinstance(self.uri, int)\n",
    "        self.instances = {k: self.instances[k] for k in sorted(self.instances, key=lambda x: (\n",
    "            0 if isinstance(self.instances[x].uri, str) else \n",
    "            len(self.instances[x].uri) if isinstance(self.instances[x].uri, list) else \n",
    "            99999\n",
    "            # len(self.instances[x].uri) if isinstance(self.instances[x].uri, list) else 0\n",
    "        ))}\n",
    "        \n",
    "    def save(self, config:Config, path=None, name = \"instances.csv\", sort=True):\n",
    "        if not path:\n",
    "            path = config.ontology_path\n",
    "        if not name.endswith(\".csv\"):\n",
    "            name += \".csv\"\n",
    "        if sort:\n",
    "            self.sort()\n",
    "        filepath = os.path.join(path, name)\n",
    "        # TODO: make a way that this is generated dynamically\n",
    "        cols = [name for sublist in Instance.properties.values() for name in sublist]\n",
    "        header = config.csv_separator.join(cols)\n",
    "\n",
    "        # backup\n",
    "        if os.path.exists(filepath):\n",
    "            try:\n",
    "                temp = InstanceDict()\n",
    "                temp.load(config, path, name)\n",
    "                # current file is valid, so backup\n",
    "                backup_path = filepath.replace(\".csv\", \"_backup.csv\")\n",
    "                if os.path.exists(backup_path):\n",
    "                    os.remove(backup_path)\n",
    "                os.rename(filepath, backup_path)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "\n",
    "\n",
    "        with open(filepath, 'w', encoding=\"utf8\") as f:\n",
    "            f.write(header + '\\n')\n",
    "            for instance in self.instances.values():\n",
    "                line = []\n",
    "                for col in cols:\n",
    "                    if hasattr(instance, col):\n",
    "                        entry = getattr(instance, col) or \"\"\n",
    "                        while isinstance(entry, dict) and list(entry.keys()) == [col]:\n",
    "                            entry = entry[col]\n",
    "                        if isinstance(entry, dict):\n",
    "                            entry = json.dumps(entry)\n",
    "                        elif isinstance(entry, list):\n",
    "                            entry = json.dumps(entry)\n",
    "                        elif isinstance(entry, int):\n",
    "                            entry = str(entry)\n",
    "                        if config.csv_separator in entry:\n",
    "                            entry = f'\"{entry}\"'\n",
    "                        line.append(entry)\n",
    "                    else:\n",
    "                        line.append(\"\")\n",
    "                f.write(config.csv_separator.join(line) + '\\n')\n",
    "    \n",
    "    def load(self, config, path=None, name = \"instances.csv\", try_backup = True):\n",
    "        if not path:\n",
    "            path = config.ontology_path\n",
    "        if not name.endswith(\".csv\"):\n",
    "            name += \".csv\"\n",
    "        filepath = os.path.join(path, name)\n",
    "\n",
    "\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding=\"utf8\") as f:\n",
    "                lines = f.read().splitlines()\n",
    "            cols = lines[0].split(config.csv_separator)\n",
    "            for line in lines[1:]:\n",
    "                data = line.split(config.csv_separator)\n",
    "                for i in range(len(data)):\n",
    "                    if i == len(data):\n",
    "                        break\n",
    "                    while data[i].count('\"') % 2 == 1 or data[i].count('[') != data[i].count(']') or data[i].count('{') != data[i].count('}'):\n",
    "                        data[i] += \",\" + data.pop(i+1)\n",
    "                    # has separator\n",
    "                    if data[i].startswith('\"') and data[i].endswith('\"'):\n",
    "                        data[i] = data[i][1:-1]\n",
    "                    # json\n",
    "                    if data[i].startswith('{') and data[i].endswith('}'):\n",
    "                        data[i] = json.loads(data[i])\n",
    "                    # list\n",
    "                    if data[i].startswith('[') and data[i].endswith(']'):\n",
    "                        data[i] = json.loads(data[i])\n",
    "                    # int\n",
    "                    if isinstance(data[i], str) and data[i] == '-1':\n",
    "                        # TODO: Make this more general\n",
    "                        data[i] = int(data[i])\n",
    "                if len(data) != len(cols):\n",
    "                    raise Exception(f\"Error: Line {line} has too few columns.\")\n",
    "                instance = Instance(data[0], data[1], properties = {cols[i]: data[i] for i in range(2, len(data)) if data[i]})\n",
    "                instance.set_properties()\n",
    "                self.instances[instance.name] = instance\n",
    "        except Exception as e:\n",
    "            backup_name = name.replace(\".csv\", \"_backup.csv\")\n",
    "            if try_backup and os.path.exists(os.path.join(path, backup_name)):\n",
    "                self.load(config, path, backup_name, try_backup = False)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "whitelist = InstanceDict()\n",
    "whitelist.load(config)\n",
    "whitelist.add_instance_types(instance_types_dicts)\n",
    "\n",
    "whitelist.save(config)\n",
    "\n",
    "def curate_instances(instances, path = None):\n",
    "    if not path:\n",
    "        path = \"whitelist.csv\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            whitelist = f.read().splitlines()\n",
    "    \n",
    "    for instance in instances:\n",
    "        if instance not in whitelist:\n",
    "            instances.remove(instance)\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class WikiData:\n",
    "    queries_done = 0\n",
    "    new_labels = 0\n",
    "    new_entries = 0\n",
    "\n",
    "\n",
    "    def print_updates():\n",
    "        print(f\"Queries done: {WikiData.queries_done}\")\n",
    "        print(f\"New labels: {WikiData.new_labels}\")\n",
    "        print(f\"New entries: {WikiData.new_entries}\")\n",
    "\n",
    "    def __init__(self, config:Config = None):\n",
    "        self.entries = {}\n",
    "        self.label_entry_map = {}\n",
    "        if config:\n",
    "            self.load(config)\n",
    "    \n",
    "    def save(self, config, path=None, name = \"wikidata.json\"):\n",
    "        if not path:\n",
    "            path = config.ontology_path\n",
    "        if not name.endswith(\".json\"):\n",
    "            name += \".json\"\n",
    "        filepath = os.path.join(path, name)\n",
    "        with open(filepath, 'w', encoding=\"utf8\") as f:\n",
    "            data = self.__dict__\n",
    "            json.dump(data, f)\n",
    "    \n",
    "    def load(self, config, path=None, name = \"wikidata.json\"):\n",
    "        if not path:\n",
    "            path = config.ontology_path\n",
    "        if not name.endswith(\".json\"):\n",
    "            name += \".json\"\n",
    "        filepath = os.path.join(path, name)\n",
    "        if not os.path.exists(filepath):\n",
    "            return\n",
    "        with open(filepath, 'r', encoding=\"utf8\") as f:\n",
    "            data = json.load(f)\n",
    "            for key, value in data.items():\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    def query_wikidata(self, config:Config, label:str, select = 'label', limit = None, nested = False):\n",
    "        if select == 'label' and not nested:\n",
    "            if WikiData.queries_done > config.wikidata_query_limit:\n",
    "                print(\"Wikidata query limit reached.\")\n",
    "                WikiData.print_updates()\n",
    "                return False\n",
    "            else:\n",
    "                WikiData.queries_done += 1                \n",
    "            \n",
    "        \n",
    "        def transform_results(results):\n",
    "            transformed = {}\n",
    "            for result in results:\n",
    "                item_uri = result['item']['value']\n",
    "                item_label = result['itemLabel']['value']\n",
    "                # Handle cases where altLabels or description might not be present\n",
    "                alt_labels = result.get('altLabels', {}).get('value', '')\n",
    "                description = result.get('description', {}).get('value', '')\n",
    "\n",
    "                transformed[item_uri] = {\n",
    "                    'itemLabel': item_label,\n",
    "                    'altLabels': alt_labels,\n",
    "                    'description': description  # Include this line only if descriptions are desired\n",
    "                }\n",
    "            return transformed\n",
    "\n",
    "        if not limit:\n",
    "            limit = config.wikidata_query_limit\n",
    "        endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "        \n",
    "        selection = {\n",
    "            'label' : f'?item rdfs:label \"{label}\"@en.',\n",
    "            'altLabel' : f'?item skos:altLabel \"{label}\"@en.'\n",
    "        }\n",
    "\n",
    "        # query = f\"\"\"\n",
    "        # SELECT ?item ?itemLabel (GROUP_CONCAT(DISTINCT ?altLabel; separator = \", \") AS ?altLabels) WHERE {{\n",
    "        # {selection[select]}\n",
    "        # SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        # }}\n",
    "        # GROUP BY ?item ?itemLabel\n",
    "        # LIMIT {limit}\n",
    "        # \"\"\"\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT ?item ?itemLabel (GROUP_CONCAT(DISTINCT ?altLabel; separator = \", \") AS ?altLabels) \n",
    "        (SAMPLE(?description) AS ?description) WHERE {{\n",
    "        {selection[select]}\n",
    "        OPTIONAL {{ ?item skos:altLabel ?altLabel FILTER(LANG(?altLabel) = \"en\") }}\n",
    "        OPTIONAL {{ ?item schema:description ?description FILTER(LANG(?description) = \"en\") }}\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        GROUP BY ?item ?itemLabel\n",
    "        LIMIT {limit}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"WDQS-example Python/%s.%s\" % (requests.__version__, \"MyScript\"),\n",
    "            \"Accept\": \"application/json\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.get(endpoint_url, headers=headers, params={'query': query, 'format': 'json'})\n",
    "            response.raise_for_status()  # Raises stored HTTPError, if one occurred\n",
    "            \n",
    "            data = response.json()\n",
    "            results = data['results']['bindings']\n",
    "            results = transform_results(results)\n",
    "            if select == 'label':\n",
    "                if len(results) < limit:\n",
    "                    results_altLabel = self.query_wikidata(config, label, select = 'altLabel', limit = limit - len(results), nested = True)\n",
    "                    results.update(results_altLabel)\n",
    "                if not nested:\n",
    "                    if len(results) < limit and label.lower() != label:\n",
    "                        results_lower = self.query_wikidata(config, label.lower(), select = select, limit = limit - len(results), nested = True)\n",
    "                        results.update(results_lower)\n",
    "                    if len(results) < limit and label.capitalize() != label:\n",
    "                        results_capitalize = self.query_wikidata(config, label.capitalize(), select = select, limit = limit - len(results), nested = True)\n",
    "                        results.update(results_capitalize)\n",
    "                    if len(results) < limit and label.upper() != label:\n",
    "                        results_upper = self.query_wikidata(config, label.upper(), select = select, limit = limit - len(results), nested = True)\n",
    "                        results.update(results_upper)\n",
    "\n",
    "                    wikidata.label_entry_map[label] = list(results.keys())\n",
    "                    WikiData.new_labels += 1\n",
    "                    for key, value in results.items():\n",
    "                        if key not in wikidata.entries:\n",
    "                            wikidata.entries[key] = value\n",
    "                            WikiData.new_entries += 1\n",
    "            if results:\n",
    "                return results\n",
    "            else:\n",
    "                # print(\"No matching Wikidata entry found.\")\n",
    "                return []\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Query failed: {e}\")\n",
    "\n",
    "    def get_uri(self, config:Config, label:str, allow_query = True):\n",
    "        if label in self.label_entry_map:\n",
    "            return self.label_entry_map[label]\n",
    "        elif allow_query:\n",
    "            res = self.query_wikidata(config, label)\n",
    "            if res == False:\n",
    "                print(\"Could not get URI. Query limit reached.\")\n",
    "                return False\n",
    "            if res:\n",
    "                self.save(config)\n",
    "            return self.label_entry_map[label]\n",
    "\n",
    "wikidata = WikiData(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries done: 0\n",
      "New labels: 0\n",
      "New entries: 0\n",
      "query_wikidata_for_instances executed in 0.05301094055175781 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_function\n",
    "def query_wikidata_for_instances(config:Config, instance_dict:InstanceDict,wikidata:WikiData, stop_at = None):\n",
    "    for instance in instance_dict.instances.values():\n",
    "        if instance.uri: \n",
    "            if isinstance(instance.uri, str):\n",
    "                continue\n",
    "            elif isinstance(instance.uri, int):\n",
    "                if instance.uri == -1:\n",
    "                    # already queried, no URI found\n",
    "                    continue\n",
    "            if isinstance(instance.uri, list):\n",
    "                if len(instance.uri) > 0:\n",
    "                    continue    \n",
    "        \n",
    "        temp_res = []\n",
    "        check = [instance.name] + getattr(instance, 'also_known_as', [])\n",
    "        i = 0\n",
    "        while i < len(check):\n",
    "            label = check[i]\n",
    "            res = wikidata.get_uri(config, label)\n",
    "            if res == False:\n",
    "                print(\"Could not query properly. Not saving this instance.\")\n",
    "                whitelist.save(config)\n",
    "                return\n",
    "            else:\n",
    "                temp_res += res\n",
    "            i += 1\n",
    "        if temp_res:\n",
    "            # We found some results\n",
    "            instance.uri = temp_res\n",
    "        else:\n",
    "            instance.uri = -1\n",
    "    whitelist.save(config)\n",
    "    WikiData.print_updates()\n",
    "\n",
    "query_wikidata_for_instances(config, whitelist, wikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if config.debug:\n",
    "#     WikiData.queries_done = 0\n",
    "#     WikiData.new_labels = 0\n",
    "#     WikiData.new_entries = 0\n",
    "#     config.wikidata_query_limit += 5\n",
    "#     config.wikidata_query_limit = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_instance_occurrence_matrix = count_occurrences(paper_nlp_paths, instances)\n",
    "\n",
    "# free unneeded memory\n",
    "del paper_nlp_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "run_debug_test(config, instances, papers, paper_instance_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_instances(config: Config,matrix, instances, instance_types_dict=None,):\n",
    "    # total occurrences of each instance\n",
    "    instance_occurrences = {}\n",
    "    \n",
    "    for i, instance in enumerate(instances):\n",
    "        instance_occurrences[instance] = matrix[:, i].sum()\n",
    "    sorted_instances = {k: float(v) for k, v in sorted(instance_occurrences.items(), key=lambda item: item[1], reverse=True) if v > 0}\n",
    "    filepath = os.path.join(config.get_output_path(),'instance_occurrences')\n",
    "    with open(filepath + '.json', 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(sorted_instances, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    sorted_instance_list = list(sorted_instances.keys())\n",
    "\n",
    "\n",
    "    if instance_types_dict is not None:\n",
    "        # Instances should be sorted by their type\n",
    "        type_lists = [[] for _ in range(len(instance_types_dict))]\n",
    "        for instance in sorted_instance_list:\n",
    "            for type_ID, instance_type in enumerate(instance_types_dict):\n",
    "                if instance in instance_types_dict[instance_type]:\n",
    "                    type_lists[type_ID].append(instance)\n",
    "        type_sorted_instances = [item for sublist in type_lists for item in sublist]\n",
    "\n",
    "    new_order = [0] * len(sorted_instance_list)\n",
    "    for i, instance in enumerate(type_sorted_instances):\n",
    "        new_order[i] = instances.index(instance)\n",
    "\n",
    "    return type_sorted_instances, new_order\n",
    "\n",
    "def remove_zeros(matrix, columns=True, rows=True, row_lists=None, column_lists=None):\n",
    "    # remove all columns that are all zeros\n",
    "    if columns:\n",
    "        deleted_columns = np.all(matrix == 0, axis=0)\n",
    "        matrix = matrix[:, ~np.all(matrix == 0, axis=0)]\n",
    "\n",
    "    # remove all rows that are all zeros\n",
    "    if rows:\n",
    "        deleted_rows = np.all(matrix == 0, axis=1)\n",
    "        matrix = matrix[~np.all(matrix == 0, axis=1)]\n",
    "\n",
    "    \n",
    "    return matrix, [deleted_columns, deleted_rows]\n",
    "\n",
    "def update_instances(matrix, instances, instance_types_dict=None):\n",
    "    instances, new_order = sort_instances(config, matrix, instances, instance_types_dict)\n",
    "\n",
    "    new_order = np.array(new_order)\n",
    "    matrix = matrix[:, new_order]\n",
    "    \n",
    "    matrix, deletions = remove_zeros(matrix)\n",
    "    return matrix, instances, deletions\n",
    "\n",
    "paper_instance_occurrence_matrix, instances, deletions = update_instances(paper_instance_occurrence_matrix, instances, instance_types_dicts)\n",
    "\n",
    "def handle_deletions(input, deletions, rows = True):\n",
    "    \"\"\"\n",
    "    input: list, dict or np.ndarray\n",
    "    deletions: list of bools\n",
    "    rows: if True, deletions[1] is used, else deletions[0]\n",
    "    \"\"\"\n",
    "    delID = 1 if rows else 0\n",
    "\n",
    "    if deletions[delID].any():\n",
    "        # rows were deleted, in this case: papers\n",
    "        if isinstance(input, list):\n",
    "            input = [item for i, item in enumerate(input) if not deletions[delID][i]]\n",
    "        elif isinstance(input, dict):\n",
    "            input = {key: item for i, (key, item) in enumerate(input.items()) if not deletions[delID][i]}\n",
    "        elif isinstance(input, np.ndarray):\n",
    "            input = input[~deletions[delID]]\n",
    "    return input\n",
    "\n",
    "papers = handle_deletions(papers, deletions)\n",
    "# free unneeded memory\n",
    "del deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_debug_test(config, instances, papers, paper_instance_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all text files\n",
    "def get_paper_full_text(directory):\n",
    "    paper_full_text = {}\n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(folder_path, file)\n",
    "                    paper_full_text[file[:-4]] = file_path\n",
    "                    break\n",
    "\n",
    "    return paper_full_text\n",
    "\n",
    "paper_full_text = get_paper_full_text('G:/Meine Ablage/SE2A-B42-Aerospace-knowledge-SWARM-SLR/00_PDFs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: find occurrences of instances in full text of papers\n",
    "import sys\n",
    "from bisect import bisect_left\n",
    "# from sortedcontainers import SortedSet\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "class PosInPaper:\n",
    "    def __init__(self):\n",
    "        # List of paper identifiers\n",
    "        self.papers = []\n",
    "        # List of literals\n",
    "        self.literals = []\n",
    "        # Dict of unique words across all literals\n",
    "        self.words = {}\n",
    "        self.word_len = []\n",
    "        # List of unique combinations of words across all literals\n",
    "        self.word_combinations = {}\n",
    "        self.word_combination_lists = []\n",
    "        self.word_combination_index_literal = {}\n",
    "        # 2D list mapping pairs of literals to their word combination index\n",
    "        self.word_combination_index_literal_literal = []\n",
    "        # 2D list of SortedSets, each containing the positions of a word in a paper\n",
    "        self.word_occurrences_in_papers = []\n",
    "        # 3D list containing the minimum distances between word combinations in each paper\n",
    "        self.min_distances = []\n",
    "\n",
    "    @time_function\n",
    "    def populate(self, config: Config, papers: list, literals: list[str], paper_full_text, optimize=True):\n",
    "        \"\"\"\n",
    "        Populates the internal data structures with occurrences and distances of literals in papers.\n",
    "\n",
    "        Parameters:\n",
    "        - config (Config): Configuration object containing settings.\n",
    "        - papers (list): List of paper identifiers.\n",
    "        - literals (list[str]): List of literals to process.\n",
    "        - paper_full_text (dict): Mapping from paper identifiers to their full text file paths.\n",
    "        - optimize (bool): Flag to optimize data structures after population.\n",
    "        \"\"\"\n",
    "        self.initialize_variables(papers, literals)\n",
    "        self.process_literals()\n",
    "        self.process_literal_combinations()\n",
    "        self.setup_data_structures()\n",
    "        self.find_occurrences_in_texts(paper_full_text)\n",
    "        if optimize:\n",
    "            self.optimize_data()\n",
    "\n",
    "    def update_list_attribute(self, list, name):\n",
    "        existing = getattr(self, name)\n",
    "        if not existing:\n",
    "            setattr(self, name, list)\n",
    "        else:\n",
    "            if existing != list:\n",
    "                print(f\"Warning: {name} has changed.\")\n",
    "                for item in list:\n",
    "                    if item not in existing:\n",
    "                        print(f\"Item {item} is new.\")\n",
    "                        existing.append(item)\n",
    "                # update\n",
    "                raise NotImplementedError(\"create a function to update other relying attributes\")\n",
    "\n",
    "\n",
    "    @time_function\n",
    "    def initialize_variables(self, papers, literals):\n",
    "        \"\"\"\n",
    "        Initializes basic variables for the class instance.\n",
    "\n",
    "        Parameters:\n",
    "        - papers (list): List of paper identifiers.\n",
    "        - literals (list): List of literals to process.\n",
    "        \"\"\"\n",
    "        if not self.papers:\n",
    "            self.papers = papers\n",
    "        else:\n",
    "            if self.papers != papers:\n",
    "                print(\"Warning: Papers have changed.\")\n",
    "                for paper in papers:\n",
    "                    if paper not in self.papers:\n",
    "                        print(f\"Paper {paper} is new.\")\n",
    "                        self.papers.append(paper)\n",
    "        # self.papers = papers\n",
    "        \n",
    "        if not self.literals:\n",
    "            self.literals = literals\n",
    "        else:\n",
    "            if self.literals != literals:\n",
    "                print(\"Warning: Literals have changed.\")\n",
    "                for literal in literals:\n",
    "                    if literal not in self.literals:\n",
    "                        print(f\"Literal {literal} is new.\")\n",
    "                        self.literals.append(literal)\n",
    "                        self.word_combination_index_literal[literal] = None\n",
    "\n",
    "        if len(self.literals) != len(self.word_combination_index_literal):\n",
    "            for literal in self.literals:\n",
    "                if literal not in self.word_combination_index_literal:\n",
    "                    self.word_combination_index_literal[literal] = None\n",
    "            # sort self.word_combination_index_literal by self.literals\n",
    "            self.word_combination_index_literal = {k: self.word_combination_index_literal[k] for k in self.literals}\n",
    "        if isinstance(self.word_combination_index_literal_literal, np.ndarray) and self.word_combination_index_literal_literal.size == 0:\n",
    "            self.word_combination_index_literal_literal = np.full((len(self.literals), len(self.literals)), None, dtype=object)\n",
    "        elif isinstance(self.word_combination_index_literal_literal, list) and self.word_combination_index_literal_literal == []:\n",
    "            self.word_combination_index_literal_literal = [[None] * len(self.literals) for _ in range(len(self.literals))]\n",
    "        elif len(self.literals) != len(self.word_combination_index_literal_literal):\n",
    "            # pad self.word_combination_index_literal_literal\n",
    "            len_dif = len(self.literals) - len(self.word_combination_index_literal_literal)\n",
    "            self.word_combination_index_literal_literal = np.pad(self.word_combination_index_literal_literal, ((0, len_dif), (0, len_dif)), 'constant', constant_values=None)\n",
    "            # self.word_combination_index_literal_literal = [[None] * len(self.literals) for _ in range(len(self.literals))]\n",
    "\n",
    "        # self.literals = literals\n",
    "\n",
    "    @time_function\n",
    "    def process_literals(self):\n",
    "        \"\"\"\n",
    "        Processes each literal to extract and store unique words and word combinations.\n",
    "\n",
    "        Parameters:\n",
    "        - literals (list): List of literals to process.\n",
    "        \"\"\"\n",
    "        for lit in self.literals:\n",
    "            word_list = split_string(lit)\n",
    "            self.add_words(word_list)\n",
    "            self.add_if_word_combination(word_list, lit)\n",
    "\n",
    "    def add_words(self, word_list):\n",
    "        \"\"\"\n",
    "        Adds unique words from a list to the internal list of words.\n",
    "\n",
    "        Parameters:\n",
    "        - word_list (list): List of words to add.\n",
    "        \"\"\"\n",
    "        for word in word_list:\n",
    "            if word not in self.words:\n",
    "                self.words[word] = len(self.words)\n",
    "                self.word_len.append(len(word))\n",
    "\n",
    "    def add_if_word_combination(self, word_list, lit):\n",
    "        \"\"\"\n",
    "        Adds a unique combination of words from a list to the internal list of word combinations.\n",
    "\n",
    "        Parameters:\n",
    "        - word_list (list): List of words forming a combination.\n",
    "        - lit (str): The literal corresponding to the word combination.\n",
    "        \"\"\"\n",
    "        if len(word_list) > 1:\n",
    "            pos = self.word_combination_index_literal.get(lit, -1)\n",
    "            if pos == -1 or pos == None:\n",
    "                froz = frozenset(word_list)\n",
    "                pos = len(self.word_combinations)\n",
    "                self.add_word_combination(froz, pos)\n",
    "                self.word_combination_index_literal[lit] = pos\n",
    "    \n",
    "    def add_word_combination(self, froz, pos):\n",
    "        self.word_combinations[froz] = pos\n",
    "        self.word_combination_lists.append([self.words[word] for word in sorted(froz, key=len, reverse=True)])\n",
    "\n",
    "    @time_function\n",
    "    def process_literal_combinations(self):\n",
    "        \"\"\"\n",
    "        Processes combinations of literals to store their indices in the internal data structure.\n",
    "\n",
    "        Parameters:\n",
    "        - literals (list): List of literals to process.\n",
    "        \"\"\"\n",
    "        # Use a dictionary for quick lookup and storage\n",
    "        combination_index = len(self.word_combinations)\n",
    "\n",
    "        for id1, literal1 in enumerate(self.literals):\n",
    "            for id2 in range(id1 + 1, len(self.literals)):\n",
    "                if self.word_combination_index_literal_literal[id1][id2] is not None:\n",
    "                    continue\n",
    "                literal2 = self.literals[id2]\n",
    "                # Use a sorted tuple for consistent ordering\n",
    "                froz = frozenset(split_string(literal1) + split_string(literal2))\n",
    "                # Check if the combination is already in the dictionary\n",
    "                pos = self.word_combinations.get(froz, -1)\n",
    "                if pos == -1:\n",
    "                    pos = combination_index\n",
    "                    combination_index += 1\n",
    "\n",
    "                    self.add_word_combination(froz, pos)\n",
    "\n",
    "                # Update the matrix with the index of the combination\n",
    "                self.word_combination_index_literal_literal[id1][id2] = pos\n",
    "                self.word_combination_index_literal_literal[id2][id1] = pos\n",
    "\n",
    "    @time_function\n",
    "    def setup_data_structures(self):\n",
    "        \"\"\"\n",
    "        Initializes the data structures for storing word occurrences and minimum distances.\n",
    "\n",
    "        Parameters:\n",
    "        - papers (list): List of paper identifiers.\n",
    "        \"\"\"\n",
    "        if self.word_occurrences_in_papers == []:\n",
    "            self.word_occurrences_in_papers = [[[] for _ in self.words] for _ in self.papers]\n",
    "        if isinstance(self.min_distances, list) and self.min_distances == [] or self.min_distances is None:\n",
    "            self.min_distances = np.full((len(self.papers), len(self.word_combinations)), -2, dtype=int)\n",
    "        # If new papers or words have been added, update the data structures\n",
    "        if len(self.papers) > len(self.min_distances):\n",
    "            self.min_distances = np.pad(self.min_distances, ((0, len(self.papers) - len(self.min_distances)), (0, 0)), 'constant', constant_values=-2)\n",
    "        if len(self.word_combinations) > len(self.min_distances[0]):\n",
    "            len_dif = len(self.word_combinations) - len(self.min_distances[0])\n",
    "            self.min_distances = np.pad(self.min_distances, ((0, 0), (0, len_dif)), 'constant', constant_values=-2)\n",
    "\n",
    "    @time_function\n",
    "    def find_occurrences_in_texts(self, paper_full_text):\n",
    "        \"\"\"\n",
    "        Finds and stores the occurrences of each word in the full text of each paper.\n",
    "\n",
    "        Parameters:\n",
    "        - papers (list): List of paper identifiers.\n",
    "        - paper_full_text (dict): Mapping from paper identifiers to their full text file paths.\n",
    "        \"\"\"\n",
    "        for paperID, paper in enumerate(self.papers):\n",
    "            if paper in paper_full_text:\n",
    "                with open(paper_full_text[paper], 'r', encoding=\"utf8\") as f:\n",
    "                    text = f.read().lower()\n",
    "                    for word, wordID in self.words.items():\n",
    "                        if not self.word_occurrences_in_papers[paperID][wordID]:\n",
    "                            self.find_and_add_word_occurrences(paperID, wordID, word, text)\n",
    "            else:\n",
    "                print(f\"Paper {paper} has no full text available.\")\n",
    "\n",
    "    def find_and_add_word_occurrences(self, paperID, wordID, word, text):\n",
    "        \"\"\"\n",
    "        Finds and adds the occurrences of a word in a paper's text to the internal data structure.\n",
    "\n",
    "        Parameters:\n",
    "        - paperID (int): The index of the paper in the internal list.\n",
    "        - wordID (int): The index of the word in the internal list.\n",
    "        - word (str): The word to find occurrences of.\n",
    "        - text (str): The full text of the paper.\n",
    "        \"\"\"\n",
    "        pos = text.find(word)\n",
    "        while pos != -1:\n",
    "            # self.word_occurrences_in_papers[paperID][wordID].add(pos)\n",
    "            self.word_occurrences_in_papers[paperID][wordID].append([pos, wordID])\n",
    "            pos = text.find(word, pos + 1)\n",
    "\n",
    "    @time_function\n",
    "    def optimize_data(self):\n",
    "        \"\"\"\n",
    "        Optimizes the internal data structures for faster access and smaller memory footprint.\n",
    "        \"\"\"\n",
    "        # self.word_combination_index_literal_literal = np.array(self.word_combination_index_literal_literal, dtype=int)\n",
    "        for paperID in range(len(self.papers)):\n",
    "            for wordID in range(len(self.words)):\n",
    "                # self.word_occurrences_in_papers[paperID][wordID] = SortedSet(self.word_occurrences_in_papers[paperID][wordID])\n",
    "                if not self.word_occurrences_in_papers[paperID][wordID]:\n",
    "                    continue\n",
    "                if isinstance(self.word_occurrences_in_papers[paperID][wordID][0], int):\n",
    "                    self.word_occurrences_in_papers[paperID][wordID] = [(x, wordID) for x in self.word_occurrences_in_papers[paperID][wordID]]\n",
    "                    print (f\"Optimizing {list(self.words.keys())[wordID]} in paper {paperID}\")\n",
    "                for occurrence in self.word_occurrences_in_papers[paperID][wordID]:\n",
    "                    if isinstance(occurrence, int):\n",
    "                        self.word_occurrences_in_papers[paperID][wordID] = [(occurrence, wordID)]\n",
    "                        # break\n",
    "                        raise Exception(\"This should not happen\")\n",
    "\n",
    "    def save_to_csv(self, config:Config = None, path = None, name = \"pos_in_paper\"):\n",
    "        if path is None:\n",
    "            path = config.get_output_path()\n",
    "\n",
    "        # save min_distances to csv\n",
    "        # dump self.min_distances to csv, with self.papers as row headers and self.word_combinations as column headers\n",
    "        filepath = os.path.join(path, name + '_min_distances.csv')\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            word_combinations = [\"_\".join(sorted(froz, key=len, reverse=True)) for froz in self.word_combinations.keys()]\n",
    "            f.write(\"papers\" + config.csv_separator + config.csv_separator.join(word_combinations) + '\\n')\n",
    "            for i, paper in enumerate(self.papers):\n",
    "                f.write(paper + config.csv_separator + config.csv_separator.join(map(str, self.min_distances[i])) + '\\n')\n",
    "        \n",
    "\n",
    "\n",
    "    @time_function\n",
    "    def save_to_file(self, config, path=None, name = \"pos_in_paper\", check_size=False, min_distance_to_csv=False, backup = True):\n",
    "        \"\"\"\n",
    "        Saves the internal data structures to files for persistence.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str, optional): The base path for the output files. Defaults to \"pos_in_paper\".\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = config.get_output_path()\n",
    "        filepath = os.path.join(path, name + '.json')\n",
    "        \n",
    "        data = {}\n",
    "\n",
    "        for key, value in self.__dict__.items():\n",
    "            # if key == \"min_distances\" or key == \"word_combination_index_literal_literal\":\n",
    "            if value.__class__.__name__ == \"ndarray\": # min_distances, word_combination_index_literal_literal\n",
    "                data[key] = value.tolist()\n",
    "            # if key == \"min_distances\":\n",
    "            #     data[key] = value.tolist()\n",
    "            elif key == \"word_combinations\":\n",
    "                data[key] = {\"_\".join(key): value for key, value in self.word_combinations.items()}\n",
    "            else:\n",
    "                data[key] = value\n",
    "            if check_size:\n",
    "                # Construct the file name for each sub-dictionary\n",
    "                filepath = os.path.join(path, f\"{name}_{key}.json\")\n",
    "                with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(data[key], f, ensure_ascii=False)\n",
    "            pass\n",
    "\n",
    "        if min_distance_to_csv:\n",
    "            self.save_to_csv(config, path, name)\n",
    "        \n",
    "        if backup:\n",
    "            backup_path = os.path.join(path, name + \"_backup\" + '.json')\n",
    "            if os.path.exists(filepath):\n",
    "                existing_is_healthy = True\n",
    "                try:\n",
    "                    self.load_from_file(config, path, name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Overwriting existing save\")\n",
    "                    existing_is_healthy = False\n",
    "                if existing_is_healthy:\n",
    "                    if os.path.exists(backup_path):\n",
    "                        os.remove(backup_path)\n",
    "                    os.rename(filepath, backup_path)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "    @time_function\n",
    "    def load_from_file(self, config, path=None, name=\"pos_in_paper\", backup=True):\n",
    "        \"\"\"\n",
    "        Loads the internal data structures from files.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str, optional): The base path for the input files. Defaults to \"pos_in_paper\".\n",
    "        \"\"\"\n",
    "        if path is None:\n",
    "            path = config.get_output_path()\n",
    "        filepath = os.path.join(path, name + '.json')\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {filepath}: {e}\")\n",
    "            if backup:\n",
    "                backup_path = os.path.join(path, name + \"_backup\" + '.json')\n",
    "                if os.path.exists(backup_path):\n",
    "                    print(f\"Trying to load backup file {backup_path}\")\n",
    "                    with open(backup_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                else:\n",
    "                    raise Exception(f\"No backup file found at {backup_path}\")\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "\n",
    "        for key, value in data.items():\n",
    "            if key == \"word_combinations\":\n",
    "                setattr(self, key, {frozenset(split_string(sub_key)): i for i, sub_key in enumerate(value)})\n",
    "            elif key == \"min_distances\" or key == \"word_combination_index_literal_literal\":\n",
    "                setattr(self, key, np.array(value))\n",
    "            else:\n",
    "                try:\n",
    "                    setattr(self, key, value)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Error loading pos_in_paper attribute {key}: {e}\")\n",
    "\n",
    "        self.setup_data_structures()\n",
    "        \n",
    "    @time_function\n",
    "    def calculate_all_possible(self):\n",
    "        \"\"\"\n",
    "        Calculates the minimum distances between all possible combinations of literals in all papers.\n",
    "        \"\"\"\n",
    "        save_every = None\n",
    "        if len(self.papers) > 300:\n",
    "            print(\"Warning: This operation is computationally expensive and may take a long time.\")\n",
    "            save_every = 300\n",
    "        for p in range(len(self.papers)):\n",
    "            if save_every and p % save_every == 0:\n",
    "                print(f\"Processing paper {p} of {len(self.papers)}\")\n",
    "                self.save_to_file(config)\n",
    "            for w in range(len(self.word_combinations)):\n",
    "                self.find_min_distance_by_id(p, w)\n",
    "            # for i in range(len(self.literals)):\n",
    "            #     for j in range(i + 1, len(self.literals)):\n",
    "            #         # get word_combination_index_literal_literal\n",
    "                    # self.find_min_distance_by_id(p, self.word_combination_index_literal_literal[i][j])\n",
    "\n",
    "    def find_min_distance_by_id(self, paperID, wcID):\n",
    "        \"\"\"\n",
    "        Finds the minimum distance between occurrences of literals in a paper.\n",
    "\n",
    "        Parameters:\n",
    "        - paper (str): The identifier for the paper.\n",
    "        - literals (list): A list of literals for which the distance is to be found.\n",
    "        - allow_call (bool): Flag to allow recursive call to get_min_distance.\n",
    "\n",
    "        Returns:\n",
    "        - int: The minimum distance between occurrences of the literals.\n",
    "        \"\"\"\n",
    "        distance = self.min_distances[paperID][wcID]\n",
    "\n",
    "        if distance == -1:\n",
    "            # word combination not found in paper\n",
    "            return -1\n",
    "        if distance == -2:\n",
    "            # calculate distance\n",
    "            pass\n",
    "        else:\n",
    "            return distance\n",
    "        \n",
    "        list_ids = self.word_combination_lists[wcID]\n",
    "        # since we have attached global Word IDs to the occurences, we need to map to their local position\n",
    "        list_ids_map = {list_ids[i]: i for i in range(len(list_ids))}\n",
    "        # literals = [list(self.words)[i] for i in list_ids]\n",
    "        \n",
    "        #TODO: It should be possible to remove smaller words from the list,\n",
    "        # if a larger word contains it:\n",
    "        # e.g. remove \"engine\" if \"engineer\" is in the list\n",
    "        ## The following implementation works, but is not used for now. Reasons:\n",
    "        ## 1. It could be slower than the current implementation\n",
    "        ## 2. It might be beneficial to future use-cases to not remove smaller words\n",
    "        # literals = [list(self.words)[key] for key in list_ids_map]\n",
    "        # # check if any literal is a substring of another\n",
    "        # for i, lit1 in enumerate(literals):\n",
    "        #     for j, lit2 in enumerate(literals):\n",
    "        #         if i != j and lit1 in lit2:\n",
    "        #             # if lit1 is a substring of lit2, remove it from the list\n",
    "        #             list_ids_map.pop(list_ids[i])\n",
    "        #             break\n",
    "        \n",
    "        lit_len = [self.word_len[i] for i in list_ids]\n",
    "\n",
    "        for i in list_ids:\n",
    "            if not self.word_occurrences_in_papers[paperID][i]:\n",
    "                self.min_distances[paperID][wcID] = -1\n",
    "                return -1\n",
    "        # Outsourced to optimize\n",
    "        # inputs = [[(x, i) for x in self.word_occurrences_in_papers[paperID][wordID]] for i, wordID in enumerate(list_ids)]\n",
    "        inputs = [self.word_occurrences_in_papers[paperID][wordID] for wordID in list_ids]\n",
    "\n",
    "        indices = [lst[0][0] for lst in inputs]\n",
    "        best = float('inf')\n",
    "\n",
    "        for item in sorted(sum(inputs, [])):\n",
    "            if item[0] not in indices:\n",
    "                continue\n",
    "            indices[list_ids_map[item[1]]] = item[0]\n",
    "            arr_min = min(indices)\n",
    "            best = min(max(indices) - arr_min - lit_len[indices.index(arr_min)], best)\n",
    "            if best <= 0:\n",
    "                best = 0\n",
    "                break\n",
    "        self.min_distances[paperID][wcID] = best\n",
    "\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_data_structures executed in 0.0 seconds\n",
      "load_from_file executed in 2.5283749103546143 seconds\n",
      "Warning: Literals have changed.\n",
      "initialize_variables executed in 0.0 seconds\n",
      "process_literals executed in 0.0009999275207519531 seconds\n",
      "process_literal_combinations executed in 0.010001897811889648 seconds\n",
      "setup_data_structures executed in 0.0 seconds\n",
      "find_occurrences_in_texts executed in 4.481794357299805 seconds\n",
      "optimize_data executed in 0.04300951957702637 seconds\n",
      "populate executed in 4.535805702209473 seconds\n"
     ]
    }
   ],
   "source": [
    "pos_in_paper = PosInPaper()\n",
    "\n",
    "# config.recalculate_pos_in_paper = True # May be used for debug purposes\n",
    "\n",
    "if not config.recalculate_pos_in_paper:\n",
    "    try:\n",
    "        pos_in_paper.load_from_file(config)\n",
    "    # print exception\n",
    "    except Exception as e:\n",
    "        # if config.debug:\n",
    "        #     raise e\n",
    "        print(e)\n",
    "        print(\"Starting from scratch.\")\n",
    "        \n",
    "        config.recalculate_pos_in_paper = True\n",
    "\n",
    "# TODO:\n",
    "# raise NotImplementedError(\"Implement a check that compares the loaded instances and papers with the current ones\")\n",
    "\n",
    "# if config.recalculate_pos_in_paper:\n",
    "pos_in_paper.populate(config, papers, instances, paper_full_text)\n",
    "    # pos_in_paper.save_to_file(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.recalculate_pos_in_paper or -2 in pos_in_paper.min_distances:\n",
    "    pos_in_paper.calculate_all_possible()\n",
    "    # Info: This method is extremely slow. requires more testing, which is currently done in a side project:\n",
    "    ## scripts\\SLR\\MVP\\test_case.ipynb\n",
    "    pos_in_paper.save_to_file(config)\n",
    "    config.recalculate_pos_in_paper = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: find the gap between the pieces of an instance\n",
    "import sys\n",
    "\n",
    "@time_function\n",
    "def find_instance_piece_gap(config:Config, papers, paper_full_text, instances, paper_instance_occurrence_matrix, pos_in_paper:PosInPaper):\n",
    "    error_matrix = np.zeros(paper_instance_occurrence_matrix.shape, dtype=float)\n",
    "    for paperID, paper in enumerate(papers):\n",
    "        if paperID % 100 == 0:\n",
    "            # print(f\"Processing paper {paperID} of {len(papers)}\")\n",
    "            pass\n",
    "        if paper in paper_full_text:\n",
    "            for i, instance in enumerate(instances):\n",
    "                if paper_instance_occurrence_matrix[paperID][i] == 0:\n",
    "                    continue\n",
    "                wcID = pos_in_paper.word_combination_index_literal[instance]\n",
    "                # TODO: handle if that instance has no word combination index entry\n",
    "                if wcID is None:\n",
    "                    # word has no distance\n",
    "                    continue\n",
    "                min_distance = pos_in_paper.find_min_distance_by_id(paperID, wcID)\n",
    "                if min_distance is None:\n",
    "                    pass\n",
    "                if min_distance > config.gap_too_large_threshold:\n",
    "                    # print(f\"Gap for {instance} in {paper} ({min_distance} > {GAP_TOO_LARGE_THRESHOLD})\")\n",
    "                    paper_instance_occurrence_matrix[paperID][i] = 0\n",
    "                    # get log base 10 of min distance\n",
    "                    error_matrix[paperID][i] = round(np.log10(min_distance), 1)\n",
    "                \n",
    "                # Some pieces may not be found in the full text\n",
    "                if min_distance == -1:\n",
    "                    # print(f\"{instance} not found in {paper} at all\")\n",
    "                    paper_instance_occurrence_matrix[paperID][i] = 0\n",
    "                    error_matrix[paperID][i] = min_distance\n",
    "                    # for these, we do not store the gap                    \n",
    "                    continue\n",
    "\n",
    "    return error_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_instance_piece_gap executed in 0.08324432373046875 seconds\n"
     ]
    }
   ],
   "source": [
    "error_matrix = find_instance_piece_gap(config, papers, paper_full_text, instances, paper_instance_occurrence_matrix, pos_in_paper)\n",
    "\n",
    "error_matrix, has_error = remove_zeros(error_matrix)\n",
    "error_papers = handle_deletions(papers, has_error)\n",
    "error_instances = handle_deletions(instances, has_error, rows = False)\n",
    "\n",
    "paper_instance_occurrence_matrix, instances, deletions = update_instances(paper_instance_occurrence_matrix, instances, instance_types_dicts)\n",
    "\n",
    "papers = handle_deletions(papers, deletions)\n",
    "\n",
    "instance_instance_co_occurrence_matrix = np.dot(paper_instance_occurrence_matrix.T, paper_instance_occurrence_matrix)\n",
    "\n",
    "# free unneeded memory\n",
    "del deletions, has_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year_paper_occurrence_matrix\n",
    "def create_year_paper_occurrence_matrix(papers_metadata, paper_instance_occurrence_matrix, papers, is_error_matrix=False):\n",
    "    year_papers = {}\n",
    "\n",
    "    for paper in papers_metadata:\n",
    "        if 'year' in papers_metadata[paper]:\n",
    "            year = int(papers_metadata[paper]['year'])\n",
    "            if year not in year_papers:\n",
    "                year_papers[year] = []\n",
    "            year_papers[year].append(paper)\n",
    "\n",
    "\n",
    "    earliest = min(year_papers)\n",
    "    latest = max(year_papers)\n",
    "    span = latest-earliest+1\n",
    "\n",
    "    for year in range(earliest, latest):\n",
    "        if year not in year_papers:\n",
    "            year_papers[year] = []\n",
    "\n",
    "    year_papers = {k: v for k, v in sorted(year_papers.items(), key=lambda item: item[0])}\n",
    "\n",
    "    if is_error_matrix:\n",
    "        # convert any value != 0 to 1\n",
    "        paper_instance_occurrence_matrix = np.where(paper_instance_occurrence_matrix != 0, 1, 0)\n",
    "\n",
    "    # create a year_instance_occurence matrix from the paper_instance_occurrence_matrix\n",
    "    year_instance_occurrence_matrix = np.zeros((span, paper_instance_occurrence_matrix.shape[1]), dtype=int)\n",
    "    for yearID, year in enumerate(year_papers):\n",
    "        for paper in year_papers[year]:\n",
    "            if paper in papers:\n",
    "                paperID = papers.index(paper)\n",
    "                year_instance_occurrence_matrix[yearID] += paper_instance_occurrence_matrix[paperID]\n",
    "    \n",
    "    return year_instance_occurrence_matrix, year_papers\n",
    "\n",
    "year_instance_occurrence_matrix, year_papers = create_year_paper_occurrence_matrix(papers_metadata, paper_instance_occurrence_matrix, papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Complete\n",
    "\n",
    "We now have:\n",
    "\n",
    "| Variable                          | Type    | Size         | Comments |\n",
    "|-----------------------------------|---------|--------------|----------|\n",
    "| error_instances                   | list    | 165          | Comments |\n",
    "| error_matrix                      | ndarray | (999, 165)   | Comments |\n",
    "| error_papers                      | list    | 999          | Comments |\n",
    "| gap_too_large_threshold           | int     | n.a.         | Comments |\n",
    "| instance_piece_gap                | dict    | 151          | Comments |\n",
    "| instance_types_dicts              | dict    | 5            | Comments |\n",
    "| instances                         | list    | 315          | Comments |\n",
    "| paper_full_text                   | dict    | 1029         | Comments |\n",
    "| paper_instance_occurrence_matrix  | ndarray | (1003, 315)  | Comments |\n",
    "| papers                            | list    | 1003         | Comments |\n",
    "| pos_in_paper                      | dict    | 1003         | Comments |\n",
    "\n",
    "Consisting of:\n",
    "* The paper_instance_occurrence_matrix, binary listing if a term (instance) is present in a paper\n",
    "  * papers x instances\n",
    "* The error_matrix, of all instances that were dropped from the paper_instance_occurrence_matrix\n",
    "  * error_papers x error_instances\n",
    "\n",
    "And some leftover variables:\n",
    "* instance_types_dicts, listing all instance types (\"process\", \"software\", ...) and their respective instance sets (\"Curation\", \"Knowledge Work\", ...)\n",
    "* paper_full_text, containing each papers full text\n",
    "  * pos_in_paper, listing for each paper: for each instance: each position of that instance in that papers full text.\n",
    "* instance_piece_gap, a dict listing all instances made up from compound words (e.g. \"Knowledge Work\", and their minimum distance in each papers full text)\n",
    "  * gap_too_large_threshold, defining how far appart a finding of \"Knowledge\" and \"Work\" would qualify as \"Knowledge Work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~3 min | {( len(papers) * len(instances) ) / (3 * 1000) }seconds  compare proximity of all instances with one antoher\n",
    "# ~8 min right now.\n",
    "# 3 min 30 sec with 164 papers and 339 instances\n",
    "@time_function\n",
    "def calculate_proximity_matrix(config:Config, pos_in_paper:PosInPaper, instances, mode = \"sqrt\", try_to_save_time = False):\n",
    "    # TODO: Optimize this function.\n",
    "    # each instance needs to have it's occurences as pieces clustered together, so that only those below max distance are considered\n",
    "\n",
    "    # create a np zeros matrix of size instances x instances\n",
    "    instance_instance_proximity_matrix = np.zeros((len(instances), len(instances)), dtype=float)\n",
    "    \n",
    "    # alternatives are:\n",
    "    # \"sqrt\" - 1 / (square root of the distance)\n",
    "    # \"linear\" - 1 / distance\n",
    "    # \"binary\" - 1 if distance < MAX_GAP_THRESHOLD, 0 otherwise\n",
    "    # \"log\" - 1 / log(distance) \n",
    "    \n",
    "    # There is a chance that pos_in_paper papers and instances are out of sync with the current papers and instances\n",
    "    paperIDs = [paperID for paperID, name in enumerate(pos_in_paper.papers) if name in papers] \n",
    "    lID_map = {instances.index(name):instanceID for instanceID, name in enumerate(pos_in_paper.literals) if name in instances}\n",
    "\n",
    "    for id1 in range(len(instances)):\n",
    "        # print (f\"Processing {id1} of {len(instances)}: {instance1}\")\n",
    "        for id2 in range(id1+1, len(instances)):\n",
    "            # FIXME: this resulted in a matrix which was not symmetric.\n",
    "            # That hints at a problem with the calclulation, [id1][id2] and [id2][id1] should be the same\n",
    "            wcID = pos_in_paper.word_combination_index_literal_literal[lID_map[id1]][lID_map[id2]]\n",
    "            for paperID in paperIDs:\n",
    "                distance = pos_in_paper.find_min_distance_by_id(paperID, wcID)\n",
    "                \n",
    "                if distance < 0:\n",
    "                    # print(f\"Error: {instance1} and {instance2} not found in {paper}\")\n",
    "                    continue\n",
    "                result = 0.0\n",
    "                if distance == 0:\n",
    "                    result = 1\n",
    "                elif distance == 1:\n",
    "                    result = 1\n",
    "                elif mode == \"sqrt\":\n",
    "                    result = 1 / np.sqrt(distance)\n",
    "                elif mode == \"linear\":\n",
    "                    result = 1 / distance\n",
    "                elif mode == \"binary\":\n",
    "                    result = 1 if distance < config.gap_too_large_threshold else 0\n",
    "                elif mode == \"log\":\n",
    "                    result = 1 / np.log(distance)\n",
    "                else:\n",
    "                    print(\"Error: unknown mode\")\n",
    "                    break\n",
    "                if result > 0.0:\n",
    "                    instance_instance_proximity_matrix[id1][id2] += result\n",
    "                    instance_instance_proximity_matrix[id2][id1] += result\n",
    "\n",
    "    #TODO rest doesnt seem to work, short fix implemented:\n",
    "    # create a copy of labels that only contains instances that are in the proximity matrix\n",
    "\n",
    "    instance_instance_proximity_matrix, deletions = remove_zeros(instance_instance_proximity_matrix)\n",
    "    proximity_instances = handle_deletions(instances, deletions, rows=False)\n",
    "    \n",
    "    return instance_instance_proximity_matrix, proximity_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_proximity_matrix executed in 5.36823296546936 seconds\n"
     ]
    }
   ],
   "source": [
    "instance_instance_proximity_matrix, proximity_instances = calculate_proximity_matrix(config, pos_in_paper, instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "def get_rules(matrix, columns):\n",
    "    # AttributeError: 'numpy.ndarray' object has no attribute 'dtypes'\n",
    "    dataframe = pd.DataFrame(matrix, columns=columns).astype(bool)\n",
    "\n",
    "    # for each process:\n",
    "    # create one res\n",
    "\n",
    "    res = apriori(dataframe, min_support=0.4, use_colnames=True, max_len=2)\n",
    "\n",
    "    # visualize res\n",
    "    res = res.sort_values(by='support', ascending=False)\n",
    "    res = res.reset_index(drop=True)\n",
    "    # res\n",
    "\n",
    "    rules = association_rules(res)\n",
    "    # sort rules by confidence\n",
    "    # rules = rules.sort_values(by='confidence', ascending=False)\n",
    "    rules = rules.sort_values(by='lift', ascending=False) # (propably most important)\n",
    "    # rules = rules.sort_values(by='leverage', ascending=False)\n",
    "    # export rules to csv\n",
    "    return rules\n",
    "\n",
    "rules = get_rules(paper_instance_occurrence_matrix, instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cross_type_rules(rules):\n",
    "    cross_type = [False] * len(rules)\n",
    "\n",
    "    for i, antecentent in enumerate(rules.antecedents):\n",
    "        antecentent, = antecentent\n",
    "        consequent, = rules.iloc[i].consequents\n",
    "        type1, type2 = None, None\n",
    "        for type in instance_types_dicts:\n",
    "            if antecentent in instance_types_dicts[type]:\n",
    "                type1 = type\n",
    "            if consequent in instance_types_dicts[type]:\n",
    "                type2 = type\n",
    "            if type1 and type2:\n",
    "                break\n",
    "        if type1 != type2:\n",
    "            cross_type[i] = True\n",
    "            # print(rules.iloc[i])\n",
    "\n",
    "    # create a copy for all rules that are cross type\n",
    "    rules_cross_type = rules[cross_type].copy()\n",
    "    return rules_cross_type\n",
    "\n",
    "rules_cross_type = identify_cross_type_rules(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_done = False\n",
    "\n",
    "def print_kg_dict(config:Config, kg_dict, header):\n",
    "    filepath = os.path.join(config.get_output_path(), 'instance_relations.csv')\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(header + '\\n')\n",
    "        total_comma = len(kg_dict) - 1\n",
    "        for pos1, type1 in enumerate(kg_dict):\n",
    "            preamble = \",\" * pos1\n",
    "            for pos2, type2 in enumerate(kg_dict[type1]):\n",
    "                intermediate = \",\" * (pos2 + 1)\n",
    "                rest_comma = \",\" * (total_comma - pos1 - pos2)\n",
    "                for i1, i2 in kg_dict[type1][type2]:\n",
    "                    f.write(preamble + i1 + intermediate + i2 + rest_comma + '\\n')\n",
    "\n",
    "def knowledge_graph_population_cross_type_rules(config:Config, rules:association_rules, instance_types_dicts):\n",
    "    header = config.csv_separator.join(instance_types_dicts.keys())\n",
    "    # Triangular dict\n",
    "    dummy_dict = {}\n",
    "    for instance_type in instance_types_dicts:\n",
    "        dummy_dict[instance_type] = {}\n",
    "        for type in instance_types_dicts:\n",
    "            if type not in dummy_dict:\n",
    "                dummy_dict[instance_type][type] = []\n",
    "    for i, antecentent in enumerate(rules.antecedents):\n",
    "        antecentent, = antecentent\n",
    "        consequent, = rules.iloc[i].consequents\n",
    "        first_type = None\n",
    "        second_type = None\n",
    "        for type in instance_types_dicts:\n",
    "            if antecentent in instance_types_dicts[type]:\n",
    "                # type1 = type\n",
    "                if not first_type:\n",
    "                    first_type = type\n",
    "                    first_instance = antecentent\n",
    "                else:\n",
    "                    second_type = type\n",
    "                    second_instance = antecentent\n",
    "            if consequent in instance_types_dicts[type]:\n",
    "                if not first_type:\n",
    "                    first_type = type\n",
    "                    first_instance = consequent\n",
    "                else:\n",
    "                    second_type = type\n",
    "                    second_instance = consequent\n",
    "            if first_type and second_type:\n",
    "                break\n",
    "        if first_type != second_type:\n",
    "            dummy_dict[first_type][second_type].append((first_instance, second_instance))\n",
    "\n",
    "    print_kg_dict(config, dummy_dict, header)\n",
    "\n",
    "    return True\n",
    "\n",
    "try:\n",
    "    kg_done = knowledge_graph_population_cross_type_rules(config, rules_cross_type, instance_types_dicts)\n",
    "except Exception as e:\n",
    "    if config.debug:\n",
    "        raise e\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare csv file again\n",
    "# process,software,data item,data model,data format specification,interchange format,data visualization,data validation,inference,source\n",
    "\n",
    "@time_function\n",
    "def knowledge_graph_population(config:Config, instance_types_dicts, property_types_dicts, instance_instance_proximity_matrix, proximity_instances):\n",
    "    columns = list(instance_types_dicts.keys()) \n",
    "    # columns += list(property_types_dicts.keys())\n",
    "    # columns = ['process', 'software', 'data item', 'data model', 'data format specification', 'data visualization', 'data validation', 'inference']\n",
    "\n",
    "    rows = []\n",
    "    for c_ID, column in enumerate(columns):\n",
    "        for instance in instance_types_dicts[column]:\n",
    "            # add the instance to the csv with each of their relations\n",
    "            if instance not in proximity_instances:\n",
    "                continue\n",
    "            instance_index = proximity_instances.index(instance)\n",
    "            for oc_ID, other_column in enumerate(columns):\n",
    "                if other_column not in instance_types_dicts:\n",
    "                    if other_column in property_types_dicts:\n",
    "                        #TODO: handle properties specially\n",
    "                        continue\n",
    "                    continue\n",
    "                if other_column != column:\n",
    "                    other_column_instances = instance_types_dicts[other_column]\n",
    "                    for other_instance in other_column_instances:\n",
    "                        if other_instance not in proximity_instances:\n",
    "                            continue\n",
    "                        other_instance_index = proximity_instances.index(other_instance)\n",
    "                        if instance_instance_proximity_matrix[instance_index][other_instance_index] > config.proximity_min_value:\n",
    "                            # build row column by column\n",
    "                            row = [''] * len(columns)\n",
    "                            row[c_ID] = instance\n",
    "                            row[oc_ID] = other_instance\n",
    "                            rows.append(row)\n",
    "\n",
    "    # write to csv\n",
    "    filepath = os.path.join(config.get_output_path(),'instance_relations.csv')\n",
    "    with open(filepath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(config.csv_separator.join(columns) + '\\n')\n",
    "        for row in rows:\n",
    "            f.write(config.csv_separator.join(row) + '\\n')\n",
    "    return True\n",
    "\n",
    "if not kg_done:\n",
    "    kg_done = knowledge_graph_population(config, instance_types_dicts, property_types_dicts, instance_instance_proximity_matrix, proximity_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: inference\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: inference, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: acquisition\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: acquisition, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: check\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: check, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: reasoning\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: reasoning, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      api\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      api\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    NaN\n",
      "data format specification     NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: failure\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: failure, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: optimization\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: optimization, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      api\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                      NaN\n",
      "software                     cad\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: reasoning\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: reasoning, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: inference\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: inference, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                        NaN\n",
      "software                     image\n",
      "data item                      NaN\n",
      "data model                     NaN\n",
      "data format specification      NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: failure\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: failure, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: reasoning\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: reasoning, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: acquisition\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: acquisition, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: check\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: check, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: optimization\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: optimization, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      NaN\n",
      "software                     cad\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      NaN\n",
      "software                     cad\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                        NaN\n",
      "software                     image\n",
      "data item                      NaN\n",
      "data model                     NaN\n",
      "data format specification      NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      NaN\n",
      "software                     cad\n",
      "data item                    NaN\n",
      "data model                   NaN\n",
      "data format specification    NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: check\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: check, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: failure\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: failure, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: optimization\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: optimization, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: training\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: training, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: check\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: check, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: failure\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: failure, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: optimization\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: optimization, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: check\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: check, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacture\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: manufacture, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: optimization\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: optimization, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: evaluation\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: evaluation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: reasoning\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: reasoning, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: detailed\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: detailed, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: creation\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: creation, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: failure\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: failure, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: acquisition\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: acquisition, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: processing\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: processing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   xml\n",
      "data format specification    NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: inference\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: inference, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: review\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: review, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: manufacturing\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: manufacturing, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: design\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   xml\n",
      "data format specification    NaN\n",
      "Name: design, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: development\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: development, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: reasoning\n",
      "data_row: process                       NaN\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: reasoning, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: analysis\n",
      "data_row: process                      NaN\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   xml\n",
      "data format specification    NaN\n",
      "Name: analysis, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                          access\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          NaN\n",
      "data format specification           NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                             word\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                        access\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                        access\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           access\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           access\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        cad\n",
      "data item                       NaN\n",
      "data model                      NaN\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                         word\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                       access\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       NaN\n",
      "data format specification        NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      api\n",
      "software                     NaN\n",
      "data item                    NaN\n",
      "data model                   add\n",
      "data format specification    NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           api\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                          word\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                    add\n",
      "data format specification     NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      add\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      add\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                       api\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                      xml\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      word\n",
      "software                      NaN\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                     step\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                      access\n",
      "software                        NaN\n",
      "data item                       NaN\n",
      "data model                     step\n",
      "data format specification       NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                        access\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                        access\n",
      "software                          NaN\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                     express\n",
      "data model                        NaN\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                        express\n",
      "data model                           NaN\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                          add\n",
      "data format specification           NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                        add\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                       NaN\n",
      "software                      cad\n",
      "data item                     NaN\n",
      "data model                   step\n",
      "data format specification     NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                     database\n",
      "data format specification           NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     material\n",
      "data item                         NaN\n",
      "data model                       step\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                             NaN\n",
      "software                     difficulty\n",
      "data item                           NaN\n",
      "data model                         step\n",
      "data format specification           NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                          step\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                          step\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           xml\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                           add\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                     ontology\n",
      "data item                         NaN\n",
      "data model                       step\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                      database\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                              NaN\n",
      "software                     description\n",
      "data item                            NaN\n",
      "data model                      database\n",
      "data format specification            NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                       add\n",
      "data format specification        NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                           NaN\n",
      "software                          NaN\n",
      "data item                     express\n",
      "data model                   database\n",
      "data format specification         NaN\n",
      "Name: nan, dtype: object\n",
      "'inference'\n",
      "ind: inference\n",
      "row: process                            NaN\n",
      "software                           NaN\n",
      "data item                          NaN\n",
      "data model                   isBasedOn\n",
      "data format specification          NaN\n",
      "interchange format                 NaN\n",
      "data visualization                 NaN\n",
      "data validation                    NaN\n",
      "inference                          NaN\n",
      "Name: inference, dtype: object\n",
      "col: data model\n",
      "data_ind: nan\n",
      "data_row: process                          NaN\n",
      "software                         NaN\n",
      "data item                    express\n",
      "data model                      step\n",
      "data format specification        NaN\n",
      "Name: nan, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: DeprecationWarning: invalid escape sequence '\\R'\n",
      "<>:14: DeprecationWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\timwi\\AppData\\Local\\Temp\\ipykernel_30680\\2405170987.py:14: DeprecationWarning: invalid escape sequence '\\R'\n",
      "  df_re = df_re.set_index('Domain\\Range')\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "import pandas as pd\n",
    "import types\n",
    "\n",
    "\n",
    "#process,software,data item,data model,data format specification,interchange format,data visualization,data validation,inference,source\n",
    "#process,software,data item,data model,data format specification\n",
    "\n",
    "\n",
    "def save_as_owl(config:Config, path=None):\n",
    "    onto_path = config.ontology_path\n",
    "    df_cl = pd.read_csv(os.path.join(onto_path,'classes.csv'))\n",
    "    df_re = pd.read_csv(os.path.join(onto_path,'relations.csv'))\n",
    "    df_re = df_re.set_index('Domain\\Range')\n",
    "    if path is None:\n",
    "        path = config.get_output_path()\n",
    "    data_path = os.path.join(path, 'instance_relations.csv')\n",
    "    df = pd.read_csv(data_path)\n",
    "    # df = pd.read_csv('data.csv')\n",
    "\n",
    "    onto = get_ontology('http://tib.eu/slr')\n",
    "\n",
    "    with onto:\n",
    "\n",
    "        # Classes\n",
    "        for ind, row in df_cl.iterrows():\n",
    "            cl = types.new_class(row['URI'], (Thing,))\n",
    "            cl.label = row['Label']\n",
    "\n",
    "        # Relations\n",
    "        for ind, row in df_re.iterrows():\n",
    "            for col in df_re.columns:\n",
    "                if ind == col:\n",
    "                    continue\n",
    "                if pd.isna(row[col]):\n",
    "                    continue\n",
    "                for re in row[col].split(config.csv_separator):\n",
    "                    re = re.strip()\n",
    "                    re_cl = types.new_class(re, (ObjectProperty,))\n",
    "                    re_cl.label = re\n",
    "                    domain_cl = onto.search_one(label = ind)\n",
    "                    range_cl = onto.search_one(label = col)\n",
    "                    re_cl.domain = domain_cl\n",
    "                    re_cl.range = range_cl\n",
    "\n",
    "                    for data_ind, data_row in df.iterrows():\n",
    "                        try:\n",
    "                            sub_label = data_row[ind]\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(f\"ind: {ind}\")\n",
    "                            print(f\"row: {row}\")\n",
    "                            print(f\"col: {col}\")\n",
    "                            print(f\"data_ind: {data_ind}\")\n",
    "                            print(f\"data_row: {data_row}\")\n",
    "                            continue\n",
    "                        if pd.isna(sub_label):\n",
    "                            #sub_label = f'{data_ind}_{ind}'\n",
    "                            continue\n",
    "                        obj_label = data_row[col]\n",
    "                        if pd.isna(obj_label):\n",
    "                            #obj_label = f'{data_ind}_{col}'\n",
    "                            continue\n",
    "\n",
    "                        sub = onto.search_one(label = sub_label)\n",
    "                        if not sub:\n",
    "                            sub = domain_cl()\n",
    "                        sub.label = sub_label\n",
    "\n",
    "                        obj = onto.search_one(label = obj_label)\n",
    "                        if not obj:\n",
    "                            obj = range_cl()\n",
    "                        obj.label = obj_label\n",
    "                        re_cl[sub].append(obj)\n",
    "                        \n",
    "    output_path = os.path.join(path, 'onto.owl')\n",
    "    # onto.save('onto.owl')\n",
    "    onto.save(output_path)\n",
    "    onto.destroy()\n",
    "\n",
    "save_as_owl(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.visualize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent a dict\n",
    "import csv\n",
    "import os\n",
    "from itables import init_notebook_mode, show\n",
    "\n",
    "# better represent dataframes\n",
    "if not config.for_git:\n",
    "    init_notebook_mode(all_interactive=True)\n",
    "\n",
    "\n",
    "def prep_dict(input_dict):\n",
    "    changes_needed = {}\n",
    "    # get ONLY THE FIRST key and value   \n",
    "    key, value = next(iter(input_dict.items()))     \n",
    "    key_change = \"\"\n",
    "    value_change = \"\"\n",
    "    if isinstance(key, frozenset):\n",
    "        key_change = \"str\"\n",
    "    if isinstance(value, set):\n",
    "        value_change = \"list\"\n",
    "    if isinstance(value, dict):\n",
    "        value_change = prep_dict(value)\n",
    "    changes_needed[key_change] = value_change\n",
    "    return changes_needed\n",
    "    \n",
    "def change_dict(input_dict, changes_needed):\n",
    "    for key, value in changes_needed.items():\n",
    "        if key == \"str\" and value == \"list\":\n",
    "            input_dict = {str(key): list(value) for key, value in input_dict.items()}\n",
    "        elif key == \"str\":\n",
    "            input_dict = {str(key): value for key, value in input_dict.items()}\n",
    "        elif value == \"list\":\n",
    "            input_dict = {key: list(value) for key, value in input_dict.items()}\n",
    "        elif key == \"str\" and value == \"dict\":\n",
    "            input_dict = {str(key): change_dict(value, changes_needed[\"str\"]) for key, value in input_dict.items()}\n",
    "        elif value == \"dict\":\n",
    "            input_dict = {key: change_dict(value, changes_needed[\"\"]) for key, value in input_dict.items()}\n",
    "    return input_dict\n",
    "\n",
    "def process_list(config:Config, input_list:list, filename=\"some_list\", path=None):\n",
    "    if path is None:\n",
    "        path = config.get_output_path()\n",
    "    filepath = os.path.join(path, filename)\n",
    "    with open(filepath + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "        for item in input_list:\n",
    "            f.write(f\"{item}\\n\")\n",
    "\n",
    "def process_dict(config:Config, input_dict:dict, filename=\"some_dict\", path=None):\n",
    "    # convert all sets to lists\n",
    "    changes_needed = prep_dict(input_dict)\n",
    "    processed_dict = change_dict(input_dict, changes_needed)\n",
    "\n",
    "    if path is None:\n",
    "        path = config.get_output_path()\n",
    "    filepath = os.path.join(path, filename)\n",
    "    with open(filepath + '.json', 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(processed_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # TODO: Only do this for dicts that need statistical analysis\n",
    "    requires_analysis = False\n",
    "    value = list(processed_dict.values())[0]  # Convert dict_values to list to make it subscriptable\n",
    "    if isinstance(value, dict):\n",
    "        value = list(value.values())[0]  # Convert dict_values to list to make it subscriptable\n",
    "        if isinstance(value, int) or isinstance(value, float):\n",
    "            requires_analysis = True\n",
    "    if not requires_analysis:\n",
    "        return\n",
    "    \n",
    "    container = [\n",
    "        [\"Instance\", \"Min\", \"Max\", \"Mean\", \"Median\", \"Std\"]\n",
    "    ]\n",
    "\n",
    "    for instance, papers in input_dict.items():\n",
    "\n",
    "        # print(f\"Instance: {instance}\")\n",
    "        gaps = papers.values()\n",
    "        # generate all kinds of statistical values\n",
    "        min_gap = min(gaps)\n",
    "        max_gap = max(gaps)\n",
    "        mean_gap = sum(gaps) / len(gaps)\n",
    "        median_gap = np.median(list(gaps))\n",
    "        std_gap = np.std(list(gaps))\n",
    "        container.append([instance, min_gap, max_gap, mean_gap, median_gap, std_gap])\n",
    "\n",
    "    filepath = os.path.join(path, filename)\n",
    "\n",
    "    # TODO: Handle CSV separator\n",
    "    # if not for_git:\n",
    "    # Function to convert a single value\n",
    "    # def convert_decimal_delimiter(value, decimal=CSV_DECIMAL):\n",
    "    #     if isinstance(value, float):\n",
    "    #         return f\"{value}\".replace('.', decimal)\n",
    "    #     return value\n",
    "\n",
    "    # # Convert all floats in your container to strings with the desired decimal delimiter\n",
    "    # container = [[convert_decimal_delimiter(value) for value in row] for row in container]\n",
    "\n",
    "    # write to csv\n",
    "    with open(filepath + \".csv\", 'w', newline='') as file:\n",
    "        writer = csv.writer(file, delimiter=config.csv_separator)\n",
    "        writer.writerows(container)   \n",
    "\n",
    "def process_dataframe(config:Config, input_df, name = \"some_df\", path=None):\n",
    "    if path is None:\n",
    "        path = config.get_output_path()\n",
    "    filepath = os.path.join(path, name)\n",
    "\n",
    "    # convert all froensets to strings\n",
    "    for col in input_df.columns:\n",
    "        # input_df[col] = input_df[col].apply(lambda x: \"_\".join(x))\n",
    "        first_element_type = input_df[col].apply(type).iloc[0]\n",
    "        if first_element_type == frozenset:\n",
    "            input_df[col] = input_df[col].apply(lambda x: \" \".join(x))\n",
    "                    \n",
    "    input_df.to_csv(filepath + '.csv', sep=config.csv_separator, decimal=config.csv_decimal)\n",
    "    show(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize co-occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import math\n",
    "\n",
    "def visualize_matrix(config:Config, matrix: np.ndarray, rows: list[str], columns: list[str] = None, name: str = 'some_matrix', format = '.png', path = None) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes a matrix as a heatmap.\n",
    "    matrix: The matrix to visualize\n",
    "    rows: The labels for the rows\n",
    "    columns: The labels for the columns\n",
    "    name: The name of the file to save\n",
    "    format: The format of the file to save (default: '.png', also accepts '.svg' and '.pdf', also accepts a list of formats)\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = rows\n",
    "\n",
    "    if path is None:\n",
    "        path = config.get_output_path(visualization=True)\n",
    "\n",
    "    ## Calculate the maximum size of the plot\n",
    "    dpi = 300\n",
    "    max_dpi = 600\n",
    "    if config.for_git:\n",
    "        dpi = 96\n",
    "        max_dpi = 200\n",
    "    max_pixel = 2**16  # Maximum size in any direction\n",
    "    max_size = max_pixel / dpi  # Maximum size in any direction\n",
    "    max_size_total = max_size * max_size # Maximum size in total\n",
    "    max_size_total *= 0.05 # produce smaller files\n",
    "\n",
    "    # Experience value of space required per cell\n",
    "    factor = 0.18\n",
    "    size_x: float = 2 + len(columns) * factor\n",
    "    size_y: float = 3 + len(rows) * 0.8 * factor\n",
    "\n",
    "    while size_x * size_y < max_size_total and dpi < max_dpi:\n",
    "        dpi /= 0.95 \n",
    "        max_size_total *= 0.95\n",
    "\n",
    "    if dpi > max_dpi:\n",
    "        dpi = max_dpi\n",
    "\n",
    "    while size_x * size_y > max_size_total:\n",
    "        dpi *= 0.95 \n",
    "        max_size_total /= 0.95\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(size_x, size_y), dpi=dpi)\n",
    "\n",
    "    cax = ax.matshow(matrix, cmap='viridis')\n",
    "\n",
    "    # use labels from instance_occurrences\n",
    "    ax.set_xticks(range(len(columns)))\n",
    "    ax.set_xticklabels(list(columns), fontsize=10, rotation=90)\n",
    "    ax.set_yticks(range(len(rows)))\n",
    "    ax.set_yticklabels(list(rows), fontsize=10)\n",
    "\n",
    "    # # adjust the spacing between the labels\n",
    "    # plt.gca().tick_params(axis='x', which='major', pad=15)\n",
    "    # plt.gca().tick_params(axis='y', which='major', pad=15)\n",
    "\n",
    "    # show the number of co-occurrences in each cell, if greater than 0\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix[i])):\n",
    "            if matrix[i, j] == 0:\n",
    "                continue\n",
    "            # if co_occurrences[i, j] > 100:\n",
    "            #     continue\n",
    "            \n",
    "            # make sure the text is at most 3 digits and a dot\n",
    "            decimals = 2\n",
    "            if matrix[i, j] > 99:\n",
    "                decimals = 0\n",
    "            elif matrix[i, j] > 9:\n",
    "                decimals = 1\n",
    "            cell_text = round(matrix[i, j], decimals)\n",
    "            if decimals == 0:\n",
    "                cell_text = int(cell_text)\n",
    "            plt.text(j, i, cell_text, ha='center', va='center', color='white', fontsize=4)\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # title\n",
    "    plt.title(name)\n",
    "\n",
    "    if isinstance(format, list):\n",
    "        for f in format:\n",
    "            if f[0] != '.':\n",
    "                f = '.' + f\n",
    "            filepath = os.path.join(path, name + f)\n",
    "            fig.savefig(filepath)\n",
    "    else:\n",
    "        if format[0] != '.':\n",
    "            format = '.' + format\n",
    "        filepath = os.path.join(path, name + format)\n",
    "        fig.savefig(filepath)\n",
    "\n",
    "def visualize_matrix_graph(config:Config, matrix, instances, instance_types_dicts, name='some_matrix_graph', path=None, node_size_mode = \"sqrt\", raise_mode = \"prune\"):\n",
    "    if path is None:\n",
    "        path = config.get_output_path(path, visualization=True)\n",
    "\n",
    "    SEED = config.proximity_seed or 17\n",
    "    K_SPRRING = config.proximity_k_spring or 18\n",
    "    MIN_VALUE = config.proximity_min_value or 0.01\n",
    "\n",
    "    scale = len(instances) * .12\n",
    "    # Create a new figure\n",
    "    x = scale / 10 * 16\n",
    "    y = scale / 10 * 9\n",
    "    fig = plt.figure(figsize=(x, y))\n",
    "\n",
    "    # normalize the proximity matrix\n",
    "    matrix = matrix / matrix.max()\n",
    "\n",
    "    \n",
    "    # Make sure the matrix is not completely stretched out\n",
    "    if matrix.min() < MIN_VALUE:\n",
    "        if raise_mode == \"prune\":\n",
    "            # remove every value that is below MIN_VALUE\n",
    "            matrix = np.where(matrix < MIN_VALUE, 0, matrix)\n",
    "        elif raise_mode == \"sqrt\":\n",
    "            while np.min(matrix[np.nonzero(matrix)]) < MIN_VALUE:\n",
    "                matrix = np.sqrt(matrix)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown raise mode\")\n",
    "\n",
    "    # alternatives are:\n",
    "    # \"linear\" - take proximity as is\n",
    "    # \"sqrt\" - sqrt(proximity)\n",
    "    # \"log\" - log(proximity)\n",
    "    if node_size_mode == \"log\":\n",
    "        # TODO: see how this works with log(1)\n",
    "        nodesize_map = [np.log(matrix[:, i].sum() + 1) for i in range(len(instances))]\n",
    "    elif node_size_mode == \"sqrt\":\n",
    "        nodesize_map = [np.sqrt(matrix[:, i].sum()) for i in range(len(instances))]\n",
    "    elif node_size_mode == \"linear\":\n",
    "        nodesize_map = [matrix[:, i].sum()for i in range(len(instances))]\n",
    "    else:\n",
    "        nodesize_map = [matrix[:, i].sum() for i in range(len(instances))]\n",
    "        \n",
    "    # print(max(nodesize_map))\n",
    "    # print(min(nodesize_map))\n",
    "\n",
    "    nodesize_map = np.array(nodesize_map) / max(nodesize_map) * 1000\n",
    "\n",
    "    # print(max(nodesize_map))\n",
    "    # print(min(nodesize_map))\n",
    "\n",
    "\n",
    "    # Create a graph from the proximity matrix\n",
    "    G = nx.from_numpy_array(matrix)\n",
    "\n",
    "    # Specify the layout\n",
    "    pos = nx.spring_layout(G, seed=SEED, k=K_SPRRING/math.sqrt(G.order()))  # Seed for reproducibility\n",
    "\n",
    "    color_map = []\n",
    "\n",
    "    color = {\n",
    "        \"process\": \"#1f77b4\",  # muted blue\n",
    "        \"software\": \"#ff7f0e\",  # safety orange\n",
    "        \"data item\": \"#2ca02c\",  # cooked asparagus green\n",
    "        \"data model\": \"#d62728\",  # brick red\n",
    "        \"data format specification\": \"#9467bd\",  # muted purple\n",
    "        \"interchange format\": \"#8c564b\",  # chestnut brown\n",
    "        # \"source\": \"#e377c2\",  # raspberry yogurt pink\n",
    "    }\n",
    "\n",
    "    for instance in instances:\n",
    "        added = False\n",
    "        for instance_type in instance_types_dicts:\n",
    "            if instance in instance_types_dicts[instance_type]:\n",
    "                color_map.append(color[instance_type])\n",
    "                added = True\n",
    "                break\n",
    "        if not added:\n",
    "            color_map.append(\"grey\")\n",
    "\n",
    "    # Draw the graph\n",
    "    options = {\n",
    "        \"edge_color\": \"grey\",\n",
    "        \"linewidths\": 0.5,\n",
    "        \"width\": 0.5,\n",
    "        \"with_labels\": True,  # This will add labels to the nodes\n",
    "        \"labels\": {i: label for i, label in enumerate(instances)},\n",
    "        \"node_color\": color_map,\n",
    "        \"node_size\": nodesize_map,\n",
    "        # \"edge_color\": \"white\",\n",
    "        # \"alpha\": 0.9,\n",
    "    }\n",
    "\n",
    "    # print(nx.is_weighted(G))\n",
    "\n",
    "\n",
    "    # nx.set_edge_attributes(G, values = 1, name = 'weight')\n",
    "\n",
    "    nx.draw(G, pos, **options, ax=fig.add_subplot(111))\n",
    "\n",
    "    # Make the graph more spacious\n",
    "    fig.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.9)\n",
    "\n",
    "    # Create a patch for each color\n",
    "    patches = [mpatches.Patch(color=color[key], label=key) for key in color]\n",
    "\n",
    "    # Add the legend to the graph\n",
    "    plt.legend(handles=patches, loc='upper right', fontsize='x-large')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save plot to file\n",
    "    filepath = os.path.join(path, name)\n",
    "    fig.savefig(filepath + '.png')\n",
    "    fig.savefig(filepath + '.svg')\n",
    "\n",
    "    # nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "def sankey(config:Config, matrix, instances, instance_types_dicts, name='some_sankey', path = None):\n",
    "    #TODO: Implement a method to create one graph per Process\n",
    "    if path is None:\n",
    "        path = config.get_output_path(path, visualization=True)\n",
    "    # Convert the proximity matrix into a list of source nodes, target nodes, and values\n",
    "    sources = []\n",
    "    targets = []\n",
    "    values = []\n",
    "\n",
    "    x_pos=[0] * len(instances)\n",
    "    y_pos=[0] * len(instances)\n",
    "    color_map=[0] * len(instances)\n",
    "\n",
    "    max_types = len(instance_types_dicts)\n",
    "    type_positions = [0.1 + (i / max_types) * 0.8 for i in range(max_types)]\n",
    "\n",
    "    color = {\n",
    "        \"process\": \"#1f77b4\",  # muted blue\n",
    "        \"software\": \"#ff7f0e\",  # safety orange\n",
    "        \"data item\": \"#2ca02c\",  # cooked asparagus green\n",
    "        \"data model\": \"#d62728\",  # brick red\n",
    "        \"data format specification\": \"#9467bd\",  # muted purple\n",
    "        \"interchange format\": \"#8c564b\",  # chestnut brown\n",
    "        # \"source\": \"#e377c2\",  # raspberry yogurt pink\n",
    "    }\n",
    "    color = list(color.values())\n",
    "\n",
    "    space = {}\n",
    "\n",
    "    for i in range(matrix.shape[0]):\n",
    "        source_type = None\n",
    "\n",
    "        for j in range(matrix.shape[1]):\n",
    "            target_type = None\n",
    "            \n",
    "            for type_depth, type in enumerate(instance_types_dicts):\n",
    "                if instances[i] in instance_types_dicts[type]:\n",
    "                    source_type = type_depth\n",
    "                if instances[j] in instance_types_dicts[type]:\n",
    "                    target_type = type_depth\n",
    "\n",
    "            # only keep directly forward moving connections\n",
    "            if target_type - source_type != 1:\n",
    "                continue\n",
    "\n",
    "            # only keep forward moving connections\n",
    "            if target_type - source_type <= 0:\n",
    "                continue\n",
    "\n",
    "            if source_type not in space:\n",
    "                space[source_type] = {}\n",
    "            if i not in space[source_type]:\n",
    "                space[source_type][i] = 0\n",
    "            space[source_type][i] += matrix[i][j]\n",
    "            \n",
    "            if target_type not in space:\n",
    "                space[target_type] = {}\n",
    "            if j not in space[target_type]:\n",
    "                space[target_type][j] = 0\n",
    "            space[target_type][j] += matrix[i][j]\n",
    "\n",
    "            x_pos[i] = type_positions[source_type]\n",
    "            x_pos[j] = type_positions[target_type]\n",
    "            color_map[i] = color[source_type]\n",
    "            color_map[j] = color[target_type]\n",
    "            if matrix[i][j] > 0.0:  # Ignore zero values\n",
    "                sources.append(i)\n",
    "                targets.append(j)\n",
    "                values.append(matrix[i][j])\n",
    "\n",
    "    for type in space:\n",
    "        sum_values = sum(space[type].values())\n",
    "        space[type] = {k: v/sum_values for k, v in sorted(space[type].items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    # assign each instance a proper y position\n",
    "    for type in space:\n",
    "        bottom = 0.1\n",
    "        for i, instance in enumerate(space[type]):\n",
    "            y_pos[instance] = bottom\n",
    "            bottom += space[type][instance] * 0.8\n",
    "\n",
    "    nodes = dict(\n",
    "        # pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=instances,\n",
    "        color=color_map,\n",
    "        x=x_pos,\n",
    "        y=y_pos,\n",
    "        align=\"right\",\n",
    "    )\n",
    "\n",
    "    # Create a Sankey diagram\n",
    "    fig = go.Figure(data=[go.Sankey(\n",
    "        node=nodes,\n",
    "        link=dict(\n",
    "            source=sources,\n",
    "            target=targets,\n",
    "            value=values\n",
    "        )\n",
    "    )])\n",
    "\n",
    "\n",
    "    fig.update_layout(width=1920, height=1080)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"Sankey Diagram\", font_size=10)\n",
    "    # fig.show()\n",
    "    \n",
    "    filepath = os.path.join(path, name)\n",
    "    fig.write_image(filepath + '.png')\n",
    "    fig.write_image(filepath + '.svg')\n",
    "    fig.write_html(filepath + '.html')\n",
    "\n",
    "# Represent a matrix\n",
    "def process_matrix(config:Config, matrix, rows, columns=None, name = 'some_matrix', path = None, instance_types_dicts = None, mode = \"sqrt\"):\n",
    "    if columns is None:\n",
    "        columns = rows\n",
    "    if path is None:\n",
    "        path = config.get_output_path()\n",
    "    df = pd.DataFrame(matrix, columns=columns, index=rows)\n",
    "    filepath = os.path.join(path, name)\n",
    "    df.to_csv(filepath + '.csv', sep=config.csv_separator, decimal=config.csv_decimal)\n",
    "    path = config.get_output_path(path, visualization=True)\n",
    "    if config.visualize:\n",
    "        if instance_types_dicts:\n",
    "            sankey(config, matrix, rows, instance_types_dicts, name + '_sankey', path=path)\n",
    "            if mode:\n",
    "                visualize_matrix_graph(config, matrix, rows, instance_types_dicts, name + '_graph', path=path, node_size_mode=config.proximity_mode)\n",
    "            else:\n",
    "                visualize_matrix_graph(config, matrix, rows, instance_types_dicts, name + '_graph', path=path)\n",
    "        visualize_matrix(config, matrix, rows, columns, name, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize timeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def visualize_timeline(config:Config, year_instance_occurrence_matrix, year_papers, instances, instance_types_dicts, name='some_timeline', path=None, recursion_depth=0, start_index=0, error_matrix=None, error_instances=None):\n",
    "    if not path:\n",
    "        path = config.get_output_path(path, visualization=True)\n",
    "    years = list(year_papers.keys())\n",
    "    max_papers = max([len(year_papers[year]) for year in years])\n",
    "    yearly_papers = [len(year_papers[year]) for year in years]\n",
    "\n",
    "\n",
    "    ALPHA_ERROR_LINE = 0.3\n",
    "    ALPHA_ERROR_ZONE = 0.2\n",
    "    ALPHA_PAPER_BAR = 0.3\n",
    "\n",
    "\n",
    "    for type in instance_types_dicts:\n",
    "        use = [instance in instance_types_dicts[type] for instance in instances]\n",
    "        type_instances = [instance for instance, use_flag in zip(instances, use) if use_flag]\n",
    "        total_occurrences = [np.sum(year_instance_occurrence_matrix[:, instances.index(instance)]) for instance in type_instances]\n",
    "        type_instances_sorted = [x for _, x in sorted(zip(total_occurrences, type_instances), key=lambda pair: pair[0], reverse=True)]\n",
    "        \n",
    "        PARTITION_SIZE = 10\n",
    "        # if error_instances is not None:\n",
    "        #     PARTITION_SIZE = int(0.5 * PARTITION_SIZE)\n",
    "        \n",
    "        type_matrix = year_instance_occurrence_matrix[:, [instances.index(instance) for instance in type_instances_sorted]]\n",
    "        factor = 1\n",
    "        size_x = (2 + len(years) / 6) * factor\n",
    "        size_y = (2 + max_papers / 15) * factor\n",
    "        size_y_2 = (2 + PARTITION_SIZE / 2) * factor\n",
    "        size_y = max(size_y, size_y_2)\n",
    "        fig, ax = plt.subplots(figsize=(size_x, size_y), dpi=300)\n",
    "\n",
    "        ax.set_xticks(range(len(years)))\n",
    "        years_labels = [year if len(year_papers[year]) > 0 else '' for year in years]\n",
    "        ax.set_xticklabels(years_labels, fontsize=10, rotation=90)\n",
    "        \n",
    "        step_size = max(1, math.ceil(max_papers / 10))\n",
    "        ax.set_yticks(np.arange(0, max_papers + 1, step=step_size))\n",
    "        ax.set_yticklabels([str(int(x)) for x in np.arange(0, max_papers + 1, step=step_size)], fontsize=10)\n",
    "        \n",
    "        # set y axis label\n",
    "        ax.set_ylabel('absolute', fontsize=10)\n",
    "\n",
    "        plt.bar(range(len(years)), yearly_papers, color='black', alpha=ALPHA_PAPER_BAR, label=f\"Total papers ({sum(yearly_papers)})\", zorder=0)\n",
    "\n",
    "        line_count = 0\n",
    "        i = start_index\n",
    "        while line_count < PARTITION_SIZE and i < len(type_instances_sorted):\n",
    "            instance = type_instances_sorted[i]\n",
    "            yearly_occurrences = type_matrix[:, i]\n",
    "            i_total_occurrences = yearly_occurrences.sum()\n",
    "            label = f\"{instance} ({i_total_occurrences})\"\n",
    "            values = yearly_occurrences\n",
    "            line = plt.plot(range(len(years)), values, label=label, zorder=3)[0]\n",
    "            line_count += 1\n",
    "            if error_matrix is not None and instance in error_instances:\n",
    "                color = line.get_color()\n",
    "                errors = error_matrix[:, error_instances.index(instance)]\n",
    "                errors_plus = yearly_occurrences + errors\n",
    "                line.set_label(f\"{instance} ({i_total_occurrences}-{sum(errors_plus)})\")\n",
    "                # Plot the error as a half transparent line on top of the normal line\n",
    "                plt.plot(range(len(years)), errors_plus, color=color, alpha=ALPHA_ERROR_LINE, label=f\"{instance} (w/o proximity)\", zorder=2)\n",
    "                line_count += 1\n",
    "                # color in the area between the normal line and the error line\n",
    "                plt.fill_between(range(len(years)), yearly_occurrences, errors_plus, color=color, alpha=ALPHA_ERROR_ZONE, zorder=1)\n",
    "            i += 1\n",
    "                \n",
    "                # plt.scatter(range(len(years)), errors, color='red', label=f\"{instance} (error)\", zorder=1)\n",
    "        stop_index = i\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        plt.title(f\"Number of papers covering {type} instances (#{start_index+1} to #{stop_index} of {len(type_instances_sorted)})\")\n",
    "\n",
    "        # Inset for relative values\n",
    "        fig.canvas.draw()\n",
    "        x_lim = ax.get_xlim()  # Get the current x-axis limits from the main plot\n",
    "\n",
    "        bbox = ax.get_position()\n",
    "        bb_left, bb_bottom = bbox.x0, bbox.y0\n",
    "        bb_width, bb_height = bbox.width, bbox.height\n",
    "\n",
    "        ax_inset = plt.axes([bb_left, 0.05, bb_width, 0.15], alpha=ALPHA_PAPER_BAR, facecolor='lightgrey')\n",
    "        for i, instance in enumerate(type_instances_sorted[start_index:stop_index], start=start_index):\n",
    "            yearly_occurrences = type_matrix[:, i]\n",
    "            values_relative = [occurrences / papers if papers > 0 else 0 for occurrences, papers in zip(yearly_occurrences, yearly_papers)]\n",
    "            line_relative = ax_inset.plot(range(len(years)), values_relative, label=f\"{instance} (relative)\", zorder=3)[0]\n",
    "\n",
    "            # add the error part\n",
    "            if error_matrix is not None and instance in error_instances:\n",
    "                color = line_relative.get_color()\n",
    "                errors = error_matrix[:, error_instances.index(instance)]\n",
    "                errors_plus = yearly_occurrences + errors\n",
    "                errors_relative = [error / papers if papers > 0 else 0 for error, papers in zip(errors_plus, yearly_papers)]\n",
    "                if max(errors_relative) > 1:\n",
    "                    print(f\"Error: {instance} has a relative error > 1\")\n",
    "                    # throw an exception because this should never be the case:\n",
    "                    # raise Exception(f\"Error: relative {instance} occurence + error > 1\")\n",
    "\n",
    "\n",
    "                ax_inset.plot(range(len(years)), errors_relative, alpha=ALPHA_ERROR_LINE, color=color, label=f\"{instance} (error, relative)\", zorder=2)\n",
    "                # color in the area between the normal line and the error line\n",
    "                ax_inset.fill_between(range(len(years)), values_relative, errors_relative, alpha=ALPHA_ERROR_ZONE, color=color, zorder=1)\n",
    "        \n",
    "        ax_inset.set_xlim(x_lim)\n",
    "\n",
    "        ax_inset.set_xticks([])\n",
    "        ax_inset.set_yticks(np.arange(0, 1.1, step=0.5))\n",
    "        ax_inset.set_yticklabels([f\"{int(x*100)}%\" for x in np.arange(0, 1.1, step=0.5)], fontsize=8)\n",
    "\n",
    "        # set y axis label\n",
    "        ax_inset.set_ylabel('relative', fontsize=10)\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "        start_string = f\"{start_index+1}\"\n",
    "        stop_string = f\"{stop_index}\"\n",
    "\n",
    "        # fill up with 0 to have a constant length\n",
    "        start_string = \"0\" * (3 - len(start_string)) + start_string\n",
    "        stop_string = \"0\" * (3 - len(stop_string)) + stop_string\n",
    "\n",
    "        part_appendix = f\"{start_string}_to_{stop_string}\"\n",
    "        filepath = os.path.join(path, name)\n",
    "        plt.savefig(f\"{filepath}_{type.replace(' ', '_')}_{part_appendix}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        start_index = stop_index\n",
    "        if start_index < len(type_instances_sorted):\n",
    "            # if recursion_depth > 0:\n",
    "            #     break\n",
    "            visualize_timeline(config, year_instance_occurrence_matrix, year_papers, instances, {type: instance_types_dicts[type]}, name, path=path, recursion_depth=recursion_depth + 1, start_index=start_index, error_matrix=error_matrix, error_instances=error_instances)\n",
    "        start_index = 0\n",
    "            \n",
    "if config.visualize:\n",
    "    yearly_error_matrix, year_error_papers = create_year_paper_occurrence_matrix(papers_metadata, error_matrix, error_papers, is_error_matrix=True)\n",
    "    visualize_timeline(config, year_instance_occurrence_matrix, year_papers, instances, instance_types_dicts, name=\"year_instance_occurrence_matrix\", error_matrix=yearly_error_matrix, error_instances=error_instances) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_list(config, instances, \"instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Dicts: instance_types_dicts, papers_metadata, instance_piece_gap\n",
    "process_dict(config, instance_types_dicts, 'instance_types_dicts')\n",
    "process_dict(config, papers_metadata, 'papers_metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"itables_ba224cfc_1598_48c9_b4ce_8f147c83dce5\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<div style=\"float:left; margin-right: 10px;\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "</div>\n",
       "<div>\n",
       "Loading ITables v2.1.1 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</div>\n",
       "</tr></tbody>\n",
       "\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.10/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.10/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_ba224cfc_1598_48c9_b4ce_8f147c83dce5:not(.dataTable)\").forEach(table => {\n",
       "        // Define the table data\n",
       "        const data = [[263, \"manufacture\", \"manufacturing\", 0.426829, 0.646341, 0.402439, 0.942857, 1.45876, 0.126562, 6.189024, 0.548678], [265, \"cad\", \"manufacturing\", 0.457317, 0.646341, 0.402439, 0.88, 1.361509, 0.106856, 2.947154, 0.489275], [229, \"reasoning\", \"ontology\", 0.560976, 0.591463, 0.45122, 0.804348, 1.359928, 0.119423, 2.088076, 0.602853], [180, \"manufacturing\", \"material\", 0.646341, 0.658537, 0.52439, 0.811321, 1.232006, 0.098751, 1.809756, 0.532478], [192, \"check\", \"detailed\", 0.609756, 0.72561, 0.512195, 0.84, 1.157647, 0.06975, 1.714939, 0.348958], [188, \"word\", \"express\", 0.621951, 0.713415, 0.512195, 0.823529, 1.154349, 0.068486, 1.623984, 0.353687], [218, \"training\", \"review\", 0.530488, 0.768293, 0.469512, 0.885057, 1.15198, 0.061942, 2.015854, 0.280992], [223, \"training\", \"evaluation\", 0.530488, 0.762195, 0.463415, 0.873563, 1.146115, 0.059079, 1.88082, 0.271531], [244, \"training\", \"express\", 0.530488, 0.713415, 0.432927, 0.816092, 1.143924, 0.054469, 1.558308, 0.267971], [144, \"material\", \"evaluation\", 0.658537, 0.762195, 0.573171, 0.87037, 1.141926, 0.071237, 1.834495, 0.363982], [242, \"difficulty\", \"review\", 0.493902, 0.768293, 0.432927, 0.876543, 1.140898, 0.053465, 1.876829, 0.244018], [197, \"creation\", \"express\", 0.621951, 0.713415, 0.506098, 0.813725, 1.140607, 0.062388, 1.538511, 0.326079], [220, \"training\", \"processing\", 0.530488, 0.780488, 0.469512, 0.885057, 1.13398, 0.055473, 1.909756, 0.251644], [178, \"optimization\", \"detailed\", 0.640244, 0.72561, 0.52439, 0.819048, 1.128772, 0.059823, 1.516367, 0.317107], [213, \"ontology\", \"express\", 0.591463, 0.713415, 0.47561, 0.804124, 1.127148, 0.053651, 1.463094, 0.276119], [261, \"acquisition\", \"review\", 0.481707, 0.768293, 0.414634, 0.860759, 1.120354, 0.044542, 1.66408, 0.207266], [264, \"api\", \"add\", 0.45122, 0.79878, 0.402439, 0.891892, 1.116567, 0.042014, 1.86128, 0.190236], [161, \"manufacturing\", \"evaluation\", 0.646341, 0.762195, 0.54878, 0.849057, 1.113962, 0.056142, 1.575457, 0.289272], [171, \"word\", \"review\", 0.621951, 0.768293, 0.530488, 0.852941, 1.110177, 0.052647, 1.57561, 0.262514], [177, \"material\", \"detailed\", 0.658537, 0.72561, 0.530488, 0.805556, 1.110177, 0.052647, 1.41115, 0.29064], [258, \"acquisition\", \"processing\", 0.481707, 0.780488, 0.414634, 0.860759, 1.102848, 0.038667, 1.576497, 0.179931], [168, \"check\", \"add\", 0.609756, 0.79878, 0.536585, 0.88, 1.101679, 0.049524, 1.676829, 0.236506], [210, \"reasoning\", \"processing\", 0.560976, 0.780488, 0.481707, 0.858696, 1.100204, 0.043873, 1.553471, 0.207454], [246, \"failure\", \"review\", 0.512195, 0.768293, 0.432927, 0.845238, 1.100151, 0.039411, 1.497186, 0.18662], [158, \"material\", \"review\", 0.658537, 0.768293, 0.554878, 0.842593, 1.096708, 0.048929, 1.472023, 0.258242], [248, \"failure\", \"evaluation\", 0.512195, 0.762195, 0.426829, 0.833333, 1.093333, 0.036437, 1.426829, 0.175], [174, \"creation\", \"processing\", 0.621951, 0.780488, 0.530488, 0.852941, 1.092831, 0.045062, 1.492683, 0.224694], [172, \"word\", \"processing\", 0.621951, 0.780488, 0.530488, 0.852941, 1.092831, 0.045062, 1.492683, 0.224694], [153, \"material\", \"processing\", 0.658537, 0.780488, 0.560976, 0.851852, 1.091435, 0.046996, 1.481707, 0.245342], [194, \"training\", \"description\", 0.530488, 0.878049, 0.506098, 0.954023, 1.086526, 0.040303, 2.652439, 0.169614], [224, \"reasoning\", \"evaluation\", 0.560976, 0.762195, 0.463415, 0.826087, 1.083826, 0.035842, 1.367378, 0.17617], [105, \"detailed\", \"add\", 0.72561, 0.79878, 0.628049, 0.865546, 1.083585, 0.048446, 1.49657, 0.281122], [247, \"difficulty\", \"add\", 0.493902, 0.79878, 0.426829, 0.864198, 1.081896, 0.03231, 1.481707, 0.14957], [170, \"manufacturing\", \"review\", 0.646341, 0.768293, 0.536585, 0.830189, 1.080563, 0.040006, 1.364499, 0.210815], [196, \"check\", \"review\", 0.609756, 0.768293, 0.506098, 0.83, 1.080317, 0.037626, 1.362984, 0.190512], [70, \"processing\", \"database\", 0.780488, 0.841463, 0.707317, 0.90625, 1.076993, 0.050565, 1.691057, 0.32567], [69, \"database\", \"processing\", 0.841463, 0.780488, 0.707317, 0.84058, 1.076993, 0.050565, 1.37694, 0.450928], [262, \"api\", \"database\", 0.45122, 0.841463, 0.408537, 0.905405, 1.075989, 0.028852, 1.675958, 0.12869], [201, \"check\", \"evaluation\", 0.609756, 0.762195, 0.5, 0.82, 1.07584, 0.035247, 1.321138, 0.18064], [257, \"inference\", \"description\", 0.439024, 0.878049, 0.414634, 0.944444, 1.075617, 0.029149, 2.195122, 0.12532], [256, \"difficulty\", \"processing\", 0.493902, 0.780488, 0.414634, 0.839506, 1.075617, 0.029149, 1.36773, 0.138909], [237, \"failure\", \"add\", 0.512195, 0.79878, 0.439024, 0.857143, 1.073064, 0.029893, 1.408537, 0.139583], [204, \"ontology\", \"processing\", 0.591463, 0.780488, 0.493902, 0.835052, 1.06991, 0.032272, 1.330793, 0.159941], [268, \"difficulty\", \"evaluation\", 0.493902, 0.762195, 0.402439, 0.814815, 1.069037, 0.025989, 1.284146, 0.127601], [250, \"failure\", \"processing\", 0.512195, 0.780488, 0.426829, 0.833333, 1.067708, 0.027067, 1.317073, 0.13], [198, \"word\", \"evaluation\", 0.621951, 0.762195, 0.506098, 0.813725, 1.067608, 0.032049, 1.276637, 0.167509], [133, \"material\", \"database\", 0.658537, 0.841463, 0.591463, 0.898148, 1.067364, 0.037329, 1.556541, 0.184831], [103, \"processing\", \"evaluation\", 0.780488, 0.762195, 0.634146, 0.8125, 1.066, 0.039262, 1.268293, 0.282051], [104, \"evaluation\", \"processing\", 0.762195, 0.780488, 0.634146, 0.832, 1.066, 0.039262, 1.30662, 0.260355], [54, \"review\", \"access\", 0.768293, 0.908537, 0.743902, 0.968254, 1.065729, 0.04588, 2.881098, 0.266178], [53, \"access\", \"review\", 0.908537, 0.768293, 0.743902, 0.818792, 1.065729, 0.04588, 1.278681, 0.674317], [215, \"training\", \"database\", 0.530488, 0.841463, 0.47561, 0.896552, 1.065467, 0.029224, 1.53252, 0.130869], [116, \"material\", \"description\", 0.658537, 0.878049, 0.615854, 0.935185, 1.065072, 0.037626, 1.881533, 0.178925], [148, \"optimization\", \"database\", 0.640244, 0.841463, 0.573171, 0.895238, 1.063906, 0.034429, 1.513304, 0.166967], [134, \"express\", \"processing\", 0.713415, 0.780488, 0.591463, 0.82906, 1.062233, 0.034652, 1.284146, 0.204431], [157, \"creation\", \"database\", 0.621951, 0.841463, 0.554878, 0.892157, 1.060244, 0.031529, 1.470067, 0.150301], [216, \"difficulty\", \"access\", 0.493902, 0.908537, 0.47561, 0.962963, 1.059906, 0.026881, 2.469512, 0.111677], [72, \"evaluation\", \"description\", 0.762195, 0.878049, 0.707317, 0.928, 1.056889, 0.038073, 1.693767, 0.226348], [71, \"description\", \"evaluation\", 0.878049, 0.762195, 0.707317, 0.805556, 1.056889, 0.038073, 1.222997, 0.441379], [142, \"express\", \"review\", 0.713415, 0.768293, 0.579268, 0.811966, 1.056844, 0.031157, 1.232262, 0.187682], [162, \"ontology\", \"description\", 0.591463, 0.878049, 0.54878, 0.927835, 1.056701, 0.029447, 1.689895, 0.131343], [187, \"training\", \"step\", 0.530488, 0.914634, 0.512195, 0.965517, 1.055632, 0.026993, 2.47561, 0.112245], [179, \"creation\", \"add\", 0.621951, 0.79878, 0.52439, 0.843137, 1.055531, 0.027588, 1.282774, 0.13916], [159, \"material\", \"add\", 0.658537, 0.79878, 0.554878, 0.842593, 1.054849, 0.028852, 1.278336, 0.152276], [254, \"inference\", \"access\", 0.439024, 0.908537, 0.420732, 0.958333, 1.05481, 0.021862, 2.195122, 0.092628], [202, \"creation\", \"evaluation\", 0.621951, 0.762195, 0.5, 0.803922, 1.054745, 0.025952, 1.212805, 0.137293], [182, \"optimization\", \"review\", 0.640244, 0.768293, 0.518293, 0.809524, 1.053666, 0.026398, 1.216463, 0.141575], [113, \"evaluation\", \"review\", 0.762195, 0.768293, 0.615854, 0.808, 1.051683, 0.030265, 1.206809, 0.206651], [112, \"review\", \"evaluation\", 0.768293, 0.762195, 0.615854, 0.801587, 1.051683, 0.030265, 1.198537, 0.21209], [101, \"evaluation\", \"add\", 0.762195, 0.79878, 0.640244, 0.84, 1.051603, 0.031417, 1.257622, 0.206349], [102, \"add\", \"evaluation\", 0.79878, 0.762195, 0.640244, 0.801527, 1.051603, 0.031417, 1.198171, 0.243867], [267, \"image\", \"analysis\", 0.402439, 0.95122, 0.402439, 1.0, 1.051282, 0.019631, Infinity, 0.081633], [232, \"training\", \"add\", 0.530488, 0.79878, 0.445122, 0.83908, 1.050452, 0.021379, 1.250436, 0.102295], [186, \"optimization\", \"evaluation\", 0.640244, 0.762195, 0.512195, 0.8, 1.0496, 0.024204, 1.189024, 0.131356], [238, \"cad\", \"step\", 0.457317, 0.914634, 0.439024, 0.96, 1.0496, 0.020747, 2.134146, 0.087079], [137, \"check\", \"step\", 0.609756, 0.914634, 0.585366, 0.96, 1.0496, 0.027662, 2.134146, 0.121094], [149, \"creation\", \"description\", 0.621951, 0.878049, 0.573171, 0.921569, 1.049564, 0.027067, 1.554878, 0.124914], [228, \"failure\", \"database\", 0.512195, 0.841463, 0.45122, 0.880952, 1.046929, 0.020226, 1.331707, 0.091892], [230, \"reasoning\", \"review\", 0.560976, 0.768293, 0.45122, 0.804348, 1.046929, 0.020226, 1.184282, 0.102102], [131, \"word\", \"access\", 0.621951, 0.908537, 0.591463, 0.95098, 1.046717, 0.026398, 1.865854, 0.118058], [132, \"creation\", \"access\", 0.621951, 0.908537, 0.591463, 0.95098, 1.046717, 0.026398, 1.865854, 0.118058], [90, \"processing\", \"add\", 0.780488, 0.79878, 0.652439, 0.835938, 1.046517, 0.029001, 1.226481, 0.202492], [91, \"add\", \"processing\", 0.79878, 0.780488, 0.652439, 0.816794, 1.046517, 0.029001, 1.198171, 0.220901], [203, \"creation\", \"review\", 0.621951, 0.768293, 0.5, 0.803922, 1.046374, 0.022159, 1.181707, 0.117231], [85, \"evaluation\", \"database\", 0.762195, 0.841463, 0.670732, 0.88, 1.045797, 0.029372, 1.321138, 0.184149], [226, \"acquisition\", \"access\", 0.481707, 0.908537, 0.457317, 0.949367, 1.044941, 0.019668, 1.806402, 0.08298], [130, \"detailed\", \"processing\", 0.72561, 0.780488, 0.591463, 0.815126, 1.04438, 0.025134, 1.187361, 0.154868], [219, \"failure\", \"description\", 0.512195, 0.878049, 0.469512, 0.916667, 1.043981, 0.01978, 1.463415, 0.086364], [75, \"add\", \"database\", 0.79878, 0.841463, 0.70122, 0.877863, 1.043257, 0.029075, 1.298018, 0.206061], [74, \"database\", \"add\", 0.841463, 0.79878, 0.70122, 0.833333, 1.043257, 0.029075, 1.207317, 0.261538], [129, \"manufacturing\", \"description\", 0.646341, 0.878049, 0.591463, 0.915094, 1.042191, 0.023944, 1.436314, 0.114469], [245, \"difficulty\", \"database\", 0.493902, 0.841463, 0.432927, 0.876543, 1.041689, 0.017326, 1.284146, 0.079077], [118, \"optimization\", \"step\", 0.640244, 0.914634, 0.609756, 0.952381, 1.04127, 0.024167, 1.792683, 0.110169], [251, \"api\", \"access\", 0.45122, 0.908537, 0.426829, 0.945946, 1.041175, 0.01688, 1.692073, 0.072063], [184, \"reasoning\", \"description\", 0.560976, 0.878049, 0.512195, 0.913043, 1.039855, 0.019631, 1.402439, 0.087302], [150, \"word\", \"description\", 0.621951, 0.878049, 0.567073, 0.911765, 1.038399, 0.02097, 1.382114, 0.097815], [80, \"detailed\", \"step\", 0.72561, 0.914634, 0.689024, 0.94958, 1.038207, 0.025357, 1.693089, 0.13412], [235, \"acquisition\", \"description\", 0.481707, 0.878049, 0.439024, 0.911392, 1.037975, 0.016062, 1.376307, 0.070588], [165, \"word\", \"database\", 0.621951, 0.841463, 0.542683, 0.872549, 1.036942, 0.019334, 1.243902, 0.094237], [45, \"processing\", \"analysis\", 0.780488, 0.95122, 0.768293, 0.984375, 1.034856, 0.025877, 3.121951, 0.153439], [44, \"analysis\", \"processing\", 0.95122, 0.780488, 0.768293, 0.807692, 1.034856, 0.025877, 1.141463, 0.690476], [173, \"check\", \"database\", 0.609756, 0.841463, 0.530488, 0.87, 1.033913, 0.0174, 1.219512, 0.084052], [151, \"xml\", \"database\", 0.652439, 0.841463, 0.567073, 0.869159, 1.032913, 0.01807, 1.211672, 0.091681], [260, \"cad\", \"description\", 0.457317, 0.878049, 0.414634, 0.906667, 1.032593, 0.013087, 1.30662, 0.058163], [107, \"material\", \"step\", 0.658537, 0.914634, 0.621951, 0.944444, 1.032593, 0.019631, 1.536585, 0.092437], [93, \"express\", \"description\", 0.713415, 0.878049, 0.646341, 0.905983, 1.031814, 0.019929, 1.297118, 0.107587], [190, \"word\", \"add\", 0.621951, 0.79878, 0.512195, 0.823529, 1.030983, 0.015393, 1.140244, 0.079493], [266, \"manufacture\", \"step\", 0.426829, 0.914634, 0.402439, 0.942857, 1.030857, 0.012046, 1.493902, 0.052224], [121, \"word\", \"analysis\", 0.621951, 0.95122, 0.609756, 0.980392, 1.030669, 0.018144, 2.487805, 0.07871], [169, \"xml\", \"add\", 0.652439, 0.79878, 0.536585, 0.82243, 1.029607, 0.01543, 1.133184, 0.082735], [164, \"reasoning\", \"analysis\", 0.560976, 0.95122, 0.54878, 0.978261, 1.028428, 0.01517, 2.243902, 0.062963], [84, \"detailed\", \"access\", 0.72561, 0.908537, 0.676829, 0.932773, 1.026676, 0.017586, 1.360518, 0.094695], [199, \"failure\", \"analysis\", 0.512195, 0.95122, 0.5, 0.97619, 1.026252, 0.01279, 2.04878, 0.052439], [222, \"difficulty\", \"step\", 0.493902, 0.914634, 0.463415, 0.938272, 1.025844, 0.011675, 1.382927, 0.049778], [86, \"express\", \"access\", 0.713415, 0.908537, 0.664634, 0.931624, 1.025412, 0.016471, 1.337652, 0.086473], [181, \"optimization\", \"add\", 0.640244, 0.79878, 0.52439, 0.819048, 1.025373, 0.012976, 1.112003, 0.068782], [211, \"difficulty\", \"analysis\", 0.493902, 0.95122, 0.481707, 0.975309, 1.025324, 0.011898, 1.97561, 0.048803], [55, \"access\", \"add\", 0.908537, 0.79878, 0.743902, 0.818792, 1.025053, 0.018181, 1.110434, 0.267213], [56, \"add\", \"access\", 0.79878, 0.908537, 0.743902, 0.931298, 1.025053, 0.018181, 1.331301, 0.121461], [209, \"acquisition\", \"development\", 0.481707, 0.97561, 0.481707, 1.0, 1.025, 0.011749, Infinity, 0.047059], [253, \"manufacture\", \"development\", 0.426829, 0.97561, 0.426829, 1.0, 1.025, 0.01041, Infinity, 0.042553], [189, \"failure\", \"development\", 0.512195, 0.97561, 0.512195, 1.0, 1.025, 0.012493, Infinity, 0.05], [160, \"check\", \"description\", 0.609756, 0.878049, 0.54878, 0.9, 1.025, 0.013385, 1.219512, 0.0625], [176, \"training\", \"development\", 0.530488, 0.97561, 0.530488, 1.0, 1.025, 0.012939, Infinity, 0.051948], [29, \"description\", \"step\", 0.878049, 0.914634, 0.823171, 0.9375, 1.025, 0.020077, 1.365854, 0.2], [185, \"optimization\", \"processing\", 0.640244, 0.780488, 0.512195, 0.8, 1.025, 0.012493, 1.097561, 0.067797], [28, \"step\", \"description\", 0.914634, 0.878049, 0.823171, 0.9, 1.025, 0.020077, 1.219512, 0.285714], [217, \"acquisition\", \"analysis\", 0.481707, 0.95122, 0.469512, 0.974684, 1.024667, 0.011303, 1.926829, 0.046448], [152, \"check\", \"access\", 0.609756, 0.908537, 0.567073, 0.93, 1.023624, 0.013087, 1.30662, 0.05914], [66, \"evaluation\", \"step\", 0.762195, 0.914634, 0.713415, 0.936, 1.02336, 0.016285, 1.333841, 0.095989], [252, \"inference\", \"analysis\", 0.439024, 0.95122, 0.426829, 0.972222, 1.02208, 0.009221, 1.756098, 0.038509], [98, \"material\", \"analysis\", 0.658537, 0.95122, 0.640244, 0.972222, 1.02208, 0.013831, 1.756098, 0.063265], [38, \"step\", \"database\", 0.914634, 0.841463, 0.786585, 0.86, 1.022029, 0.016954, 1.132404, 0.252492], [37, \"database\", \"step\", 0.841463, 0.914634, 0.786585, 0.934783, 1.022029, 0.016954, 1.308943, 0.135957], [135, \"xml\", \"description\", 0.652439, 0.878049, 0.585366, 0.897196, 1.021807, 0.012493, 1.186253, 0.061404], [81, \"review\", \"description\", 0.768293, 0.878049, 0.689024, 0.896825, 1.021384, 0.014426, 1.181989, 0.090359], [109, \"optimization\", \"analysis\", 0.640244, 0.95122, 0.621951, 0.971429, 1.021245, 0.012939, 1.707317, 0.057827], [259, \"manufacture\", \"analysis\", 0.426829, 0.95122, 0.414634, 0.971429, 1.021245, 0.008626, 1.707317, 0.036295], [163, \"ontology\", \"access\", 0.591463, 0.908537, 0.54878, 0.927835, 1.021241, 0.011414, 1.267422, 0.050912], [208, \"reasoning\", \"database\", 0.560976, 0.841463, 0.481707, 0.858696, 1.020479, 0.009667, 1.121951, 0.04571], [147, \"optimization\", \"description\", 0.640244, 0.878049, 0.573171, 0.895238, 1.019577, 0.011005, 1.16408, 0.053372], [255, \"api\", \"step\", 0.45122, 0.914634, 0.420732, 0.932432, 1.019459, 0.008031, 1.263415, 0.034783], [43, \"add\", \"analysis\", 0.79878, 0.95122, 0.77439, 0.969466, 1.019182, 0.014575, 1.597561, 0.093534], [42, \"analysis\", \"add\", 0.95122, 0.79878, 0.77439, 0.814103, 1.019182, 0.014575, 1.082422, 0.385827], [119, \"material\", \"access\", 0.658537, 0.908537, 0.609756, 0.925926, 1.01914, 0.011452, 1.234756, 0.055], [111, \"detailed\", \"database\", 0.72561, 0.841463, 0.621951, 0.857143, 1.018634, 0.011377, 1.109756, 0.066667], [139, \"creation\", \"step\", 0.621951, 0.914634, 0.579268, 0.931373, 1.018301, 0.01041, 1.243902, 0.047538], [16, \"description\", \"development\", 0.878049, 0.97561, 0.871951, 0.993056, 1.017882, 0.015318, 3.512195, 0.144056], [17, \"development\", \"description\", 0.97561, 0.878049, 0.871951, 0.89375, 1.017882, 0.015318, 1.147776, 0.72028], [183, \"reasoning\", \"access\", 0.560976, 0.908537, 0.518293, 0.923913, 1.016924, 0.008626, 1.202091, 0.037908], [51, \"evaluation\", \"development\", 0.762195, 0.97561, 0.756098, 0.992, 1.0168, 0.012493, 3.04878, 0.069479], [76, \"detailed\", \"analysis\", 0.72561, 0.95122, 0.70122, 0.966387, 1.015945, 0.011005, 1.45122, 0.057198], [89, \"material\", \"development\", 0.658537, 0.97561, 0.652439, 0.990741, 1.015509, 0.009964, 2.634146, 0.044726], [83, \"express\", \"analysis\", 0.713415, 0.95122, 0.689024, 0.965812, 1.015341, 0.01041, 1.426829, 0.052721], [99, \"manufacturing\", \"development\", 0.646341, 0.97561, 0.640244, 0.990566, 1.01533, 0.009667, 2.585366, 0.042693], [67, \"review\", \"step\", 0.768293, 0.914634, 0.713415, 0.928571, 1.015238, 0.010708, 1.195122, 0.064777], [214, \"failure\", \"step\", 0.512195, 0.914634, 0.47561, 0.928571, 1.015238, 0.007139, 1.195122, 0.030769], [114, \"creation\", \"development\", 0.621951, 0.97561, 0.615854, 0.990196, 1.014951, 0.009072, 2.487805, 0.038965], [65, \"processing\", \"access\", 0.780488, 0.908537, 0.719512, 0.921875, 1.014681, 0.01041, 1.170732, 0.065913], [78, \"processing\", \"description\", 0.780488, 0.878049, 0.695122, 0.890625, 1.014323, 0.009816, 1.114983, 0.064327], [156, \"reasoning\", \"development\", 0.560976, 0.97561, 0.554878, 0.98913, 1.013859, 0.007585, 2.243902, 0.031136], [33, \"database\", \"analysis\", 0.841463, 0.95122, 0.810976, 0.963768, 1.013192, 0.010559, 1.346341, 0.082128], [32, \"analysis\", \"database\", 0.95122, 0.841463, 0.810976, 0.852564, 1.013192, 0.010559, 1.075292, 0.266917], [207, \"difficulty\", \"development\", 0.493902, 0.97561, 0.487805, 0.987654, 1.012346, 0.005949, 1.97561, 0.024096], [236, \"difficulty\", \"description\", 0.493902, 0.878049, 0.439024, 0.888889, 1.012346, 0.005354, 1.097561, 0.024096], [206, \"training\", \"access\", 0.530488, 0.908537, 0.487805, 0.91954, 1.012111, 0.005837, 1.13676, 0.025487], [110, \"manufacturing\", \"analysis\", 0.646341, 0.95122, 0.621951, 0.962264, 1.011611, 0.007139, 1.292683, 0.032454], [123, \"xml\", \"step\", 0.652439, 0.914634, 0.603659, 0.925234, 1.011589, 0.006916, 1.141768, 0.032961], [231, \"cad\", \"development\", 0.457317, 0.97561, 0.45122, 0.986667, 1.011333, 0.005057, 1.829268, 0.02065], [125, \"manufacturing\", \"step\", 0.646341, 0.914634, 0.597561, 0.924528, 1.010818, 0.006395, 1.131098, 0.03026], [243, \"inference\", \"development\", 0.439024, 0.97561, 0.432927, 0.986111, 1.010764, 0.00461, 1.756098, 0.018983], [233, \"acquisition\", \"step\", 0.481707, 0.914634, 0.445122, 0.924051, 1.010295, 0.004536, 1.123984, 0.019662], [127, \"creation\", \"analysis\", 0.621951, 0.95122, 0.597561, 0.960784, 1.010055, 0.005949, 1.243902, 0.026333], [57, \"step\", \"add\", 0.914634, 0.79878, 0.737805, 0.806667, 1.009873, 0.007213, 1.040791, 0.114522], [58, \"add\", \"step\", 0.79878, 0.914634, 0.737805, 0.923664, 1.009873, 0.007213, 1.118293, 0.048585], [59, \"review\", \"analysis\", 0.768293, 0.95122, 0.737805, 0.960317, 1.009565, 0.00699, 1.229268, 0.040887], [239, \"cad\", \"analysis\", 0.457317, 0.95122, 0.439024, 0.96, 1.009231, 0.004015, 1.219512, 0.016854], [60, \"evaluation\", \"analysis\", 0.762195, 0.95122, 0.731707, 0.96, 1.009231, 0.006692, 1.219512, 0.038462], [15, \"step\", \"analysis\", 0.914634, 0.95122, 0.878049, 0.96, 1.009231, 0.008031, 1.219512, 0.107143], [14, \"analysis\", \"step\", 0.95122, 0.914634, 0.878049, 0.923077, 1.009231, 0.008031, 1.109756, 0.1875], [46, \"processing\", \"development\", 0.780488, 0.97561, 0.768293, 0.984375, 1.008984, 0.006841, 1.560976, 0.040564], [50, \"review\", \"development\", 0.768293, 0.97561, 0.756098, 0.984127, 1.00873, 0.006544, 1.536585, 0.037351], [241, \"api\", \"analysis\", 0.45122, 0.95122, 0.432927, 0.959459, 1.008663, 0.003718, 1.203252, 0.015649], [128, \"xml\", \"access\", 0.652439, 0.908537, 0.597561, 0.915888, 1.008091, 0.004796, 1.087398, 0.023093], [64, \"processing\", \"step\", 0.780488, 0.914634, 0.719512, 0.921875, 1.007917, 0.005651, 1.092683, 0.035782], [143, \"word\", \"step\", 0.621951, 0.914634, 0.573171, 0.921569, 1.007582, 0.004313, 1.088415, 0.019904], [97, \"optimization\", \"design\", 0.640244, 0.993902, 0.640244, 1.0, 1.006135, 0.003904, Infinity, 0.016949], [269, \"image\", \"design\", 0.402439, 0.993902, 0.402439, 1.0, 1.006135, 0.002454, Infinity, 0.010204], [6, \"design\", \"step\", 0.993902, 0.914634, 0.914634, 0.920245, 1.006135, 0.005577, 1.070356, 1.0], [225, \"cad\", \"design\", 0.457317, 0.993902, 0.457317, 1.0, 1.006135, 0.002789, Infinity, 0.011236], [39, \"processing\", \"design\", 0.780488, 0.993902, 0.780488, 1.0, 1.006135, 0.004759, Infinity, 0.027778], [234, \"inference\", \"design\", 0.439024, 0.993902, 0.439024, 1.0, 1.006135, 0.002677, Infinity, 0.01087], [227, \"api\", \"design\", 0.45122, 0.993902, 0.45122, 1.0, 1.006135, 0.002751, Infinity, 0.011111], [108, \"word\", \"design\", 0.621951, 0.993902, 0.621951, 1.0, 1.006135, 0.003792, Infinity, 0.016129], [47, \"review\", \"design\", 0.768293, 0.993902, 0.768293, 1.0, 1.006135, 0.004685, Infinity, 0.026316], [154, \"reasoning\", \"design\", 0.560976, 0.993902, 0.560976, 1.0, 1.006135, 0.003421, Infinity, 0.013889], [23, \"design\", \"database\", 0.993902, 0.841463, 0.841463, 0.846626, 1.006135, 0.005131, 1.033659, 1.0], [175, \"training\", \"design\", 0.530488, 0.993902, 0.530488, 1.0, 1.006135, 0.003235, Infinity, 0.012987], [22, \"database\", \"design\", 0.841463, 0.993902, 0.841463, 1.0, 1.006135, 0.005131, Infinity, 0.038462], [63, \"detailed\", \"design\", 0.72561, 0.993902, 0.72561, 1.0, 1.006135, 0.004424, Infinity, 0.022222], [120, \"check\", \"design\", 0.609756, 0.993902, 0.609756, 1.0, 1.006135, 0.003718, Infinity, 0.015625], [2, \"analysis\", \"design\", 0.95122, 0.993902, 0.95122, 1.0, 1.006135, 0.0058, Infinity, 0.125], [68, \"express\", \"design\", 0.713415, 0.993902, 0.713415, 1.0, 1.006135, 0.00435, Infinity, 0.021277], [87, \"material\", \"design\", 0.658537, 0.993902, 0.658537, 1.0, 1.006135, 0.004015, Infinity, 0.017857], [191, \"failure\", \"design\", 0.512195, 0.993902, 0.512195, 1.0, 1.006135, 0.003123, Infinity, 0.0125], [3, \"design\", \"analysis\", 0.993902, 0.95122, 0.95122, 0.957055, 1.006135, 0.0058, 1.135889, 1.0], [92, \"manufacturing\", \"design\", 0.646341, 0.993902, 0.646341, 1.0, 1.006135, 0.003941, Infinity, 0.017241], [249, \"manufacture\", \"design\", 0.426829, 0.993902, 0.426829, 1.0, 1.006135, 0.002603, Infinity, 0.010638], [7, \"step\", \"design\", 0.914634, 0.993902, 0.914634, 1.0, 1.006135, 0.005577, Infinity, 0.071429], [96, \"xml\", \"development\", 0.652439, 0.97561, 0.640244, 0.981308, 1.005841, 0.003718, 1.304878, 0.016708], [145, \"express\", \"add\", 0.713415, 0.79878, 0.573171, 0.803419, 1.005807, 0.003309, 1.023595, 0.020145], [124, \"express\", \"database\", 0.713415, 0.841463, 0.603659, 0.846154, 1.005574, 0.003346, 1.030488, 0.019342], [106, \"optimization\", \"development\", 0.640244, 0.97561, 0.628049, 0.980952, 1.005476, 0.003421, 1.280488, 0.015139], [5, \"development\", \"analysis\", 0.97561, 0.95122, 0.932927, 0.95625, 1.005288, 0.004908, 1.114983, 0.215686], [4, \"analysis\", \"development\", 0.95122, 0.97561, 0.932927, 0.980769, 1.005288, 0.004908, 1.268293, 0.107843], [25, \"step\", \"access\", 0.914634, 0.908537, 0.835366, 0.913333, 1.00528, 0.004387, 1.055347, 0.061522], [24, \"access\", \"step\", 0.908537, 0.914634, 0.835366, 0.919463, 1.00528, 0.004387, 1.059959, 0.057421], [122, \"word\", \"development\", 0.621951, 0.97561, 0.609756, 0.980392, 1.004902, 0.002974, 1.243902, 0.012903], [100, \"detailed\", \"description\", 0.72561, 0.878049, 0.640244, 0.882353, 1.004902, 0.003123, 1.036585, 0.017778], [200, \"ontology\", \"database\", 0.591463, 0.841463, 0.5, 0.845361, 1.004632, 0.002305, 1.025203, 0.011285], [126, \"check\", \"development\", 0.609756, 0.97561, 0.597561, 0.98, 1.0045, 0.002677, 1.219512, 0.01148], [195, \"training\", \"analysis\", 0.530488, 0.95122, 0.506098, 0.954023, 1.002947, 0.001487, 1.060976, 0.006259], [271, \"inference\", \"step\", 0.439024, 0.914634, 0.402439, 0.916667, 1.002222, 0.000892, 1.02439, 0.003953], [20, \"analysis\", \"access\", 0.95122, 0.908537, 0.865854, 0.910256, 1.001893, 0.001636, 1.019164, 0.038732], [21, \"access\", \"analysis\", 0.908537, 0.95122, 0.865854, 0.95302, 1.001893, 0.001636, 1.038328, 0.020657], [40, \"development\", \"add\", 0.97561, 0.79878, 0.780488, 0.8, 1.001527, 0.00119, 1.006098, 0.0625], [41, \"add\", \"development\", 0.79878, 0.97561, 0.780488, 0.977099, 1.001527, 0.00119, 1.065041, 0.007576], [34, \"access\", \"description\", 0.908537, 0.878049, 0.79878, 0.879195, 1.001305, 0.001041, 1.009485, 0.014249], [35, \"description\", \"access\", 0.878049, 0.908537, 0.79878, 0.909722, 1.001305, 0.001041, 1.013133, 0.010687], [26, \"analysis\", \"description\", 0.95122, 0.878049, 0.835366, 0.878205, 1.000178, 0.000149, 1.001284, 0.00365], [27, \"description\", \"analysis\", 0.878049, 0.95122, 0.835366, 0.951389, 1.000178, 0.000149, 1.003484, 0.00146], [88, \"express\", \"step\", 0.713415, 0.914634, 0.652439, 0.91453, 0.999886, -7.4e-05, 0.99878, -0.000398], [0, \"design\", \"development\", 0.993902, 0.97561, 0.969512, 0.97546, 0.999847, -0.000149, 0.993902, -0.02454], [1, \"development\", \"design\", 0.97561, 0.993902, 0.969512, 0.99375, 0.999847, -0.000149, 0.97561, -0.00625], [73, \"add\", \"description\", 0.79878, 0.878049, 0.70122, 0.877863, 0.999788, -0.000149, 0.998476, -0.001053], [94, \"review\", \"database\", 0.768293, 0.841463, 0.646341, 0.84127, 0.99977, -0.000149, 0.99878, -0.000992], [9, \"access\", \"design\", 0.908537, 0.993902, 0.902439, 0.993289, 0.999382, -0.000558, 0.908537, -0.006711], [8, \"design\", \"access\", 0.993902, 0.908537, 0.902439, 0.907975, 0.999382, -0.000558, 0.993902, -0.092025], [19, \"description\", \"design\", 0.878049, 0.993902, 0.871951, 0.993056, 0.999148, -0.000744, 0.878049, -0.006944], [18, \"design\", \"description\", 0.993902, 0.878049, 0.871951, 0.877301, 0.999148, -0.000744, 0.993902, -0.122699], [79, \"express\", \"development\", 0.713415, 0.97561, 0.695122, 0.974359, 0.998718, -0.000892, 0.95122, -0.004459], [141, \"check\", \"analysis\", 0.609756, 0.95122, 0.579268, 0.95, 0.998718, -0.000744, 0.97561, -0.003279], [36, \"add\", \"design\", 0.79878, 0.993902, 0.792683, 0.992366, 0.998455, -0.001227, 0.79878, -0.007634], [52, \"evaluation\", \"design\", 0.762195, 0.993902, 0.756098, 0.992, 0.998086, -0.00145, 0.762195, -0.008], [166, \"manufacturing\", \"database\", 0.646341, 0.841463, 0.542683, 0.839623, 0.997812, -0.00119, 0.988522, -0.006161], [11, \"development\", \"step\", 0.97561, 0.914634, 0.890244, 0.9125, 0.997667, -0.002082, 0.97561, -0.0875], [10, \"step\", \"development\", 0.914634, 0.97561, 0.890244, 0.973333, 0.997667, -0.002082, 0.914634, -0.026667], [12, \"access\", \"development\", 0.908537, 0.97561, 0.884146, 0.973154, 0.997483, -0.002231, 0.908537, -0.026846], [13, \"development\", \"access\", 0.97561, 0.908537, 0.884146, 0.90625, 0.997483, -0.002231, 0.97561, -0.09375], [155, \"ontology\", \"analysis\", 0.591463, 0.95122, 0.560976, 0.948454, 0.997092, -0.001636, 0.946341, -0.007088], [48, \"database\", \"access\", 0.841463, 0.908537, 0.762195, 0.905797, 0.996985, -0.002305, 0.970919, -0.01872], [49, \"access\", \"database\", 0.908537, 0.841463, 0.762195, 0.838926, 0.996985, -0.002305, 0.984248, -0.032008], [95, \"xml\", \"design\", 0.652439, 0.993902, 0.646341, 0.990654, 0.996732, -0.002119, 0.652439, -0.009346], [115, \"creation\", \"design\", 0.621951, 0.993902, 0.615854, 0.990196, 0.996271, -0.002305, 0.621951, -0.009804], [221, \"failure\", \"access\", 0.512195, 0.908537, 0.463415, 0.904762, 0.995845, -0.001933, 0.960366, -0.00848], [140, \"optimization\", \"access\", 0.640244, 0.908537, 0.579268, 0.904762, 0.995845, -0.002417, 0.960366, -0.011464], [136, \"ontology\", \"design\", 0.591463, 0.993902, 0.585366, 0.989691, 0.995762, -0.002491, 0.591463, -0.010309], [30, \"database\", \"development\", 0.841463, 0.97561, 0.817073, 0.971014, 0.99529, -0.003867, 0.841463, -0.028986], [31, \"development\", \"database\", 0.97561, 0.841463, 0.817073, 0.8375, 0.99529, -0.003867, 0.97561, -0.1625], [82, \"evaluation\", \"access\", 0.762195, 0.908537, 0.689024, 0.904, 0.995007, -0.003458, 0.952744, -0.020667], [205, \"difficulty\", \"design\", 0.493902, 0.993902, 0.487805, 0.987654, 0.993714, -0.003086, 0.493902, -0.012346], [212, \"acquisition\", \"design\", 0.481707, 0.993902, 0.47561, 0.987342, 0.993399, -0.00316, 0.481707, -0.012658], [146, \"ontology\", \"development\", 0.591463, 0.97561, 0.573171, 0.969072, 0.993299, -0.003867, 0.788618, -0.016245], [167, \"ontology\", \"step\", 0.591463, 0.914634, 0.536585, 0.907216, 0.99189, -0.004387, 0.920054, -0.019621], [77, \"detailed\", \"development\", 0.72561, 0.97561, 0.70122, 0.966387, 0.990546, -0.006692, 0.72561, -0.033613], [61, \"database\", \"description\", 0.841463, 0.878049, 0.731707, 0.869565, 0.990338, -0.007139, 0.934959, -0.057971], [62, \"description\", \"database\", 0.878049, 0.841463, 0.731707, 0.833333, 0.990338, -0.007139, 0.95122, -0.074074], [138, \"manufacturing\", \"access\", 0.646341, 0.908537, 0.579268, 0.896226, 0.986451, -0.007957, 0.881375, -0.037386], [193, \"reasoning\", \"step\", 0.560976, 0.914634, 0.506098, 0.902174, 0.986377, -0.00699, 0.872629, -0.0305], [240, \"api\", \"development\", 0.45122, 0.97561, 0.432927, 0.959459, 0.983446, -0.007287, 0.601626, -0.02976], [117, \"xml\", \"analysis\", 0.652439, 0.95122, 0.609756, 0.934579, 0.982507, -0.010857, 0.745645, -0.048732], [270, \"cad\", \"access\", 0.457317, 0.908537, 0.402439, 0.88, 0.968591, -0.01305, 0.762195, -0.056386]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": \"pageLength\", \"topEnd\": \"search\", \"bottomStart\": \"info\", \"bottomEnd\": \"paging\"}, \"order\": []};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_dataframe(config, rules, 'rules')\n",
    "# rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table id=\"itables_829befa5_de52_4c14_aaaa_6308cabebe66\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
       "<thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead><tbody><tr>\n",
       "<td style=\"vertical-align:middle; text-align:left\">\n",
       "<div style=\"float:left; margin-right: 10px;\">\n",
       "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
       "    <g style=\"fill:#d9d7fc\">\n",
       "        <path d=\"M100,400H500V357H100Z\" />\n",
       "        <path d=\"M100,300H400V257H100Z\" />\n",
       "        <path d=\"M0,200H400V157H0Z\" />\n",
       "        <path d=\"M100,100H500V57H100Z\" />\n",
       "        <path d=\"M100,350H500V307H100Z\" />\n",
       "        <path d=\"M100,250H400V207H100Z\" />\n",
       "        <path d=\"M0,150H400V107H0Z\" />\n",
       "        <path d=\"M100,50H500V7H100Z\" />\n",
       "    </g>\n",
       "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
       "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"0;0;400\"\n",
       "      dur=\"3.5s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;300;0\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "    <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;400\"\n",
       "      dur=\"3s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
       "    <animate\n",
       "      attributeName=\"width\"\n",
       "      values=\"0;400;0\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "      <animate\n",
       "      attributeName=\"x\"\n",
       "      values=\"100;100;500\"\n",
       "      dur=\"4s\"\n",
       "      repeatCount=\"indefinite\" />\n",
       "  </rect>\n",
       "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
       "            <g transform=\"translate(45 50) rotate(-45)\">\n",
       "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
       "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(450 152)\">\n",
       "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
       "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(50 352)\">\n",
       "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
       "                <polygon points=\"-35,10 0,45 35,10\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(75 250)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "\n",
       "            <g transform=\"translate(425 250) rotate(180)\">\n",
       "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
       "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
       "            </g>\n",
       "        </g>\n",
       "    </g>\n",
       "</svg>\n",
       "</a>\n",
       "</div>\n",
       "<div>\n",
       "Loading ITables v2.1.1 from the internet...\n",
       "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
       "</div>\n",
       "</tr></tbody>\n",
       "\n",
       "</table>\n",
       "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.10/dt_bundle.css\" rel=\"stylesheet\">\n",
       "<script type=\"module\">\n",
       "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.10/dt_bundle.js';\n",
       "\n",
       "    document.querySelectorAll(\"#itables_829befa5_de52_4c14_aaaa_6308cabebe66:not(.dataTable)\").forEach(table => {\n",
       "        // Define the table data\n",
       "        const data = [[265, \"cad\", \"manufacturing\", 0.457317, 0.646341, 0.402439, 0.88, 1.361509, 0.106856, 2.947154, 0.489275], [229, \"reasoning\", \"ontology\", 0.560976, 0.591463, 0.45122, 0.804348, 1.359928, 0.119423, 2.088076, 0.602853], [180, \"manufacturing\", \"material\", 0.646341, 0.658537, 0.52439, 0.811321, 1.232006, 0.098751, 1.809756, 0.532478], [188, \"word\", \"express\", 0.621951, 0.713415, 0.512195, 0.823529, 1.154349, 0.068486, 1.623984, 0.353687], [244, \"training\", \"express\", 0.530488, 0.713415, 0.432927, 0.816092, 1.143924, 0.054469, 1.558308, 0.267971], [144, \"material\", \"evaluation\", 0.658537, 0.762195, 0.573171, 0.87037, 1.141926, 0.071237, 1.834495, 0.363982], [242, \"difficulty\", \"review\", 0.493902, 0.768293, 0.432927, 0.876543, 1.140898, 0.053465, 1.876829, 0.244018], [197, \"creation\", \"express\", 0.621951, 0.713415, 0.506098, 0.813725, 1.140607, 0.062388, 1.538511, 0.326079], [213, \"ontology\", \"express\", 0.591463, 0.713415, 0.47561, 0.804124, 1.127148, 0.053651, 1.463094, 0.276119], [264, \"api\", \"add\", 0.45122, 0.79878, 0.402439, 0.891892, 1.116567, 0.042014, 1.86128, 0.190236], [171, \"word\", \"review\", 0.621951, 0.768293, 0.530488, 0.852941, 1.110177, 0.052647, 1.57561, 0.262514], [177, \"material\", \"detailed\", 0.658537, 0.72561, 0.530488, 0.805556, 1.110177, 0.052647, 1.41115, 0.29064], [168, \"check\", \"add\", 0.609756, 0.79878, 0.536585, 0.88, 1.101679, 0.049524, 1.676829, 0.236506], [158, \"material\", \"review\", 0.658537, 0.768293, 0.554878, 0.842593, 1.096708, 0.048929, 1.472023, 0.258242], [172, \"word\", \"processing\", 0.621951, 0.780488, 0.530488, 0.852941, 1.092831, 0.045062, 1.492683, 0.224694], [153, \"material\", \"processing\", 0.658537, 0.780488, 0.560976, 0.851852, 1.091435, 0.046996, 1.481707, 0.245342], [194, \"training\", \"description\", 0.530488, 0.878049, 0.506098, 0.954023, 1.086526, 0.040303, 2.652439, 0.169614], [105, \"detailed\", \"add\", 0.72561, 0.79878, 0.628049, 0.865546, 1.083585, 0.048446, 1.49657, 0.281122], [247, \"difficulty\", \"add\", 0.493902, 0.79878, 0.426829, 0.864198, 1.081896, 0.03231, 1.481707, 0.14957], [70, \"processing\", \"database\", 0.780488, 0.841463, 0.707317, 0.90625, 1.076993, 0.050565, 1.691057, 0.32567], [69, \"database\", \"processing\", 0.841463, 0.780488, 0.707317, 0.84058, 1.076993, 0.050565, 1.37694, 0.450928], [262, \"api\", \"database\", 0.45122, 0.841463, 0.408537, 0.905405, 1.075989, 0.028852, 1.675958, 0.12869], [257, \"inference\", \"description\", 0.439024, 0.878049, 0.414634, 0.944444, 1.075617, 0.029149, 2.195122, 0.12532], [256, \"difficulty\", \"processing\", 0.493902, 0.780488, 0.414634, 0.839506, 1.075617, 0.029149, 1.36773, 0.138909], [237, \"failure\", \"add\", 0.512195, 0.79878, 0.439024, 0.857143, 1.073064, 0.029893, 1.408537, 0.139583], [204, \"ontology\", \"processing\", 0.591463, 0.780488, 0.493902, 0.835052, 1.06991, 0.032272, 1.330793, 0.159941], [268, \"difficulty\", \"evaluation\", 0.493902, 0.762195, 0.402439, 0.814815, 1.069037, 0.025989, 1.284146, 0.127601], [198, \"word\", \"evaluation\", 0.621951, 0.762195, 0.506098, 0.813725, 1.067608, 0.032049, 1.276637, 0.167509], [133, \"material\", \"database\", 0.658537, 0.841463, 0.591463, 0.898148, 1.067364, 0.037329, 1.556541, 0.184831], [54, \"review\", \"access\", 0.768293, 0.908537, 0.743902, 0.968254, 1.065729, 0.04588, 2.881098, 0.266178], [53, \"access\", \"review\", 0.908537, 0.768293, 0.743902, 0.818792, 1.065729, 0.04588, 1.278681, 0.674317], [215, \"training\", \"database\", 0.530488, 0.841463, 0.47561, 0.896552, 1.065467, 0.029224, 1.53252, 0.130869], [148, \"optimization\", \"database\", 0.640244, 0.841463, 0.573171, 0.895238, 1.063906, 0.034429, 1.513304, 0.166967], [134, \"express\", \"processing\", 0.713415, 0.780488, 0.591463, 0.82906, 1.062233, 0.034652, 1.284146, 0.204431], [157, \"creation\", \"database\", 0.621951, 0.841463, 0.554878, 0.892157, 1.060244, 0.031529, 1.470067, 0.150301], [216, \"difficulty\", \"access\", 0.493902, 0.908537, 0.47561, 0.962963, 1.059906, 0.026881, 2.469512, 0.111677], [72, \"evaluation\", \"description\", 0.762195, 0.878049, 0.707317, 0.928, 1.056889, 0.038073, 1.693767, 0.226348], [71, \"description\", \"evaluation\", 0.878049, 0.762195, 0.707317, 0.805556, 1.056889, 0.038073, 1.222997, 0.441379], [142, \"express\", \"review\", 0.713415, 0.768293, 0.579268, 0.811966, 1.056844, 0.031157, 1.232262, 0.187682], [187, \"training\", \"step\", 0.530488, 0.914634, 0.512195, 0.965517, 1.055632, 0.026993, 2.47561, 0.112245], [179, \"creation\", \"add\", 0.621951, 0.79878, 0.52439, 0.843137, 1.055531, 0.027588, 1.282774, 0.13916], [159, \"material\", \"add\", 0.658537, 0.79878, 0.554878, 0.842593, 1.054849, 0.028852, 1.278336, 0.152276], [254, \"inference\", \"access\", 0.439024, 0.908537, 0.420732, 0.958333, 1.05481, 0.021862, 2.195122, 0.092628], [101, \"evaluation\", \"add\", 0.762195, 0.79878, 0.640244, 0.84, 1.051603, 0.031417, 1.257622, 0.206349], [102, \"add\", \"evaluation\", 0.79878, 0.762195, 0.640244, 0.801527, 1.051603, 0.031417, 1.198171, 0.243867], [267, \"image\", \"analysis\", 0.402439, 0.95122, 0.402439, 1.0, 1.051282, 0.019631, Infinity, 0.081633], [232, \"training\", \"add\", 0.530488, 0.79878, 0.445122, 0.83908, 1.050452, 0.021379, 1.250436, 0.102295], [238, \"cad\", \"step\", 0.457317, 0.914634, 0.439024, 0.96, 1.0496, 0.020747, 2.134146, 0.087079], [137, \"check\", \"step\", 0.609756, 0.914634, 0.585366, 0.96, 1.0496, 0.027662, 2.134146, 0.121094], [149, \"creation\", \"description\", 0.621951, 0.878049, 0.573171, 0.921569, 1.049564, 0.027067, 1.554878, 0.124914], [228, \"failure\", \"database\", 0.512195, 0.841463, 0.45122, 0.880952, 1.046929, 0.020226, 1.331707, 0.091892], [132, \"creation\", \"access\", 0.621951, 0.908537, 0.591463, 0.95098, 1.046717, 0.026398, 1.865854, 0.118058], [90, \"processing\", \"add\", 0.780488, 0.79878, 0.652439, 0.835938, 1.046517, 0.029001, 1.226481, 0.202492], [91, \"add\", \"processing\", 0.79878, 0.780488, 0.652439, 0.816794, 1.046517, 0.029001, 1.198171, 0.220901], [85, \"evaluation\", \"database\", 0.762195, 0.841463, 0.670732, 0.88, 1.045797, 0.029372, 1.321138, 0.184149], [226, \"acquisition\", \"access\", 0.481707, 0.908537, 0.457317, 0.949367, 1.044941, 0.019668, 1.806402, 0.08298], [219, \"failure\", \"description\", 0.512195, 0.878049, 0.469512, 0.916667, 1.043981, 0.01978, 1.463415, 0.086364], [129, \"manufacturing\", \"description\", 0.646341, 0.878049, 0.591463, 0.915094, 1.042191, 0.023944, 1.436314, 0.114469], [245, \"difficulty\", \"database\", 0.493902, 0.841463, 0.432927, 0.876543, 1.041689, 0.017326, 1.284146, 0.079077], [118, \"optimization\", \"step\", 0.640244, 0.914634, 0.609756, 0.952381, 1.04127, 0.024167, 1.792683, 0.110169], [184, \"reasoning\", \"description\", 0.560976, 0.878049, 0.512195, 0.913043, 1.039855, 0.019631, 1.402439, 0.087302], [150, \"word\", \"description\", 0.621951, 0.878049, 0.567073, 0.911765, 1.038399, 0.02097, 1.382114, 0.097815], [80, \"detailed\", \"step\", 0.72561, 0.914634, 0.689024, 0.94958, 1.038207, 0.025357, 1.693089, 0.13412], [235, \"acquisition\", \"description\", 0.481707, 0.878049, 0.439024, 0.911392, 1.037975, 0.016062, 1.376307, 0.070588], [165, \"word\", \"database\", 0.621951, 0.841463, 0.542683, 0.872549, 1.036942, 0.019334, 1.243902, 0.094237], [173, \"check\", \"database\", 0.609756, 0.841463, 0.530488, 0.87, 1.033913, 0.0174, 1.219512, 0.084052], [107, \"material\", \"step\", 0.658537, 0.914634, 0.621951, 0.944444, 1.032593, 0.019631, 1.536585, 0.092437], [93, \"express\", \"description\", 0.713415, 0.878049, 0.646341, 0.905983, 1.031814, 0.019929, 1.297118, 0.107587], [190, \"word\", \"add\", 0.621951, 0.79878, 0.512195, 0.823529, 1.030983, 0.015393, 1.140244, 0.079493], [266, \"manufacture\", \"step\", 0.426829, 0.914634, 0.402439, 0.942857, 1.030857, 0.012046, 1.493902, 0.052224], [121, \"word\", \"analysis\", 0.621951, 0.95122, 0.609756, 0.980392, 1.030669, 0.018144, 2.487805, 0.07871], [84, \"detailed\", \"access\", 0.72561, 0.908537, 0.676829, 0.932773, 1.026676, 0.017586, 1.360518, 0.094695], [222, \"difficulty\", \"step\", 0.493902, 0.914634, 0.463415, 0.938272, 1.025844, 0.011675, 1.382927, 0.049778], [86, \"express\", \"access\", 0.713415, 0.908537, 0.664634, 0.931624, 1.025412, 0.016471, 1.337652, 0.086473], [181, \"optimization\", \"add\", 0.640244, 0.79878, 0.52439, 0.819048, 1.025373, 0.012976, 1.112003, 0.068782], [211, \"difficulty\", \"analysis\", 0.493902, 0.95122, 0.481707, 0.975309, 1.025324, 0.011898, 1.97561, 0.048803], [55, \"access\", \"add\", 0.908537, 0.79878, 0.743902, 0.818792, 1.025053, 0.018181, 1.110434, 0.267213], [56, \"add\", \"access\", 0.79878, 0.908537, 0.743902, 0.931298, 1.025053, 0.018181, 1.331301, 0.121461], [160, \"check\", \"description\", 0.609756, 0.878049, 0.54878, 0.9, 1.025, 0.013385, 1.219512, 0.0625], [29, \"description\", \"step\", 0.878049, 0.914634, 0.823171, 0.9375, 1.025, 0.020077, 1.365854, 0.2], [28, \"step\", \"description\", 0.914634, 0.878049, 0.823171, 0.9, 1.025, 0.020077, 1.219512, 0.285714], [152, \"check\", \"access\", 0.609756, 0.908537, 0.567073, 0.93, 1.023624, 0.013087, 1.30662, 0.05914], [66, \"evaluation\", \"step\", 0.762195, 0.914634, 0.713415, 0.936, 1.02336, 0.016285, 1.333841, 0.095989], [98, \"material\", \"analysis\", 0.658537, 0.95122, 0.640244, 0.972222, 1.02208, 0.013831, 1.756098, 0.063265], [135, \"xml\", \"description\", 0.652439, 0.878049, 0.585366, 0.897196, 1.021807, 0.012493, 1.186253, 0.061404], [81, \"review\", \"description\", 0.768293, 0.878049, 0.689024, 0.896825, 1.021384, 0.014426, 1.181989, 0.090359], [163, \"ontology\", \"access\", 0.591463, 0.908537, 0.54878, 0.927835, 1.021241, 0.011414, 1.267422, 0.050912], [208, \"reasoning\", \"database\", 0.560976, 0.841463, 0.481707, 0.858696, 1.020479, 0.009667, 1.121951, 0.04571], [147, \"optimization\", \"description\", 0.640244, 0.878049, 0.573171, 0.895238, 1.019577, 0.011005, 1.16408, 0.053372], [255, \"api\", \"step\", 0.45122, 0.914634, 0.420732, 0.932432, 1.019459, 0.008031, 1.263415, 0.034783], [43, \"add\", \"analysis\", 0.79878, 0.95122, 0.77439, 0.969466, 1.019182, 0.014575, 1.597561, 0.093534], [42, \"analysis\", \"add\", 0.95122, 0.79878, 0.77439, 0.814103, 1.019182, 0.014575, 1.082422, 0.385827], [119, \"material\", \"access\", 0.658537, 0.908537, 0.609756, 0.925926, 1.01914, 0.011452, 1.234756, 0.055], [111, \"detailed\", \"database\", 0.72561, 0.841463, 0.621951, 0.857143, 1.018634, 0.011377, 1.109756, 0.066667], [139, \"creation\", \"step\", 0.621951, 0.914634, 0.579268, 0.931373, 1.018301, 0.01041, 1.243902, 0.047538], [16, \"description\", \"development\", 0.878049, 0.97561, 0.871951, 0.993056, 1.017882, 0.015318, 3.512195, 0.144056], [17, \"development\", \"description\", 0.97561, 0.878049, 0.871951, 0.89375, 1.017882, 0.015318, 1.147776, 0.72028], [183, \"reasoning\", \"access\", 0.560976, 0.908537, 0.518293, 0.923913, 1.016924, 0.008626, 1.202091, 0.037908], [89, \"material\", \"development\", 0.658537, 0.97561, 0.652439, 0.990741, 1.015509, 0.009964, 2.634146, 0.044726], [83, \"express\", \"analysis\", 0.713415, 0.95122, 0.689024, 0.965812, 1.015341, 0.01041, 1.426829, 0.052721], [67, \"review\", \"step\", 0.768293, 0.914634, 0.713415, 0.928571, 1.015238, 0.010708, 1.195122, 0.064777], [214, \"failure\", \"step\", 0.512195, 0.914634, 0.47561, 0.928571, 1.015238, 0.007139, 1.195122, 0.030769], [65, \"processing\", \"access\", 0.780488, 0.908537, 0.719512, 0.921875, 1.014681, 0.01041, 1.170732, 0.065913], [78, \"processing\", \"description\", 0.780488, 0.878049, 0.695122, 0.890625, 1.014323, 0.009816, 1.114983, 0.064327], [33, \"database\", \"analysis\", 0.841463, 0.95122, 0.810976, 0.963768, 1.013192, 0.010559, 1.346341, 0.082128], [32, \"analysis\", \"database\", 0.95122, 0.841463, 0.810976, 0.852564, 1.013192, 0.010559, 1.075292, 0.266917], [207, \"difficulty\", \"development\", 0.493902, 0.97561, 0.487805, 0.987654, 1.012346, 0.005949, 1.97561, 0.024096], [206, \"training\", \"access\", 0.530488, 0.908537, 0.487805, 0.91954, 1.012111, 0.005837, 1.13676, 0.025487], [231, \"cad\", \"development\", 0.457317, 0.97561, 0.45122, 0.986667, 1.011333, 0.005057, 1.829268, 0.02065], [125, \"manufacturing\", \"step\", 0.646341, 0.914634, 0.597561, 0.924528, 1.010818, 0.006395, 1.131098, 0.03026], [233, \"acquisition\", \"step\", 0.481707, 0.914634, 0.445122, 0.924051, 1.010295, 0.004536, 1.123984, 0.019662], [239, \"cad\", \"analysis\", 0.457317, 0.95122, 0.439024, 0.96, 1.009231, 0.004015, 1.219512, 0.016854], [15, \"step\", \"analysis\", 0.914634, 0.95122, 0.878049, 0.96, 1.009231, 0.008031, 1.219512, 0.107143], [14, \"analysis\", \"step\", 0.95122, 0.914634, 0.878049, 0.923077, 1.009231, 0.008031, 1.109756, 0.1875], [241, \"api\", \"analysis\", 0.45122, 0.95122, 0.432927, 0.959459, 1.008663, 0.003718, 1.203252, 0.015649], [128, \"xml\", \"access\", 0.652439, 0.908537, 0.597561, 0.915888, 1.008091, 0.004796, 1.087398, 0.023093], [64, \"processing\", \"step\", 0.780488, 0.914634, 0.719512, 0.921875, 1.007917, 0.005651, 1.092683, 0.035782], [143, \"word\", \"step\", 0.621951, 0.914634, 0.573171, 0.921569, 1.007582, 0.004313, 1.088415, 0.019904], [269, \"image\", \"design\", 0.402439, 0.993902, 0.402439, 1.0, 1.006135, 0.002454, Infinity, 0.010204], [6, \"design\", \"step\", 0.993902, 0.914634, 0.914634, 0.920245, 1.006135, 0.005577, 1.070356, 1.0], [225, \"cad\", \"design\", 0.457317, 0.993902, 0.457317, 1.0, 1.006135, 0.002789, Infinity, 0.011236], [227, \"api\", \"design\", 0.45122, 0.993902, 0.45122, 1.0, 1.006135, 0.002751, Infinity, 0.011111], [108, \"word\", \"design\", 0.621951, 0.993902, 0.621951, 1.0, 1.006135, 0.003792, Infinity, 0.016129], [23, \"design\", \"database\", 0.993902, 0.841463, 0.841463, 0.846626, 1.006135, 0.005131, 1.033659, 1.0], [22, \"database\", \"design\", 0.841463, 0.993902, 0.841463, 1.0, 1.006135, 0.005131, Infinity, 0.038462], [68, \"express\", \"design\", 0.713415, 0.993902, 0.713415, 1.0, 1.006135, 0.00435, Infinity, 0.021277], [87, \"material\", \"design\", 0.658537, 0.993902, 0.658537, 1.0, 1.006135, 0.004015, Infinity, 0.017857], [7, \"step\", \"design\", 0.914634, 0.993902, 0.914634, 1.0, 1.006135, 0.005577, Infinity, 0.071429], [96, \"xml\", \"development\", 0.652439, 0.97561, 0.640244, 0.981308, 1.005841, 0.003718, 1.304878, 0.016708], [145, \"express\", \"add\", 0.713415, 0.79878, 0.573171, 0.803419, 1.005807, 0.003309, 1.023595, 0.020145], [124, \"express\", \"database\", 0.713415, 0.841463, 0.603659, 0.846154, 1.005574, 0.003346, 1.030488, 0.019342], [25, \"step\", \"access\", 0.914634, 0.908537, 0.835366, 0.913333, 1.00528, 0.004387, 1.055347, 0.061522], [24, \"access\", \"step\", 0.908537, 0.914634, 0.835366, 0.919463, 1.00528, 0.004387, 1.059959, 0.057421], [122, \"word\", \"development\", 0.621951, 0.97561, 0.609756, 0.980392, 1.004902, 0.002974, 1.243902, 0.012903], [100, \"detailed\", \"description\", 0.72561, 0.878049, 0.640244, 0.882353, 1.004902, 0.003123, 1.036585, 0.017778], [200, \"ontology\", \"database\", 0.591463, 0.841463, 0.5, 0.845361, 1.004632, 0.002305, 1.025203, 0.011285], [271, \"inference\", \"step\", 0.439024, 0.914634, 0.402439, 0.916667, 1.002222, 0.000892, 1.02439, 0.003953], [20, \"analysis\", \"access\", 0.95122, 0.908537, 0.865854, 0.910256, 1.001893, 0.001636, 1.019164, 0.038732], [21, \"access\", \"analysis\", 0.908537, 0.95122, 0.865854, 0.95302, 1.001893, 0.001636, 1.038328, 0.020657], [40, \"development\", \"add\", 0.97561, 0.79878, 0.780488, 0.8, 1.001527, 0.00119, 1.006098, 0.0625], [41, \"add\", \"development\", 0.79878, 0.97561, 0.780488, 0.977099, 1.001527, 0.00119, 1.065041, 0.007576], [34, \"access\", \"description\", 0.908537, 0.878049, 0.79878, 0.879195, 1.001305, 0.001041, 1.009485, 0.014249], [35, \"description\", \"access\", 0.878049, 0.908537, 0.79878, 0.909722, 1.001305, 0.001041, 1.013133, 0.010687], [26, \"analysis\", \"description\", 0.95122, 0.878049, 0.835366, 0.878205, 1.000178, 0.000149, 1.001284, 0.00365], [27, \"description\", \"analysis\", 0.878049, 0.95122, 0.835366, 0.951389, 1.000178, 0.000149, 1.003484, 0.00146], [88, \"express\", \"step\", 0.713415, 0.914634, 0.652439, 0.91453, 0.999886, -7.4e-05, 0.99878, -0.000398], [73, \"add\", \"description\", 0.79878, 0.878049, 0.70122, 0.877863, 0.999788, -0.000149, 0.998476, -0.001053], [94, \"review\", \"database\", 0.768293, 0.841463, 0.646341, 0.84127, 0.99977, -0.000149, 0.99878, -0.000992], [9, \"access\", \"design\", 0.908537, 0.993902, 0.902439, 0.993289, 0.999382, -0.000558, 0.908537, -0.006711], [8, \"design\", \"access\", 0.993902, 0.908537, 0.902439, 0.907975, 0.999382, -0.000558, 0.993902, -0.092025], [19, \"description\", \"design\", 0.878049, 0.993902, 0.871951, 0.993056, 0.999148, -0.000744, 0.878049, -0.006944], [18, \"design\", \"description\", 0.993902, 0.878049, 0.871951, 0.877301, 0.999148, -0.000744, 0.993902, -0.122699], [79, \"express\", \"development\", 0.713415, 0.97561, 0.695122, 0.974359, 0.998718, -0.000892, 0.95122, -0.004459], [36, \"add\", \"design\", 0.79878, 0.993902, 0.792683, 0.992366, 0.998455, -0.001227, 0.79878, -0.007634], [166, \"manufacturing\", \"database\", 0.646341, 0.841463, 0.542683, 0.839623, 0.997812, -0.00119, 0.988522, -0.006161], [11, \"development\", \"step\", 0.97561, 0.914634, 0.890244, 0.9125, 0.997667, -0.002082, 0.97561, -0.0875], [10, \"step\", \"development\", 0.914634, 0.97561, 0.890244, 0.973333, 0.997667, -0.002082, 0.914634, -0.026667], [12, \"access\", \"development\", 0.908537, 0.97561, 0.884146, 0.973154, 0.997483, -0.002231, 0.908537, -0.026846], [13, \"development\", \"access\", 0.97561, 0.908537, 0.884146, 0.90625, 0.997483, -0.002231, 0.97561, -0.09375], [155, \"ontology\", \"analysis\", 0.591463, 0.95122, 0.560976, 0.948454, 0.997092, -0.001636, 0.946341, -0.007088], [48, \"database\", \"access\", 0.841463, 0.908537, 0.762195, 0.905797, 0.996985, -0.002305, 0.970919, -0.01872], [49, \"access\", \"database\", 0.908537, 0.841463, 0.762195, 0.838926, 0.996985, -0.002305, 0.984248, -0.032008], [95, \"xml\", \"design\", 0.652439, 0.993902, 0.646341, 0.990654, 0.996732, -0.002119, 0.652439, -0.009346], [221, \"failure\", \"access\", 0.512195, 0.908537, 0.463415, 0.904762, 0.995845, -0.001933, 0.960366, -0.00848], [140, \"optimization\", \"access\", 0.640244, 0.908537, 0.579268, 0.904762, 0.995845, -0.002417, 0.960366, -0.011464], [136, \"ontology\", \"design\", 0.591463, 0.993902, 0.585366, 0.989691, 0.995762, -0.002491, 0.591463, -0.010309], [30, \"database\", \"development\", 0.841463, 0.97561, 0.817073, 0.971014, 0.99529, -0.003867, 0.841463, -0.028986], [31, \"development\", \"database\", 0.97561, 0.841463, 0.817073, 0.8375, 0.99529, -0.003867, 0.97561, -0.1625], [82, \"evaluation\", \"access\", 0.762195, 0.908537, 0.689024, 0.904, 0.995007, -0.003458, 0.952744, -0.020667], [205, \"difficulty\", \"design\", 0.493902, 0.993902, 0.487805, 0.987654, 0.993714, -0.003086, 0.493902, -0.012346], [146, \"ontology\", \"development\", 0.591463, 0.97561, 0.573171, 0.969072, 0.993299, -0.003867, 0.788618, -0.016245], [167, \"ontology\", \"step\", 0.591463, 0.914634, 0.536585, 0.907216, 0.99189, -0.004387, 0.920054, -0.019621], [61, \"database\", \"description\", 0.841463, 0.878049, 0.731707, 0.869565, 0.990338, -0.007139, 0.934959, -0.057971], [62, \"description\", \"database\", 0.878049, 0.841463, 0.731707, 0.833333, 0.990338, -0.007139, 0.95122, -0.074074], [138, \"manufacturing\", \"access\", 0.646341, 0.908537, 0.579268, 0.896226, 0.986451, -0.007957, 0.881375, -0.037386], [193, \"reasoning\", \"step\", 0.560976, 0.914634, 0.506098, 0.902174, 0.986377, -0.00699, 0.872629, -0.0305], [240, \"api\", \"development\", 0.45122, 0.97561, 0.432927, 0.959459, 0.983446, -0.007287, 0.601626, -0.02976], [117, \"xml\", \"analysis\", 0.652439, 0.95122, 0.609756, 0.934579, 0.982507, -0.010857, 0.745645, -0.048732], [270, \"cad\", \"access\", 0.457317, 0.908537, 0.402439, 0.88, 0.968591, -0.01305, 0.762195, -0.056386]];\n",
       "\n",
       "        // Define the dt_args\n",
       "        let dt_args = {\"layout\": {\"topStart\": \"pageLength\", \"topEnd\": \"search\", \"bottomStart\": \"info\", \"bottomEnd\": \"paging\"}, \"order\": []};\n",
       "        dt_args[\"data\"] = data;\n",
       "\n",
       "        \n",
       "        new DataTable(table, dt_args);\n",
       "    });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def process_dataframe(config:Config, input_df, name = \"some_df\", path=None):\n",
    "#     if path is None:\n",
    "#         path = config.get_output_path()\n",
    "#     filepath = os.path.join(path, name)\n",
    "\n",
    "#     # convert all froensets to strings\n",
    "#     for col in input_df.columns:\n",
    "#         if isinstance(col[0], frozenset):\n",
    "#             # input_df[col] = input_df[col].apply(lambda x: \"_\".join(x))\n",
    "#             # input_df[col] = input_df[col].apply(lambda x: \"_\".join(x))\n",
    "#             input_df[col] = input_df[col].apply(lambda x: x + \"_HI!\")\n",
    "#             pass\n",
    "    \n",
    "#     input_df.to_csv(filepath + '.csv', sep=config.csv_separator, decimal=config.csv_decimal)\n",
    "#     show(input_df)\n",
    "\n",
    "# rules_cross_type = identify_cross_type_rules(rules)\n",
    "\n",
    "process_dataframe(config, rules_cross_type, 'rules_cross_type')\n",
    "# cross_type_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper x Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix(config, paper_instance_occurrence_matrix, rows=papers, columns=instances, name='paper_instance_occurrence_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix(config, error_matrix, rows=error_papers, columns=error_instances, name='error_matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance x Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix(config, instance_instance_co_occurrence_matrix, rows=instances, columns=instances, name='instance_instance_co_occurrence_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_matrix(config, instance_instance_proximity_matrix, rows=proximity_instances, columns=proximity_instances, name='instance_instance_proximity_matrix', instance_types_dicts=instance_types_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "## Pre-Processing\n",
    "Using Completion Rating in %\n",
    "\n",
    "### 80 %: Full Text extraction\n",
    "* lacking noise removal (Headings, page numbers, ...)\n",
    "* lacking line-break mending\n",
    "\n",
    "### 100 %: Bag of Words\n",
    "* The problem with BoW that the words are looked at seperatly and correlation is not really clear.\n",
    "\n",
    "\n",
    "### 99 %: TF-IDF\n",
    "* tf-idf only on terms\n",
    "\n",
    "### ? %: Part Of Speech (POS) Tagging, Named Entity Recognition (NER) \n",
    "* ready, but not used currently\n",
    "\n",
    "## Visualize\n",
    "\n",
    "### 85 % Matrix\n",
    "* CSV and Dataframe dumps work fine\n",
    "* Visualization as PNG or SVG are extremely large.\n",
    "  * DPI regulation works to somewhat keep this in check, but images still reach 20 MB\n",
    "\n",
    "### 100 % Timeline\n",
    "* arrange the papers on a timeline and identify the flow of:\n",
    "  * Processes\n",
    "  * File formats\n",
    "  * software\n",
    "  * ...\n",
    "* Additional ideas:\n",
    "  * Compare this to goolge trends\n",
    "\n",
    "## Future Work\n",
    "Using Difficulty ranked (DR) solutions:\n",
    "\n",
    "### Step 0: Look it up\n",
    "\n",
    "#### Wikidata linking & more\n",
    "* https://openrefine.org/\n",
    "\n",
    "#### More visualization\n",
    "* https://github.com/JasonKessler/scattertext \n",
    "* https://pypi.org/project/yellowbrick/\n",
    "\n",
    "#### NLP Pipelines:\n",
    "https://spacy.io/usage/processing-pipelines\n",
    "\n",
    "\n",
    "#### BLAST: Basic Local Alignment Search Tool\n",
    "  * starting point: https://academic.oup.com/bioinformatics/article/39/12/btad716/7450067\n",
    "\n",
    "#### AMIE 3\n",
    "  * https://luisgalarraga.de/docs/amie3.pdf\n",
    "  * https://github.com/dig-team/amie\n",
    "\n",
    "### Step 1: Low hanging fruits\n",
    "\n",
    "#### 1/5 DR: multi-word detection (n-gram)\n",
    "Tools:  nltk, spaCy, etc.\n",
    "\n",
    "### Step 2: Not-to-tricky follow-up\n",
    "\n",
    "#### 3/5 DR: Acronym Expansion\n",
    "Tools: spaCy - https://spacy.io/universe/project/neuralcoref\n",
    "\n",
    "#### 3/5 DR: CoReference resolution\n",
    "Tools: spaCy - https://spacy.io/universe/project/neuralcoref or https://huggingface.co/coref/ (you can use the model out of the box)\n",
    "\n",
    "### Step 3: Vector-magic\n",
    "\n",
    "#### 2-4/5 DR: Word embedding\n",
    "* Find out, that jpeg and png are similar\n",
    "\n",
    "(depending on your needs) - Tools: gensim - https://www.analyticsvidhya.com/blog/2023/07/step-by-step-guide-to-word2vec-with-gensim/\n",
    "\n",
    "#### 3/5 DR: document embedding\n",
    "Tools: gensim - https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e\n",
    "\n",
    "I would also check graph embeddings, sentence embeddings, and recently there is LLM2Vec\n",
    "\n",
    "### Step 3.1: Reaping the vector-rewards\n",
    "\n",
    "#### 1/5 DR: clustering\n",
    "Tools: sklearn\n",
    "\n",
    "Requirements: Need to have data as numbers first. This is quite possible after generating embeddings\n",
    "\n",
    "### Step 9: Won't be happening in this paper\n",
    "* Paper classes\n",
    "* Subclasses of paper classes\n",
    "* model which process is a subprocess of another process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
